{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os\n",
    "PATH = os.path.dirname(os.path.abspath(os.curdir))\n",
    "if PATH not in sys.path:\n",
    "    sys.path.insert(0, PATH)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import h5py\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "import src.Optimizer as opt\n",
    "import src.simulation_setup as setup\n",
    "import hierarchical_algorithm as ha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Buffer:  /Users/joseafonso/Desktop/PlasmaDM/Buffer_Data/Experimental_data_CO_O_merged_train.hdf5\n",
      "  d[CO2_F]/dt = -CO2_F*r_29 + r_28*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_F]/dt = -CO_F*O_F*r_35 - 0.02*CO_F*O_S*r_40 - 0.02*CO_F*Odb_S*r_61 - 0.02*CO_F*Vdb_S*r_60 - CO_F*r_31 - CO_F*r_33 - 0.02*CO_F*r_36*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_30*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_S]/dt = CO_F*r_36*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) - CO_S*O_F*r_39 - CO_S*r_37 - CO_S*r_43 - CO_S*r_44 - CO_S*r_45 - CO_S*r_46 + r_32*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[COdb_S]/dt = CO_F*Vdb_S*r_60 - COdb_S*O_F*r_62 - COdb_S*r_54 - COdb_S*r_55 - COdb_S*r_56 - COdb_S*r_57 - COdb_S*r_59 + Vdb_S*r_49\n",
      "  d[O2_F]/dt = -O2_F*O_F*r_15 - O2_F*r_10 - O2_F*r_12 - O2_F*r_14 + r_9*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_F]/dt = -CO_F*O_F*r_35 - 0.02*CO_S*O_F*r_39 - 0.02*COdb_S*O_F*r_62 - O2_F*O_F*r_15 - 2*O_F**2*r_8 - 0.02*O_F*O_S*r_7 - 0.02*O_F*Odb_S*r_27 - 0.02*O_F*Vdb_S*r_26 - O_F*r_11 - O_F*r_2 - O_F*r_34 - O_F*r_4 - 0.02*O_F*r_5*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_1*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_S]/dt = -CO_F*O_S*r_40 - O_F*O_S*r_7 + O_F*r_5*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) - O_S*r_16 - O_S*r_17 - O_S*r_38 - O_S*r_41 - O_S*r_42 - O_S*r_6 + r_3*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[Odb_S]/dt = -CO_F*Odb_S*r_61 - O_F*Odb_S*r_27 + O_F*Vdb_S*r_26 - Odb_S*r_23 - Odb_S*r_24 - Odb_S*r_25 - Odb_S*r_52 - Odb_S*r_53 - Odb_S*r_58 + Vdb_S*r_20\n",
      "  d[Vdb_S]/dt = CO_F*Odb_S*r_61 - CO_F*Vdb_S*r_60 + CO_S*r_43 + CO_S*r_44 + CO_S*r_45 + CO_S*r_46 + COdb_S*O_F*r_62 + COdb_S*r_59 + O_F*Odb_S*r_27 - O_F*Vdb_S*r_26 + O_S*r_16 + O_S*r_17 + O_S*r_41 + O_S*r_42 + Odb_S*r_25 + Odb_S*r_58 - Vdb_S*r_20 - Vdb_S*r_21 - Vdb_S*r_22 - Vdb_S*r_49 - Vdb_S*r_50 - Vdb_S*r_51 + r_18*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_19*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_47*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_48*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##* create simulator \n",
    "\n",
    "buffer_train = \"Experimental_data_CO_O_merged_train.hdf5\"\n",
    "\n",
    "const_dict, sim = setup.create_common_simulator(PATH, data_file=buffer_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Define Parameters and Bounds\n",
    "lower_bounds_dict = {\n",
    "    'A_d': 1e-8, 'B_d': 1e-8, 'E_d': 0.0, \n",
    "    'SF_30': 1e-5, 'SF_31': 1e-5, 'SF_32': 1e-5, 'SF_33': 1e-5, 'SF_34': 1e-5, 'SF_35': 1e-5, 'SF_36': 1e-5, 'SF_37': 1e-5, 'SF_38': 1e-5, 'SF_39': 1e-5,\n",
    "    'SF_49': 1e-5, 'SF_50': 1e-5, 'SF_51': 1e-5, 'SF_52': 1e-5, 'SF_53': 1e-5, 'SF_54': 1e-5, 'SF_55': 1e-5, 'SF_56': 1e-5, 'SF_57': 1e-5, 'SF_58': 1e-5, 'SF_59': 1e-5, 'SF_60': 1e-5, 'SF_61': 1e-5, 'SF_62': 1e-5,\n",
    "    'Emin': 1.0, 'Ealpha': 2000\n",
    "}\n",
    "\n",
    "upper_bounds_dict = {\n",
    "    'A_d': 5e-1, 'B_d': 1e-2, 'E_d': 30.0, \n",
    "    'SF_30': 1.0, 'SF_31': 1.0, 'SF_32': 1.0,  'SF_33': 1.0, 'SF_34': 1.0, 'SF_35': 1.0, 'SF_36': 1.0, 'SF_37': 1.0, 'SF_38': 1.0, 'SF_39': 1.0,\n",
    "    'SF_49': 1.0, 'SF_50': 1.0, 'SF_51': 1.0, 'SF_52': 1.0, 'SF_53': 1.0, 'SF_54': 1.0, 'SF_55': 1.0, 'SF_56': 1.0, 'SF_57': 1.0, 'SF_58': 1.0, 'SF_59': 1.0, 'SF_60': 1.0, 'SF_61': 1.0, 'SF_62': 1.0,\n",
    "    'Emin': 5.0, 'Ealpha': 5000\n",
    "}\n",
    "\n",
    "params_default_dict = {\n",
    "    'A_d': 0.02634, 'B_d': 7.67e-4, 'E_d': 10.75, \n",
    "    'SF_30': 1.0, 'SF_31': 1.0, 'SF_32': 1e-2,  'SF_33': 1e-1, 'SF_34': 1e-1, 'SF_35': 1e-2, 'SF_36': 1e-1, 'SF_37': 1e-1, 'SF_38': 1e-1, 'SF_39': 1e-1,\n",
    "    'SF_49': 1e-2, 'SF_50': 1.0, 'SF_51': 1.0, 'SF_52': 1.0, 'SF_53': 1e-1, 'SF_54': 1e-1, 'SF_55': 1.0, 'SF_56': 1.0, 'SF_57': 1.0, 'SF_58': 1e-1, 'SF_59': 1e-1, 'SF_60': 1e-2, 'SF_61': 1e-1, 'SF_62': 1e-1,\n",
    "    'Emin': 3.4, 'Ealpha': 3000\n",
    "}\n",
    "\n",
    "lower_bounds = np.array(list(lower_bounds_dict.values()))\n",
    "upper_bounds = np.array(list(upper_bounds_dict.values()))\n",
    "params_default_init = np.array(list(params_default_dict.values()))\n",
    "params_default_norm = (params_default_init - lower_bounds) * np.reciprocal(upper_bounds - lower_bounds)\n",
    "\n",
    "\n",
    "def func_optimization(params_input, flag='numpy'):\n",
    "    \n",
    "    ##! normalize variables\n",
    "    params = [0] * len(params_input)\n",
    "    for idx, param in enumerate(params_input):\n",
    "        params[idx] = lower_bounds[idx] + (upper_bounds[idx] - lower_bounds[idx]) * param\n",
    "    \n",
    "    A_d, B_d, E_d = params[0:3]\n",
    "    SF_30, SF_31, SF_32, SF_33, SF_34, SF_35, SF_36, SF_37, SF_38, SF_39 = params[3:13]\n",
    "    SF_49, SF_50, SF_51, SF_52, SF_53, SF_54, SF_55, SF_56, SF_57, SF_58, SF_59, SF_60, SF_61, SF_62 = params[13:27]\n",
    "    Emin, Ealpha = params[27:]\n",
    "    \n",
    "    if flag=='numpy':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * np.exp(E_d/(const_dict['R'] * T)))\n",
    "    elif flag=='torch':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * torch.exp(E_d/(const_dict['R'] * T)))\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "    \n",
    "    dict_mod_vec = [\n",
    "    {\"id\": 2, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 10, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 16, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    {\"id\": 18, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    \n",
    "    {\"id\": 31, \"rate\": None, \"model_dict\": {\"SF\": SF_31, \"nu_d\": nu_d_mod}},\n",
    "    \n",
    "    {\"id\": 30, \"rate\": None, \"model_dict\": {\"SF\": SF_30}},\n",
    "    {\"id\": 32, \"rate\": None, \"model_dict\": {\"SF\": SF_32}},\n",
    "    {\"id\": 33, \"rate\": None, \"model_dict\": {\"SF\": SF_33}},\n",
    "    {\"id\": 34, \"rate\": None, \"model_dict\": {\"SF\": SF_34}},\n",
    "    \n",
    "    {\"id\": 35, \"rate\": None, \"model_dict\": {\"SF\": SF_35}},\n",
    "    {\"id\": 36, \"rate\": None, \"model_dict\": {\"SF\": SF_36}},\n",
    "    {\"id\": 37, \"rate\": None, \"model_dict\": {\"SF\": SF_37}},\n",
    "    {\"id\": 38, \"rate\": None, \"model_dict\": {\"SF\": SF_38}},\n",
    "    {\"id\": 39, \"rate\": None, \"model_dict\": {\"SF\": SF_39}},\n",
    "    \n",
    "    {\"id\": 44, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    \n",
    "    {\"id\": 49, \"rate\": None, \"model_dict\": {\"SF\": SF_49}},\n",
    "    {\"id\": 50, \"rate\": None, \"model_dict\": {\"SF\": SF_50, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 51, \"rate\": None, \"model_dict\": {\"SF\": SF_51, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 52, \"rate\": None, \"model_dict\": {\"SF\": SF_52, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 53, \"rate\": None, \"model_dict\": {\"SF\": SF_53, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 54, \"rate\": None, \"model_dict\": {\"SF\": SF_54, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 55, \"rate\": None, \"model_dict\": {\"SF\": SF_55, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 56, \"rate\": None, \"model_dict\": {\"SF\": SF_56, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 57, \"rate\": None, \"model_dict\": {\"SF\": SF_57, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 58, \"rate\": None, \"model_dict\": {\"SF\": SF_58, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 59, \"rate\": None, \"model_dict\": {\"SF\": SF_59, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 60, \"rate\": None, \"model_dict\": {\"SF\": SF_60}},\n",
    "    {\"id\": 61, \"rate\": None, \"model_dict\": {\"SF\": SF_61}},\n",
    "    {\"id\": 62, \"rate\": None, \"model_dict\": {\"SF\": SF_62}}\n",
    "    ]\n",
    "    \n",
    "    return dict_mod_vec\n",
    "\n",
    "def loss_function(exp, teo, flag='numpy'):\n",
    "    func = ((teo-exp)**2)/(exp**2)\n",
    "    if flag == 'numpy':\n",
    "        return np.mean(func)\n",
    "    elif flag == 'torch':\n",
    "        return torch.mean(func)\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "\n",
    "\n",
    "# 4. Instantiate and Run Optimizer\n",
    "optimizer = opt.Optimizer(sim, \n",
    "                        lambda params: func_optimization(params, 'numpy'), \n",
    "                        lambda exp, teo: loss_function(exp, teo, 'numpy')\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pipeline with 5 steps...\n",
      "\n",
      "==================== CYCLE 1 ====================\n",
      "loss:  783.7419346722897 iter:  1\n",
      "\n",
      "[Step] Exact Decomposition (N=29)\n",
      "loss:  783.7419346722897 iter:  2\n",
      "loss:  783.6131523007717 iter:  3\n",
      "loss:  783.4588661803213 iter:  4\n",
      "loss:  783.453832024195 iter:  5\n",
      "loss:  783.7419336532563 iter:  6\n",
      "loss:  783.741936985504 iter:  7\n",
      "loss:  783.7340133720129 iter:  8\n",
      "loss:  783.7419369463686 iter:  9\n",
      "loss:  783.7420760099274 iter:  10\n",
      "loss:  783.7419348499305 iter:  11\n",
      "loss:  783.7419246777588 iter:  12\n",
      "loss:  783.7422188437661 iter:  13\n",
      "loss:  783.741935576763 iter:  14\n",
      "loss:  783.7424510033659 iter:  15\n",
      "loss:  783.7419285330387 iter:  16\n",
      "loss:  783.7419345508315 iter:  17\n",
      "loss:  783.7419344957118 iter:  18\n",
      "loss:  783.7419345067668 iter:  19\n",
      "loss:  783.7419345616311 iter:  20\n",
      "loss:  783.7419359558129 iter:  21\n",
      "loss:  783.7419346595168 iter:  22\n",
      "loss:  783.7419346601969 iter:  23\n",
      "loss:  783.7419346323334 iter:  24\n",
      "loss:  783.7419349179166 iter:  25\n",
      "loss:  783.741936583019 iter:  26\n",
      "loss:  783.7419359623465 iter:  27\n",
      "loss:  783.7419359666237 iter:  28\n",
      "loss:  783.741936022117 iter:  29\n",
      "loss:  783.7418988237662 iter:  30\n",
      "loss:  783.7419406296566 iter:  31\n",
      "  -> Split: Stiff=1, Sloppy=4\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  783.7419346722897 iter:  32\n",
      "loss:  783.7419346722897 iter:  33\n",
      "loss:  0.8266416850530199 iter:  34\n",
      "loss:  0.8341997889236835 iter:  35\n",
      "loss:  0.8308563009484548 iter:  36\n",
      "loss:  0.8179962796936994 iter:  37\n",
      "loss:  0.7696851587441889 iter:  38\n",
      "loss:  0.5248075265979539 iter:  39\n",
      "loss:  0.19991166259086388 iter:  40\n",
      "loss:  5.66705103174553 iter:  41\n",
      "loss:  0.24915533947273932 iter:  42\n",
      "loss:  0.21088901278572456 iter:  43\n",
      "loss:  0.17084421447109252 iter:  44\n",
      "loss:  0.1917858338044816 iter:  45\n",
      "loss:  0.16811203667798494 iter:  46\n",
      "loss:  0.16785741261254458 iter:  47\n",
      "loss:  0.16907454707531858 iter:  48\n",
      "loss:  0.7054721106155746 iter:  49\n",
      "loss:  0.16785741261254458 iter:  50\n",
      "loss:  0.7054721106155746 iter:  51\n",
      "loss:  132244.9797418677 iter:  52\n",
      "loss:  31.66183730228806 iter:  53\n",
      "loss:  0.43402560903178256 iter:  54\n",
      "loss:  0.2701066594237589 iter:  55\n",
      "loss:  0.961725361334839 iter:  56\n",
      "loss:  0.2387618213189562 iter:  57\n",
      "loss:  0.17227520078726433 iter:  58\n",
      "loss:  0.16777733551561091 iter:  59\n",
      "loss:  0.16769838645940968 iter:  60\n",
      "loss:  0.16769831826433879 iter:  61\n",
      "loss:  0.16769831401408805 iter:  62\n",
      "loss:  0.16769834099863876 iter:  63\n",
      "loss:  0.16769831401408805 iter:  64\n",
      "loss:  0.16784964113064343 iter:  65\n",
      "loss:  0.1681182537951195 iter:  66\n",
      "loss:  0.16775894814308565 iter:  67\n",
      "loss:  0.16772036500433063 iter:  68\n",
      "loss:  0.16769831255748444 iter:  69\n",
      "loss:  0.1676983118960266 iter:  70\n",
      "loss:  0.16769831189598236 iter:  71\n",
      "loss:  0.16769831189722312 iter:  72\n",
      "  -> Loss: 0.167698 (Unbounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.16769831189598236 iter:  73\n",
      "loss:  0.16771275232464358 iter:  74\n",
      "loss:  0.16773265189879727 iter:  75\n",
      "loss:  0.16769483659212867 iter:  76\n",
      "loss:  0.1676993040261575 iter:  77\n",
      "  -> Realigned. Top Eigenvals: [15940.33271412  6454.9145308     16.78564928]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:4\n",
      "loss:  0.16769831189598236 iter:  78\n",
      "loss:  0.1684585276365234 iter:  79\n",
      "loss:  0.16715965739739402 iter:  80\n",
      "loss:  0.16768456251506955 iter:  81\n",
      "loss:  0.16770099250064924 iter:  82\n",
      "loss:  0.1666448782514651 iter:  83\n",
      "loss:  0.1657097124955479 iter:  84\n",
      "loss:  0.1664296277026714 iter:  85\n",
      "loss:  0.16578310399904486 iter:  86\n",
      "loss:  0.1648189203216135 iter:  87\n",
      "loss:  0.16331765874828458 iter:  88\n",
      "loss:  0.16341196306412745 iter:  89\n",
      "loss:  0.16263096601230176 iter:  90\n",
      "loss:  0.16060846595777695 iter:  91\n",
      "loss:  0.1606733509755109 iter:  92\n",
      "loss:  0.1580271612147771 iter:  93\n",
      "loss:  0.1536953738602705 iter:  94\n",
      "loss:  0.1556883774687728 iter:  95\n",
      "loss:  0.15151720663726206 iter:  96\n",
      "loss:  0.1445339985347269 iter:  97\n",
      "loss:  0.14623113470131902 iter:  98\n",
      "loss:  0.1377115025735195 iter:  99\n",
      "loss:  0.1237344421526955 iter:  100\n",
      "loss:  0.127161417765363 iter:  101\n",
      "loss:  0.11777322724840794 iter:  102\n",
      "loss:  0.6330883834388976 iter:  103\n",
      "loss:  0.12140831221166355 iter:  104\n",
      "loss:  0.4356670556021755 iter:  105\n",
      "loss:  0.13194409064259463 iter:  106\n",
      "loss:  0.12951578455988508 iter:  107\n",
      "loss:  0.11740635918052418 iter:  108\n",
      "loss:  0.14866466738095538 iter:  109\n",
      "loss:  0.1213956821361088 iter:  110\n",
      "loss:  0.1362498367276744 iter:  111\n",
      "loss:  0.11969726835536093 iter:  112\n",
      "loss:  0.12508775605551017 iter:  113\n",
      "loss:  0.11749064356747346 iter:  114\n",
      "loss:  0.1209967112399689 iter:  115\n",
      "loss:  0.11767872992422856 iter:  116\n",
      "loss:  0.12561892310270928 iter:  117\n",
      "loss:  0.11790288461690636 iter:  118\n",
      "loss:  0.11922046496650777 iter:  119\n",
      "loss:  0.1174302671987503 iter:  120\n",
      "loss:  0.11852771188551933 iter:  121\n",
      "loss:  0.11742200712575285 iter:  122\n",
      "loss:  0.1176119125875685 iter:  123\n",
      "loss:  0.11741142743098902 iter:  124\n",
      "loss:  0.117385289472615 iter:  125\n",
      "loss:  0.11762046998285897 iter:  126\n",
      "loss:  0.11728953818463257 iter:  127\n",
      "loss:  0.11739330367087156 iter:  128\n",
      "loss:  0.11715952351400499 iter:  129\n",
      "loss:  0.11710249378998731 iter:  130\n",
      "loss:  0.11721701106281665 iter:  131\n",
      "loss:  0.11708451799620825 iter:  132\n",
      "loss:  0.11720102634435499 iter:  133\n",
      "loss:  0.11760201859610551 iter:  134\n",
      "loss:  0.11717002579228036 iter:  135\n",
      "loss:  0.11684583539114725 iter:  136\n",
      "loss:  0.11663168205509532 iter:  137\n",
      "loss:  0.11710766562610748 iter:  138\n",
      "loss:  0.11665681305898998 iter:  139\n",
      "loss:  0.1170113812347672 iter:  140\n",
      "loss:  0.11654906250320995 iter:  141\n",
      "loss:  0.11641470609216302 iter:  142\n",
      "loss:  0.11618916470204997 iter:  143\n",
      "loss:  0.11592959996464695 iter:  144\n",
      "loss:  0.11605990144112993 iter:  145\n",
      "loss:  0.11560173146463033 iter:  146\n",
      "loss:  0.11510010651836534 iter:  147\n",
      "loss:  0.11493275419705734 iter:  148\n",
      "loss:  0.11420923412917819 iter:  149\n",
      "loss:  0.11409927370365718 iter:  150\n",
      "loss:  0.1132264477266722 iter:  151\n",
      "loss:  0.11351977258378511 iter:  152\n",
      "loss:  0.11224354263041929 iter:  153\n",
      "loss:  0.11115629805477577 iter:  154\n",
      "loss:  0.11063860007478507 iter:  155\n",
      "loss:  0.10898870039723205 iter:  156\n",
      "loss:  0.10968522539929898 iter:  157\n",
      "loss:  0.10833851525724761 iter:  158\n",
      "loss:  0.10740223898050835 iter:  159\n",
      "loss:  0.10670302251161845 iter:  160\n",
      "loss:  0.10694249094234072 iter:  161\n",
      "loss:  0.10600819969386716 iter:  162\n",
      "loss:  0.10717010300789555 iter:  163\n",
      "loss:  0.10686811463162413 iter:  164\n",
      "loss:  0.1073121758581625 iter:  165\n",
      "loss:  0.10580216181652931 iter:  166\n",
      "loss:  0.10654968683792584 iter:  167\n",
      "loss:  0.10673884560937097 iter:  168\n",
      "loss:  0.1071650886138848 iter:  169\n",
      "loss:  0.10604849336208012 iter:  170\n",
      "loss:  0.10668193859080163 iter:  171\n",
      "loss:  0.10574741020879179 iter:  172\n",
      "loss:  0.10707113449450553 iter:  173\n",
      "loss:  0.10595204375076198 iter:  174\n",
      "loss:  0.10660682392978332 iter:  175\n",
      "loss:  0.10551536628442809 iter:  176\n",
      "loss:  0.10646823418652376 iter:  177\n",
      "loss:  0.10545832588526814 iter:  178\n",
      "loss:  0.10684028469754918 iter:  179\n",
      "loss:  0.10540376435550769 iter:  180\n",
      "loss:  0.10575559474251954 iter:  181\n",
      "loss:  0.10543514581634286 iter:  182\n",
      "loss:  0.10657960235291657 iter:  183\n",
      "loss:  0.10538895379384725 iter:  184\n",
      "loss:  0.1057728524674702 iter:  185\n",
      "loss:  0.10538650962833206 iter:  186\n",
      "loss:  0.10536257582190203 iter:  187\n",
      "loss:  0.10548129680350954 iter:  188\n",
      "loss:  0.10544059235914577 iter:  189\n",
      "loss:  0.1053653416185607 iter:  190\n",
      "loss:  0.10543626203215764 iter:  191\n",
      "loss:  0.10535494014109632 iter:  192\n",
      "loss:  0.10543586623083437 iter:  193\n",
      "loss:  0.10535092160049939 iter:  194\n",
      "loss:  0.10541976038354466 iter:  195\n",
      "loss:  0.10535152424748939 iter:  196\n",
      "loss:  0.10537437032457792 iter:  197\n",
      "loss:  0.10534800536901351 iter:  198\n",
      "loss:  0.10538731293924336 iter:  199\n",
      "loss:  0.10534627179922325 iter:  200\n",
      "loss:  0.10535789571456022 iter:  201\n",
      "loss:  0.10534613626526064 iter:  202\n",
      "loss:  0.10536113785977068 iter:  203\n",
      "loss:  0.10534483101181477 iter:  204\n",
      "loss:  0.10535591254266827 iter:  205\n",
      "loss:  0.10534507495679753 iter:  206\n",
      "loss:  0.10534840249708383 iter:  207\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.105345\n",
      "\n",
      "==================== CYCLE 2 ====================\n",
      "\n",
      "[Step] Exact Decomposition (N=29)\n",
      "loss:  0.10534483101181477 iter:  208\n",
      "loss:  0.10534541005017471 iter:  209\n",
      "loss:  0.10534578470788065 iter:  210\n",
      "loss:  0.10534556235712679 iter:  211\n",
      "loss:  0.10534483062272702 iter:  212\n",
      "loss:  0.10534483140034195 iter:  213\n",
      "loss:  0.10534612687285967 iter:  214\n",
      "loss:  0.10534483104881408 iter:  215\n",
      "loss:  0.10534482269451423 iter:  216\n",
      "loss:  0.10534483101592235 iter:  217\n",
      "loss:  0.10534482707159598 iter:  218\n",
      "loss:  0.1053459362229975 iter:  219\n",
      "loss:  0.10534487296994058 iter:  220\n",
      "loss:  0.10534454961172687 iter:  221\n",
      "loss:  0.1053460374734279 iter:  222\n",
      "loss:  0.10534484175475549 iter:  223\n",
      "loss:  0.10534484206769401 iter:  224\n",
      "loss:  0.10534484007136576 iter:  225\n",
      "loss:  0.10534483846594236 iter:  226\n",
      "loss:  0.10534483192576785 iter:  227\n",
      "loss:  0.10534483649501349 iter:  228\n",
      "loss:  0.10534483401071941 iter:  229\n",
      "loss:  0.10534483598856256 iter:  230\n",
      "loss:  0.10534480479882144 iter:  231\n",
      "loss:  0.10534469668554479 iter:  232\n",
      "loss:  0.10534483120974299 iter:  233\n",
      "loss:  0.10534483100699671 iter:  234\n",
      "loss:  0.10534482862996476 iter:  235\n",
      "loss:  0.1053457272054284 iter:  236\n",
      "loss:  0.10534445235255371 iter:  237\n",
      "  -> Split: Stiff=1, Sloppy=5\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.10534483101181477 iter:  238\n",
      "loss:  0.10534483101181477 iter:  239\n",
      "loss:  11.793872300090882 iter:  240\n",
      "loss:  0.7666260782296536 iter:  241\n",
      "loss:  0.5519298954951538 iter:  242\n",
      "loss:  0.4724623414316496 iter:  243\n",
      "loss:  0.28705671147225914 iter:  244\n",
      "loss:  0.22771310426475408 iter:  245\n",
      "loss:  0.18114722056807547 iter:  246\n",
      "loss:  0.23788285787883323 iter:  247\n",
      "loss:  0.19129285782398317 iter:  248\n",
      "loss:  0.30486434854069827 iter:  249\n",
      "loss:  0.14713028050508178 iter:  250\n",
      "loss:  0.11915699177636745 iter:  251\n",
      "loss:  0.12260743174511665 iter:  252\n",
      "loss:  0.10710794464806557 iter:  253\n",
      "loss:  0.10672068078633637 iter:  254\n",
      "loss:  0.10536658593763464 iter:  255\n",
      "loss:  0.10534493913654172 iter:  256\n",
      "loss:  0.10534470799583026 iter:  257\n",
      "loss:  0.10534470784497459 iter:  258\n",
      "loss:  0.10534470785415512 iter:  259\n",
      "loss:  0.10534470786113749 iter:  260\n",
      "  -> Loss: 0.105345 (Unbounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.10534470784497459 iter:  261\n",
      "loss:  0.10534371031827153 iter:  262\n",
      "loss:  0.10534275281125688 iter:  263\n",
      "loss:  0.105345409557164 iter:  264\n",
      "loss:  0.10534457534940805 iter:  265\n",
      "loss:  0.10534484365513808 iter:  266\n",
      "  -> Realigned. Top Eigenvals: [30051.14972614    66.44046199    45.79783634]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:5\n",
      "loss:  0.10534470784497459 iter:  267\n",
      "loss:  0.10532997132460498 iter:  268\n",
      "loss:  0.10529569524841338 iter:  269\n",
      "loss:  0.10532713865082456 iter:  270\n",
      "loss:  0.10534140383571794 iter:  271\n",
      "loss:  0.10534804340864555 iter:  272\n",
      "loss:  0.1053049007675516 iter:  273\n",
      "loss:  0.10529335787007127 iter:  274\n",
      "loss:  0.10527014387939594 iter:  275\n",
      "loss:  0.10527032363327102 iter:  276\n",
      "loss:  0.10526124893798262 iter:  277\n",
      "loss:  0.10523742320740348 iter:  278\n",
      "loss:  0.10521833201101063 iter:  279\n",
      "loss:  0.10516635676237383 iter:  280\n",
      "loss:  0.1051820498717941 iter:  281\n",
      "loss:  0.10515090886535985 iter:  282\n",
      "loss:  0.10508460583941275 iter:  283\n",
      "loss:  0.10509848813800181 iter:  284\n",
      "loss:  0.1050313517131741 iter:  285\n",
      "loss:  0.10491779870543474 iter:  286\n",
      "loss:  0.10496226542490679 iter:  287\n",
      "loss:  0.10489970207195572 iter:  288\n",
      "loss:  0.10476190764577681 iter:  289\n",
      "loss:  0.10474966109532259 iter:  290\n",
      "loss:  0.1045410258594641 iter:  291\n",
      "loss:  0.1046069477400163 iter:  292\n",
      "loss:  0.10441854309913089 iter:  293\n",
      "loss:  0.10408654077900797 iter:  294\n",
      "loss:  0.10420989284175645 iter:  295\n",
      "loss:  0.10398499262157235 iter:  296\n",
      "loss:  0.10356390992510561 iter:  297\n",
      "loss:  0.10360893521735366 iter:  298\n",
      "loss:  0.10337551089618596 iter:  299\n",
      "loss:  0.10276903550320814 iter:  300\n",
      "loss:  0.10270773655625157 iter:  301\n",
      "loss:  0.10177238291322001 iter:  302\n",
      "loss:  0.10209763415989984 iter:  303\n",
      "loss:  0.10142190479109048 iter:  304\n",
      "loss:  0.10010704665427653 iter:  305\n",
      "loss:  0.10047657978580368 iter:  306\n",
      "loss:  0.09927457195081664 iter:  307\n",
      "loss:  0.0970919012420991 iter:  308\n",
      "loss:  0.09785892001277079 iter:  309\n",
      "loss:  0.09672345435575809 iter:  310\n",
      "loss:  0.09393026899373981 iter:  311\n",
      "loss:  0.09393199942040391 iter:  312\n",
      "loss:  0.09250431356975351 iter:  313\n",
      "loss:  0.08824055353014165 iter:  314\n",
      "loss:  0.08789225267959008 iter:  315\n",
      "loss:  0.08277404794957172 iter:  316\n",
      "loss:  0.08414094622413895 iter:  317\n",
      "loss:  0.0809490846760339 iter:  318\n",
      "loss:  0.07608684595111123 iter:  319\n",
      "loss:  0.0763954384331132 iter:  320\n",
      "loss:  0.07308310108875067 iter:  321\n",
      "loss:  0.15469308377796256 iter:  322\n",
      "loss:  0.0754645527742101 iter:  323\n",
      "loss:  0.0759216706067031 iter:  324\n",
      "loss:  0.1681605428538351 iter:  325\n",
      "loss:  0.07675841717169217 iter:  326\n",
      "loss:  0.07475057090376985 iter:  327\n",
      "loss:  0.1254426600019622 iter:  328\n",
      "loss:  0.0736054069740335 iter:  329\n",
      "loss:  0.1162001122498049 iter:  330\n",
      "loss:  0.074294323480979 iter:  331\n",
      "loss:  0.07441690932810825 iter:  332\n",
      "loss:  0.0747620440638455 iter:  333\n",
      "loss:  0.07392227162090226 iter:  334\n",
      "loss:  0.07926425349677964 iter:  335\n",
      "loss:  0.07563749054329583 iter:  336\n",
      "loss:  0.07320377025047148 iter:  337\n",
      "loss:  0.07343183474609634 iter:  338\n",
      "loss:  0.07366496877962196 iter:  339\n",
      "loss:  0.07332062864136114 iter:  340\n",
      "loss:  0.07723708702734358 iter:  341\n",
      "loss:  0.07509540577739984 iter:  342\n",
      "loss:  0.07385117958405485 iter:  343\n",
      "loss:  0.07391857108138103 iter:  344\n",
      "loss:  0.07344581845575018 iter:  345\n",
      "loss:  0.07306918688016921 iter:  346\n",
      "loss:  0.07317485277059203 iter:  347\n",
      "loss:  0.07290621639441197 iter:  348\n",
      "loss:  0.07281447911335379 iter:  349\n",
      "loss:  0.07257635718854014 iter:  350\n",
      "loss:  0.0722537546779624 iter:  351\n",
      "loss:  0.07256703718087609 iter:  352\n",
      "loss:  0.07204602792567445 iter:  353\n",
      "loss:  0.07156449716509003 iter:  354\n",
      "loss:  0.07175779059371273 iter:  355\n",
      "loss:  0.07192354460156504 iter:  356\n",
      "loss:  0.07099662008404785 iter:  357\n",
      "loss:  0.07041744008679368 iter:  358\n",
      "loss:  0.07065587761682313 iter:  359\n",
      "loss:  0.07022730068701906 iter:  360\n",
      "loss:  0.07066801798143783 iter:  361\n",
      "loss:  0.07104838143232364 iter:  362\n",
      "loss:  0.06947257988087652 iter:  363\n",
      "loss:  0.06872777927977759 iter:  364\n",
      "loss:  0.06981780387139952 iter:  365\n",
      "loss:  0.06930657612406188 iter:  366\n",
      "loss:  0.06890450526943163 iter:  367\n",
      "loss:  0.06925720359531545 iter:  368\n",
      "loss:  0.07104738121505505 iter:  369\n",
      "loss:  0.06926183664332011 iter:  370\n",
      "loss:  0.07292890617547068 iter:  371\n",
      "loss:  0.06885399355187832 iter:  372\n",
      "loss:  0.0686002488785117 iter:  373\n",
      "loss:  0.0692964772150193 iter:  374\n",
      "loss:  0.06950469183977968 iter:  375\n",
      "loss:  0.06882688210806588 iter:  376\n",
      "loss:  0.06951168877344573 iter:  377\n",
      "loss:  0.06877625027374691 iter:  378\n",
      "loss:  0.06883865140391521 iter:  379\n",
      "loss:  0.06879741068484833 iter:  380\n",
      "loss:  0.0687047139678861 iter:  381\n",
      "loss:  0.06904106837993934 iter:  382\n",
      "loss:  0.068708978607643 iter:  383\n",
      "loss:  0.06860924523971333 iter:  384\n",
      "loss:  0.06869398053680296 iter:  385\n",
      "loss:  0.0689206672724308 iter:  386\n",
      "loss:  0.06865178263671284 iter:  387\n",
      "loss:  0.0685929797435078 iter:  388\n",
      "loss:  0.0686193283861969 iter:  389\n",
      "loss:  0.06909330736298133 iter:  390\n",
      "loss:  0.06883102090941477 iter:  391\n",
      "loss:  0.06857374884128957 iter:  392\n",
      "loss:  0.06859334477972057 iter:  393\n",
      "loss:  0.0686019073797076 iter:  394\n",
      "loss:  0.0686109000986288 iter:  395\n",
      "loss:  0.06889508800984055 iter:  396\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.068574\n",
      "  -> Conv Check: dS=9.1e-01, dPhi=2.2e-01, dLoss=3.7e-02\n",
      "\n",
      "==================== CYCLE 3 ====================\n",
      "\n",
      "[Step] Exact Decomposition (N=29)\n",
      "loss:  0.06857374884128957 iter:  397\n",
      "loss:  0.06857393049833452 iter:  398\n",
      "loss:  0.06857569659148223 iter:  399\n",
      "loss:  0.0685769606266112 iter:  400\n",
      "loss:  0.06857374886539717 iter:  401\n",
      "loss:  0.06857374882391908 iter:  402\n",
      "loss:  0.06862701843031824 iter:  403\n",
      "loss:  0.06857374800576835 iter:  404\n",
      "loss:  0.06857364922319142 iter:  405\n",
      "loss:  0.0685737488105521 iter:  406\n",
      "loss:  0.06857374996185814 iter:  407\n",
      "loss:  0.06857255370367402 iter:  408\n",
      "loss:  0.06857374618053753 iter:  409\n",
      "loss:  0.06857377563047369 iter:  410\n",
      "loss:  0.06857411189757008 iter:  411\n",
      "loss:  0.06857375338515723 iter:  412\n",
      "loss:  0.06857375538443329 iter:  413\n",
      "loss:  0.06857375462711104 iter:  414\n",
      "loss:  0.06857375262127492 iter:  415\n",
      "loss:  0.06857374945585205 iter:  416\n",
      "loss:  0.06857375045414268 iter:  417\n",
      "loss:  0.06857375022544929 iter:  418\n",
      "loss:  0.06857375204109244 iter:  419\n",
      "loss:  0.06857373444889746 iter:  420\n",
      "loss:  0.06857368800163864 iter:  421\n",
      "loss:  0.06857374889955656 iter:  422\n",
      "loss:  0.06857374884279424 iter:  423\n",
      "loss:  0.06857374787541105 iter:  424\n",
      "loss:  0.06857405570463806 iter:  425\n",
      "loss:  0.06857354906703478 iter:  426\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.06857374884128957 iter:  427\n",
      "loss:  0.06857374884128957 iter:  428\n",
      "loss:  0.3935508174405892 iter:  429\n",
      "loss:  0.48452951946521144 iter:  430\n",
      "loss:  0.2023232818354226 iter:  431\n",
      "loss:  0.3026781246738961 iter:  432\n",
      "loss:  0.22670414283382614 iter:  433\n",
      "loss:  0.26567239359203965 iter:  434\n",
      "loss:  0.2305431062232152 iter:  435\n",
      "loss:  0.24399057641295607 iter:  436\n",
      "loss:  0.21753813718507733 iter:  437\n",
      "loss:  0.2194861569561413 iter:  438\n",
      "loss:  0.18720677741365985 iter:  439\n",
      "loss:  0.18510510211633457 iter:  440\n",
      "loss:  0.06964928287788356 iter:  441\n",
      "loss:  0.06943478541523308 iter:  442\n",
      "loss:  0.1435795489616091 iter:  443\n",
      "loss:  0.10573660668686162 iter:  444\n",
      "loss:  0.08191099774070297 iter:  445\n",
      "loss:  0.07211630252795645 iter:  446\n",
      "loss:  0.06937496357957615 iter:  447\n",
      "loss:  0.06855996769765717 iter:  448\n",
      "loss:  0.06855100051929212 iter:  449\n",
      "loss:  0.06867880432183872 iter:  450\n",
      "loss:  0.06854973702620061 iter:  451\n",
      "loss:  0.06854973694594 iter:  452\n",
      "loss:  0.06854974182216017 iter:  453\n",
      "loss:  0.0685751104673266 iter:  454\n",
      "loss:  0.06854973694594 iter:  455\n",
      "loss:  0.3935491028055861 iter:  456\n",
      "loss:  0.4845388519743681 iter:  457\n",
      "loss:  0.20232317440164868 iter:  458\n",
      "loss:  0.3026763052239889 iter:  459\n",
      "loss:  0.22670384787915449 iter:  460\n",
      "loss:  0.26567024515446525 iter:  461\n",
      "loss:  0.23054374251497348 iter:  462\n",
      "loss:  0.24398578753449926 iter:  463\n",
      "loss:  0.21754752906861732 iter:  464\n",
      "loss:  0.2194689982987501 iter:  465\n",
      "loss:  0.18725404918425348 iter:  466\n",
      "loss:  0.18504433476454696 iter:  467\n",
      "loss:  0.06986233685125738 iter:  468\n",
      "loss:  0.06855207127084632 iter:  469\n",
      "loss:  0.0758807430356777 iter:  470\n",
      "loss:  0.07014624401933374 iter:  471\n",
      "loss:  0.06883091599189148 iter:  472\n",
      "loss:  0.06854974686200863 iter:  473\n",
      "loss:  0.06854973634969808 iter:  474\n",
      "loss:  0.06854973634784316 iter:  475\n",
      "loss:  0.06854973634621077 iter:  476\n",
      "loss:  0.0685500751624978 iter:  477\n",
      "loss:  0.06854978585811386 iter:  478\n",
      "loss:  0.06854974364503692 iter:  479\n",
      "loss:  0.06854973744583935 iter:  480\n",
      "loss:  0.0685497365234315 iter:  481\n",
      "loss:  0.06854973638723716 iter:  482\n",
      "loss:  0.06854973635500018 iter:  483\n",
      "loss:  0.06854973635919516 iter:  484\n",
      "loss:  0.06854973635846534 iter:  485\n",
      "loss:  0.06854973636953444 iter:  486\n",
      "  -> Loss: 0.068550 (Unbounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.06854973634621077 iter:  487\n",
      "loss:  0.06854697501949188 iter:  488\n",
      "loss:  0.06854919213544129 iter:  489\n",
      "loss:  0.0685502398272718 iter:  490\n",
      "loss:  0.06854975748433903 iter:  491\n",
      "loss:  0.0685496991280558 iter:  492\n",
      "loss:  0.06854974276743886 iter:  493\n",
      "  -> Realigned. Top Eigenvals: [31405.65239423 12433.74686245   121.62661004]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.06854973634621077 iter:  494\n",
      "loss:  0.06862941551226923 iter:  495\n",
      "loss:  0.06853925721924231 iter:  496\n",
      "loss:  0.06853718217934374 iter:  497\n",
      "loss:  0.06854931742885763 iter:  498\n",
      "loss:  0.06854880128271947 iter:  499\n",
      "loss:  0.06854961444978588 iter:  500\n",
      "loss:  0.06848155724633463 iter:  501\n",
      "loss:  0.06843895267430834 iter:  502\n",
      "loss:  0.06849475801463077 iter:  503\n",
      "loss:  0.06847890339725264 iter:  504\n",
      "loss:  0.06846010606666453 iter:  505\n",
      "loss:  0.06843836258687296 iter:  506\n",
      "loss:  0.06840571284096 iter:  507\n",
      "loss:  0.0684145699477753 iter:  508\n",
      "loss:  0.06840528982113696 iter:  509\n",
      "loss:  0.06842613390494105 iter:  510\n",
      "loss:  0.06839789581156606 iter:  511\n",
      "loss:  0.06840920324304853 iter:  512\n",
      "loss:  0.0683998127275179 iter:  513\n",
      "loss:  0.06841076958272367 iter:  514\n",
      "loss:  0.06839842359245528 iter:  515\n",
      "loss:  0.06842290581521251 iter:  516\n",
      "loss:  0.06839965873832198 iter:  517\n",
      "loss:  0.06840887505363508 iter:  518\n",
      "loss:  0.06839858813948793 iter:  519\n",
      "loss:  0.06841224849084493 iter:  520\n",
      "loss:  0.06839735362940352 iter:  521\n",
      "loss:  0.0683840879394257 iter:  522\n",
      "loss:  0.0683757967091417 iter:  523\n",
      "loss:  0.0683852098495501 iter:  524\n",
      "loss:  0.0683818393704744 iter:  525\n",
      "loss:  0.06838515819948597 iter:  526\n",
      "loss:  0.06839260767385494 iter:  527\n",
      "loss:  0.06836569703443719 iter:  528\n",
      "loss:  0.06835109310735596 iter:  529\n",
      "loss:  0.06835959580742017 iter:  530\n",
      "loss:  0.06838688886427773 iter:  531\n",
      "loss:  0.06837380734890484 iter:  532\n",
      "loss:  0.06838445054656613 iter:  533\n",
      "loss:  0.06835154939127944 iter:  534\n",
      "loss:  0.06837645321530193 iter:  535\n",
      "loss:  0.06834120476162975 iter:  536\n",
      "loss:  0.06832118208420968 iter:  537\n",
      "loss:  0.06836403526580957 iter:  538\n",
      "loss:  0.06832997117523155 iter:  539\n",
      "loss:  0.06831319241146318 iter:  540\n",
      "loss:  0.06828457550361663 iter:  541\n",
      "loss:  0.06833122707450773 iter:  542\n",
      "loss:  0.06829435993502728 iter:  543\n",
      "loss:  0.06828250906780924 iter:  544\n",
      "loss:  0.06825293499429205 iter:  545\n",
      "loss:  0.06824566604003693 iter:  546\n",
      "loss:  0.06819406609375278 iter:  547\n",
      "loss:  0.06823700014448832 iter:  548\n",
      "loss:  0.06821124817015117 iter:  549\n",
      "loss:  0.06816927558509758 iter:  550\n",
      "loss:  0.06810535172189065 iter:  551\n",
      "loss:  0.06812513029555417 iter:  552\n",
      "loss:  0.06809169310003751 iter:  553\n",
      "loss:  0.06802426242095465 iter:  554\n",
      "loss:  0.06803789008441771 iter:  555\n",
      "loss:  0.0680523584991821 iter:  556\n",
      "loss:  0.06798640731974023 iter:  557\n",
      "loss:  0.06806905713127588 iter:  558\n",
      "loss:  0.06801715215397552 iter:  559\n",
      "loss:  0.06804607733233381 iter:  560\n",
      "loss:  0.06808527222224431 iter:  561\n",
      "loss:  0.06800840836665523 iter:  562\n",
      "loss:  0.06799543303313706 iter:  563\n",
      "loss:  0.0680161800502741 iter:  564\n",
      "loss:  0.06810362334623314 iter:  565\n",
      "loss:  0.0680001372179562 iter:  566\n",
      "loss:  0.06800540823294601 iter:  567\n",
      "loss:  0.06799146849055188 iter:  568\n",
      "loss:  0.06807037379139297 iter:  569\n",
      "loss:  0.06798661280840813 iter:  570\n",
      "loss:  0.06801052281731956 iter:  571\n",
      "loss:  0.06798214576817876 iter:  572\n",
      "loss:  0.06802707335292754 iter:  573\n",
      "loss:  0.06797635694595823 iter:  574\n",
      "loss:  0.06799017225548384 iter:  575\n",
      "loss:  0.06799841695115878 iter:  576\n",
      "loss:  0.06797666457922324 iter:  577\n",
      "loss:  0.0680306978037651 iter:  578\n",
      "loss:  0.06797645856091648 iter:  579\n",
      "loss:  0.06800215394915793 iter:  580\n",
      "loss:  0.06797545590665176 iter:  581\n",
      "loss:  0.0679981164618987 iter:  582\n",
      "loss:  0.06797743010073426 iter:  583\n",
      "loss:  0.0679826593183274 iter:  584\n",
      "loss:  0.06797510193318244 iter:  585\n",
      "loss:  0.06797439170712932 iter:  586\n",
      "loss:  0.06798620311888334 iter:  587\n",
      "loss:  0.06798364943243847 iter:  588\n",
      "loss:  0.06797352871811953 iter:  589\n",
      "loss:  0.06797346485896326 iter:  590\n",
      "loss:  0.06797910766284938 iter:  591\n",
      "loss:  0.06798488705308599 iter:  592\n",
      "loss:  0.06797287126983019 iter:  593\n",
      "loss:  0.06797375893760137 iter:  594\n",
      "loss:  0.06797937848942771 iter:  595\n",
      "loss:  0.06797241230956501 iter:  596\n",
      "loss:  0.06798066406688985 iter:  597\n",
      "loss:  0.06797221691952081 iter:  598\n",
      "loss:  0.06797436113747053 iter:  599\n",
      "loss:  0.06797274340820542 iter:  600\n",
      "loss:  0.06797520095217503 iter:  601\n",
      "loss:  0.06797247377149597 iter:  602\n",
      "loss:  0.06797155848912892 iter:  603\n",
      "loss:  0.06797197057420544 iter:  604\n",
      "loss:  0.06797231947385987 iter:  605\n",
      "loss:  0.0679722258493711 iter:  606\n",
      "loss:  0.06797303917504333 iter:  607\n",
      "loss:  0.06797191264129586 iter:  608\n",
      "loss:  0.06797481325147135 iter:  609\n",
      "loss:  0.06797169549781351 iter:  610\n",
      "loss:  0.06797126770935319 iter:  611\n",
      "loss:  0.06797133583261238 iter:  612\n",
      "loss:  0.0679720675661238 iter:  613\n",
      "loss:  0.06797313724348214 iter:  614\n",
      "loss:  0.06797159392966269 iter:  615\n",
      "loss:  0.06797172557470034 iter:  616\n",
      "loss:  0.06797138380552939 iter:  617\n",
      "loss:  0.0679712539280831 iter:  618\n",
      "loss:  0.06797173368515315 iter:  619\n",
      "loss:  0.06797204162125217 iter:  620\n",
      "loss:  0.06797135898845628 iter:  621\n",
      "loss:  0.06797087459070587 iter:  622\n",
      "loss:  0.06797068216827397 iter:  623\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.067971\n",
      "  -> Conv Check: dS=1.9e-03, dPhi=1.4e-02, dLoss=6.0e-04\n",
      "\n",
      "==================== CYCLE 4 ====================\n",
      "\n",
      "[Step] Exact Decomposition (N=29)\n",
      "loss:  0.06797068216827397 iter:  624\n",
      "loss:  0.06797062279609188 iter:  625\n",
      "loss:  0.06797038731254863 iter:  626\n",
      "loss:  0.06797004753460152 iter:  627\n",
      "loss:  0.06797068024082231 iter:  628\n",
      "loss:  0.06797068409185476 iter:  629\n",
      "loss:  0.06795767087042036 iter:  630\n",
      "loss:  0.06797068148376154 iter:  631\n",
      "loss:  0.06797060299765655 iter:  632\n",
      "loss:  0.06797068213644872 iter:  633\n",
      "loss:  0.06797066360193124 iter:  634\n",
      "loss:  0.0679712815551233 iter:  635\n",
      "loss:  0.06797068303220227 iter:  636\n",
      "loss:  0.0679708072657595 iter:  637\n",
      "loss:  0.06797065330200294 iter:  638\n",
      "loss:  0.06797068417594518 iter:  639\n",
      "loss:  0.06797068753440394 iter:  640\n",
      "loss:  0.06797068728196097 iter:  641\n",
      "loss:  0.06797068469414579 iter:  642\n",
      "loss:  0.06797068221374068 iter:  643\n",
      "loss:  0.06797068186111929 iter:  644\n",
      "loss:  0.06797068216462497 iter:  645\n",
      "loss:  0.0679706824074765 iter:  646\n",
      "loss:  0.06797067224550613 iter:  647\n",
      "loss:  0.06797068270673265 iter:  648\n",
      "loss:  0.06797068214241501 iter:  649\n",
      "loss:  0.06797068216000077 iter:  650\n",
      "loss:  0.06797068220371799 iter:  651\n",
      "loss:  0.06797088501701642 iter:  652\n",
      "loss:  0.06797057251542794 iter:  653\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.06797068216827397 iter:  654\n",
      "loss:  0.06797068216827397 iter:  655\n",
      "loss:  0.3878460084664612 iter:  656\n",
      "loss:  0.5825855541889206 iter:  657\n",
      "loss:  0.19680865244660248 iter:  658\n",
      "loss:  0.2927833476406311 iter:  659\n",
      "loss:  0.215517292022349 iter:  660\n",
      "loss:  0.2548110111631567 iter:  661\n",
      "loss:  0.21929453011124886 iter:  662\n",
      "loss:  0.23288021788662902 iter:  663\n",
      "loss:  0.2066719968879124 iter:  664\n",
      "loss:  0.20882624296338956 iter:  665\n",
      "loss:  0.17712861940350672 iter:  666\n",
      "loss:  0.17544721124531548 iter:  667\n",
      "loss:  0.06797598048686894 iter:  668\n",
      "loss:  0.31029141868331006 iter:  669\n",
      "loss:  0.13562402212815872 iter:  670\n",
      "loss:  0.10009907929417289 iter:  671\n",
      "loss:  0.07858232561460608 iter:  672\n",
      "loss:  0.0703342613228012 iter:  673\n",
      "loss:  0.07519138313216618 iter:  674\n",
      "loss:  0.06831921079971845 iter:  675\n",
      "loss:  0.06882495225150678 iter:  676\n",
      "loss:  0.06798796693566066 iter:  677\n",
      "loss:  0.06812416369259372 iter:  678\n",
      "loss:  0.06795767104057389 iter:  679\n",
      "loss:  0.0679620713011754 iter:  680\n",
      "loss:  0.0679576691451746 iter:  681\n",
      "loss:  0.06795767245624422 iter:  682\n",
      "loss:  0.06795766839895229 iter:  683\n",
      "loss:  0.06796989253552814 iter:  684\n",
      "loss:  0.06795766839895229 iter:  685\n",
      "loss:  0.06796989253552814 iter:  686\n",
      "loss:  0.06799227087955437 iter:  687\n",
      "loss:  0.06796260031037685 iter:  688\n",
      "loss:  0.06795946896225366 iter:  689\n",
      "loss:  0.06795766846816562 iter:  690\n",
      "loss:  0.0679576683432877 iter:  691\n",
      "loss:  0.06795766834159125 iter:  692\n",
      "loss:  0.06795766834780624 iter:  693\n",
      "loss:  0.06795766834514953 iter:  694\n",
      "loss:  0.06795766834264093 iter:  695\n",
      "loss:  0.06795766833912054 iter:  696\n",
      "loss:  0.06795766834178354 iter:  697\n",
      "loss:  0.06795766833579536 iter:  698\n",
      "loss:  0.06795766833579536 iter:  699\n",
      "loss:  0.0679576683900926 iter:  700\n",
      "loss:  0.06795766848253272 iter:  701\n",
      "loss:  0.0679576683593994 iter:  702\n",
      "loss:  0.06795766835009524 iter:  703\n",
      "loss:  0.06795766833589416 iter:  704\n",
      "loss:  0.0679576683406869 iter:  705\n",
      "loss:  0.06795766834433287 iter:  706\n",
      "loss:  0.06795766833859603 iter:  707\n",
      "loss:  0.06795766833682741 iter:  708\n",
      "loss:  0.06795766834351072 iter:  709\n",
      "loss:  0.06795766834003057 iter:  710\n",
      "loss:  0.06795766833526297 iter:  711\n",
      "loss:  0.06795766834363184 iter:  712\n",
      "loss:  0.06795766833605021 iter:  713\n",
      "loss:  0.06795766833892053 iter:  714\n",
      "loss:  0.06795766833696984 iter:  715\n",
      "loss:  0.06795766833779268 iter:  716\n",
      "loss:  0.06795766833739642 iter:  717\n",
      "loss:  0.06795766834641982 iter:  718\n",
      "loss:  0.06795766833756847 iter:  719\n",
      "loss:  0.06795766834159232 iter:  720\n",
      "loss:  0.0679576683385387 iter:  721\n",
      "  -> Loss: 0.067958 (Unbounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.06795766833526297 iter:  722\n",
      "loss:  0.06795774122027491 iter:  723\n",
      "loss:  0.06795753302492294 iter:  724\n",
      "loss:  0.06795760867201699 iter:  725\n",
      "loss:  0.06795760780757826 iter:  726\n",
      "loss:  0.0679579032685326 iter:  727\n",
      "loss:  0.06795761558409172 iter:  728\n",
      "  -> Realigned. Top Eigenvals: [32368.96089478  9672.79838083  1239.55837902]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.06795766833526297 iter:  729\n",
      "loss:  0.06796710642111065 iter:  730\n",
      "loss:  0.06795663268329445 iter:  731\n",
      "loss:  0.06795968089098385 iter:  732\n",
      "loss:  0.06795920512495325 iter:  733\n",
      "loss:  0.06796355698170356 iter:  734\n",
      "loss:  0.06795898928503415 iter:  735\n",
      "loss:  0.06797251439973577 iter:  736\n",
      "loss:  0.06796029229358551 iter:  737\n",
      "loss:  0.06795280913994173 iter:  738\n",
      "loss:  0.06794804207621573 iter:  739\n",
      "loss:  0.06795672249178507 iter:  740\n",
      "loss:  0.0679521924166515 iter:  741\n",
      "loss:  0.06795027139065898 iter:  742\n",
      "loss:  0.06794835628061412 iter:  743\n",
      "loss:  0.06794802741076512 iter:  744\n",
      "loss:  0.06794747035424667 iter:  745\n",
      "loss:  0.06794764857976134 iter:  746\n",
      "loss:  0.06793883889653295 iter:  747\n",
      "loss:  0.06793046344019436 iter:  748\n",
      "loss:  0.06793980708046635 iter:  749\n",
      "loss:  0.06793758041134 iter:  750\n",
      "loss:  0.06793618129959371 iter:  751\n",
      "loss:  0.0679403888680389 iter:  752\n",
      "loss:  0.06793096867252507 iter:  753\n",
      "loss:  0.06792531144606495 iter:  754\n",
      "loss:  0.06791921101692415 iter:  755\n",
      "loss:  0.06792776530375799 iter:  756\n",
      "loss:  0.06791780286663249 iter:  757\n",
      "loss:  0.06790836716554968 iter:  758\n",
      "loss:  0.06790963997279707 iter:  759\n",
      "loss:  0.06790183676022224 iter:  760\n",
      "loss:  0.06788551288106631 iter:  761\n",
      "loss:  0.06790466385328976 iter:  762\n",
      "loss:  0.06789504327928177 iter:  763\n",
      "loss:  0.06788496970220809 iter:  764\n",
      "loss:  0.0678761349627777 iter:  765\n",
      "loss:  0.06786819002584007 iter:  766\n",
      "loss:  0.06784615812451807 iter:  767\n",
      "loss:  0.06786097926953022 iter:  768\n",
      "loss:  0.06784791020973088 iter:  769\n",
      "loss:  0.06783601116004025 iter:  770\n",
      "loss:  0.06781753937568315 iter:  771\n",
      "loss:  0.06780862428969182 iter:  772\n",
      "loss:  0.0677736723416135 iter:  773\n",
      "loss:  0.06781128583789701 iter:  774\n",
      "loss:  0.06777327685130323 iter:  775\n",
      "loss:  0.06773898857591386 iter:  776\n",
      "loss:  0.067746661544371 iter:  777\n",
      "loss:  0.06773594781313973 iter:  778\n",
      "loss:  0.06772344177949251 iter:  779\n",
      "loss:  0.06773790180223628 iter:  780\n",
      "loss:  0.06769569732446118 iter:  781\n",
      "loss:  0.06769348424612937 iter:  782\n",
      "loss:  0.06769116700860292 iter:  783\n",
      "loss:  0.06778419898331306 iter:  784\n",
      "loss:  0.06772602279466035 iter:  785\n",
      "loss:  0.06776267329862976 iter:  786\n",
      "loss:  0.06770922634740463 iter:  787\n",
      "loss:  0.06783813583551077 iter:  788\n",
      "loss:  0.0677008388706818 iter:  789\n",
      "loss:  0.06769031630145125 iter:  790\n",
      "loss:  0.06774159979055697 iter:  791\n",
      "loss:  0.0677157047147039 iter:  792\n",
      "loss:  0.06768556062507161 iter:  793\n",
      "loss:  0.06773581632269413 iter:  794\n",
      "loss:  0.06771414267531407 iter:  795\n",
      "loss:  0.06768785195102031 iter:  796\n",
      "loss:  0.06771996795315591 iter:  797\n",
      "loss:  0.06768748675125598 iter:  798\n",
      "loss:  0.06771750895777129 iter:  799\n",
      "loss:  0.06768481170846531 iter:  800\n",
      "loss:  0.06768838746574955 iter:  801\n",
      "loss:  0.06770112587401819 iter:  802\n",
      "loss:  0.06768176546786486 iter:  803\n",
      "loss:  0.0676867943202083 iter:  804\n",
      "loss:  0.06768976832265383 iter:  805\n",
      "loss:  0.06768150276069146 iter:  806\n",
      "loss:  0.06769795107643711 iter:  807\n",
      "loss:  0.06768045184591291 iter:  808\n",
      "loss:  0.06767795907282692 iter:  809\n",
      "loss:  0.06768497044055674 iter:  810\n",
      "loss:  0.06769189182002439 iter:  811\n",
      "loss:  0.06768007623849986 iter:  812\n",
      "loss:  0.06769577721456847 iter:  813\n",
      "loss:  0.06767908829495603 iter:  814\n",
      "loss:  0.06767714108446389 iter:  815\n",
      "loss:  0.06768265176855966 iter:  816\n",
      "loss:  0.067683576562917 iter:  817\n",
      "loss:  0.06767834825133469 iter:  818\n",
      "loss:  0.06767631177312697 iter:  819\n",
      "loss:  0.06767934473218455 iter:  820\n",
      "loss:  0.06767649846054088 iter:  821\n",
      "loss:  0.06768511944596267 iter:  822\n",
      "loss:  0.06767671385314165 iter:  823\n",
      "loss:  0.06767514430159736 iter:  824\n",
      "loss:  0.06767685711898835 iter:  825\n",
      "loss:  0.0676765467195105 iter:  826\n",
      "loss:  0.06767228159125097 iter:  827\n",
      "loss:  0.06766989060237762 iter:  828\n",
      "loss:  0.06767218848239115 iter:  829\n",
      "loss:  0.06767321395428222 iter:  830\n",
      "loss:  0.06767268789660713 iter:  831\n",
      "loss:  0.0676753458956199 iter:  832\n",
      "loss:  0.06766823725930532 iter:  833\n",
      "loss:  0.06766602822769477 iter:  834\n",
      "loss:  0.067673367484837 iter:  835\n",
      "loss:  0.06766515723943171 iter:  836\n",
      "loss:  0.06766190298353623 iter:  837\n",
      "loss:  0.06766883377514932 iter:  838\n",
      "loss:  0.06766830519097375 iter:  839\n",
      "loss:  0.06766057872300532 iter:  840\n",
      "loss:  0.06765642359368314 iter:  841\n",
      "loss:  0.06765543963765135 iter:  842\n",
      "loss:  0.0676491905355718 iter:  843\n",
      "loss:  0.067650110098582 iter:  844\n",
      "loss:  0.06765342736744955 iter:  845\n",
      "loss:  0.06764546516131298 iter:  846\n",
      "loss:  0.0676430070028058 iter:  847\n",
      "loss:  0.06763750704005937 iter:  848\n",
      "loss:  0.06763125767388888 iter:  849\n",
      "loss:  0.06762631168036497 iter:  850\n",
      "loss:  0.06761297092668844 iter:  851\n",
      "loss:  0.06761792144989774 iter:  852\n",
      "loss:  0.06760856447871053 iter:  853\n",
      "loss:  0.0675927288882859 iter:  854\n",
      "loss:  0.0675983724727377 iter:  855\n",
      "loss:  0.06759662193600155 iter:  856\n",
      "loss:  0.06757125317819757 iter:  857\n",
      "loss:  0.06754877664183699 iter:  858\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.067549\n",
      "  -> Conv Check: dS=1.0e-06, dPhi=2.7e-02, dLoss=4.2e-04\n",
      "\n",
      "==================== CYCLE 5 ====================\n",
      "\n",
      "[Step] Exact Decomposition (N=29)\n",
      "loss:  0.06754877664183699 iter:  859\n",
      "loss:  0.06754870883798923 iter:  860\n",
      "loss:  0.06754886394189576 iter:  861\n",
      "loss:  0.06754892276547171 iter:  862\n",
      "loss:  0.06754877482236697 iter:  863\n",
      "loss:  0.06754877846592433 iter:  864\n",
      "loss:  0.06753895881510619 iter:  865\n",
      "loss:  0.0675487759330103 iter:  866\n",
      "loss:  0.06754869280787429 iter:  867\n",
      "loss:  0.06754877662031976 iter:  868\n",
      "loss:  0.06754875919004245 iter:  869\n",
      "loss:  0.0675495279770999 iter:  870\n",
      "loss:  0.06754877729233623 iter:  871\n",
      "loss:  0.06754889637982925 iter:  872\n",
      "loss:  0.06754888460803163 iter:  873\n",
      "loss:  0.06754877876914822 iter:  874\n",
      "loss:  0.06754878121521973 iter:  875\n",
      "loss:  0.06754878086437356 iter:  876\n",
      "loss:  0.06754877882121572 iter:  877\n",
      "loss:  0.06754877676223296 iter:  878\n",
      "loss:  0.06754877647343867 iter:  879\n",
      "loss:  0.06754877681409097 iter:  880\n",
      "loss:  0.06754877733818496 iter:  881\n",
      "loss:  0.06754876736667807 iter:  882\n",
      "loss:  0.06754876986721794 iter:  883\n",
      "loss:  0.06754877665115476 iter:  884\n",
      "loss:  0.06754877664294512 iter:  885\n",
      "loss:  0.06754877657733506 iter:  886\n",
      "loss:  0.06754887717396012 iter:  887\n",
      "loss:  0.06754867563349014 iter:  888\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.06754877664183699 iter:  889\n",
      "loss:  0.06754877664183699 iter:  890\n",
      "loss:  0.40614373422128314 iter:  891\n",
      "loss:  0.8766454330697185 iter:  892\n",
      "loss:  0.19454378081300383 iter:  893\n",
      "loss:  0.29866267833187504 iter:  894\n",
      "loss:  0.2091905887024357 iter:  895\n",
      "loss:  0.25498235248026524 iter:  896\n",
      "loss:  0.21483690173112197 iter:  897\n",
      "loss:  0.23075794656915194 iter:  898\n",
      "loss:  0.20302053913868995 iter:  899\n",
      "loss:  0.2056443494001852 iter:  900\n",
      "loss:  0.17374700973367016 iter:  901\n",
      "loss:  0.17182077105146595 iter:  902\n",
      "loss:  0.06772848544107894 iter:  903\n",
      "loss:  0.232841286818652 iter:  904\n",
      "loss:  0.13219500270412374 iter:  905\n",
      "loss:  0.09757429536241956 iter:  906\n",
      "loss:  0.07720927023663098 iter:  907\n",
      "loss:  0.06965884626523654 iter:  908\n",
      "loss:  0.07308801798957146 iter:  909\n",
      "loss:  0.06786089568007754 iter:  910\n",
      "loss:  0.06823064190830344 iter:  911\n",
      "loss:  0.06756719617531748 iter:  912\n",
      "loss:  0.06767174599930602 iter:  913\n",
      "loss:  0.06753892467078254 iter:  914\n",
      "loss:  0.06753890461813412 iter:  915\n",
      "loss:  0.0675389006818795 iter:  916\n",
      "loss:  0.06753890148652515 iter:  917\n",
      "loss:  0.06754835243798873 iter:  918\n",
      "loss:  0.0675389006818795 iter:  919\n",
      "loss:  0.06754835243798873 iter:  920\n",
      "loss:  0.06756516040509626 iter:  921\n",
      "loss:  0.06754263493554402 iter:  922\n",
      "loss:  0.06754030336812648 iter:  923\n",
      "loss:  0.06753890074969407 iter:  924\n",
      "loss:  0.06753890067282557 iter:  925\n",
      "loss:  0.06753890067193351 iter:  926\n",
      "loss:  0.0675389006731512 iter:  927\n",
      "loss:  0.06753890067266044 iter:  928\n",
      "loss:  0.06753890067612878 iter:  929\n",
      "loss:  0.06753890067403255 iter:  930\n",
      "loss:  0.0675389006770251 iter:  931\n",
      "loss:  0.06753890067328122 iter:  932\n",
      "loss:  0.06753890067193351 iter:  933\n",
      "loss:  0.06753890069285425 iter:  934\n",
      "loss:  0.06753890069330394 iter:  935\n",
      "loss:  0.06753890067574966 iter:  936\n",
      "loss:  0.06753890067737722 iter:  937\n",
      "loss:  0.06753890067368325 iter:  938\n",
      "loss:  0.06753890067577811 iter:  939\n",
      "loss:  0.06753890067392451 iter:  940\n",
      "loss:  0.06753890067487098 iter:  941\n",
      "loss:  0.06753890067336954 iter:  942\n",
      "loss:  0.06753890067755347 iter:  943\n",
      "loss:  0.06753890067706753 iter:  944\n",
      "loss:  0.06753890067784546 iter:  945\n",
      "loss:  0.06753890067771576 iter:  946\n",
      "loss:  0.0675389006750323 iter:  947\n",
      "loss:  0.06753890067288745 iter:  948\n",
      "loss:  0.06753890067368647 iter:  949\n",
      "loss:  0.06753890067501622 iter:  950\n",
      "loss:  0.06753890067361508 iter:  951\n",
      "loss:  0.0675389006755372 iter:  952\n",
      "loss:  0.06753890067669059 iter:  953\n",
      "loss:  0.06753890067701321 iter:  954\n",
      "loss:  0.06753890067425901 iter:  955\n",
      "loss:  0.06753890067625463 iter:  956\n",
      "loss:  0.0675389006711769 iter:  957\n",
      "loss:  0.06753890067253177 iter:  958\n",
      "  -> Loss: 0.067539 (Unbounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.06753890067193351 iter:  959\n",
      "loss:  0.06753814663414417 iter:  960\n",
      "loss:  0.06753896224935133 iter:  961\n",
      "loss:  0.06753906384204239 iter:  962\n",
      "loss:  0.067538843990617 iter:  963\n",
      "loss:  0.0675388344529587 iter:  964\n",
      "loss:  0.06753885317020994 iter:  965\n",
      "  -> Realigned. Top Eigenvals: [33205.53465797  8219.2237469    531.95156255]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.06753890067193351 iter:  966\n",
      "loss:  0.0675691728452689 iter:  967\n",
      "loss:  0.06754236430892953 iter:  968\n",
      "loss:  0.06754315096689555 iter:  969\n",
      "loss:  0.06754033320791651 iter:  970\n",
      "loss:  0.0675372604632621 iter:  971\n",
      "loss:  0.06753771565747566 iter:  972\n",
      "loss:  0.06753224107953297 iter:  973\n",
      "loss:  0.06754746810110666 iter:  974\n",
      "loss:  0.06753048526516207 iter:  975\n",
      "loss:  0.06752568300038123 iter:  976\n",
      "loss:  0.06752920827174973 iter:  977\n",
      "loss:  0.06752532148218822 iter:  978\n",
      "loss:  0.06752164244065188 iter:  979\n",
      "loss:  0.06752342825296638 iter:  980\n",
      "loss:  0.06752486996983205 iter:  981\n",
      "loss:  0.0675302443026712 iter:  982\n",
      "loss:  0.0675154412442751 iter:  983\n",
      "loss:  0.06750902555774338 iter:  984\n",
      "loss:  0.0675284217440282 iter:  985\n",
      "loss:  0.06751494840901653 iter:  986\n",
      "loss:  0.06753132867470016 iter:  987\n",
      "loss:  0.06752069586037435 iter:  988\n",
      "loss:  0.06751684822197583 iter:  989\n",
      "loss:  0.06750994184378696 iter:  990\n",
      "loss:  0.06750552933402011 iter:  991\n",
      "loss:  0.06749868066102242 iter:  992\n",
      "loss:  0.06750103285002831 iter:  993\n",
      "loss:  0.067502747430674 iter:  994\n",
      "loss:  0.06750002264642542 iter:  995\n",
      "loss:  0.06749591940019302 iter:  996\n",
      "loss:  0.06749792570978755 iter:  997\n",
      "loss:  0.06749678859716453 iter:  998\n",
      "loss:  0.06749053766086067 iter:  999\n",
      "loss:  0.06748981000367389 iter:  1000\n",
      "loss:  0.06749743952793322 iter:  1001\n",
      "loss:  0.06749207609527015 iter:  1002\n",
      "loss:  0.06749162592595008 iter:  1003\n",
      "loss:  0.06750387475002702 iter:  1004\n",
      "loss:  0.06749302373253901 iter:  1005\n",
      "loss:  0.06749565400468636 iter:  1006\n",
      "loss:  0.0674864215746816 iter:  1007\n",
      "loss:  0.0674850053663661 iter:  1008\n",
      "loss:  0.06749256124729514 iter:  1009\n",
      "loss:  0.06749496732927145 iter:  1010\n",
      "loss:  0.06748982411132681 iter:  1011\n",
      "loss:  0.0675041388014272 iter:  1012\n",
      "loss:  0.06748873924725148 iter:  1013\n",
      "loss:  0.06749419557981479 iter:  1014\n",
      "loss:  0.0674892083570457 iter:  1015\n",
      "loss:  0.06748459083220679 iter:  1016\n",
      "loss:  0.0674822776927027 iter:  1017\n",
      "loss:  0.06748435165637509 iter:  1018\n",
      "loss:  0.06748331787837775 iter:  1019\n",
      "loss:  0.06747984448125453 iter:  1020\n",
      "loss:  0.06747691991888866 iter:  1021\n",
      "loss:  0.0674760010107247 iter:  1022\n",
      "loss:  0.06747166855042283 iter:  1023\n",
      "loss:  0.06747514458702078 iter:  1024\n",
      "loss:  0.06747094274479709 iter:  1025\n",
      "loss:  0.06746679086591605 iter:  1026\n",
      "loss:  0.06747034666632448 iter:  1027\n",
      "loss:  0.067465675985424 iter:  1028\n",
      "loss:  0.06746499888442599 iter:  1029\n",
      "loss:  0.06746007354802194 iter:  1030\n",
      "loss:  0.06745865368099879 iter:  1031\n",
      "loss:  0.06745321542769142 iter:  1032\n",
      "loss:  0.06744699672958773 iter:  1033\n",
      "loss:  0.06745045894919635 iter:  1034\n",
      "loss:  0.06745500527303545 iter:  1035\n",
      "loss:  0.06745007885122842 iter:  1036\n",
      "loss:  0.06747748481153766 iter:  1037\n",
      "loss:  0.06745399186196062 iter:  1038\n",
      "loss:  0.06744127308264129 iter:  1039\n",
      "loss:  0.06743990290861983 iter:  1040\n",
      "loss:  0.0674456025777423 iter:  1041\n",
      "loss:  0.06743725962753673 iter:  1042\n",
      "loss:  0.06743647601003662 iter:  1043\n",
      "loss:  0.06743907131106412 iter:  1044\n",
      "loss:  0.06743998787565816 iter:  1045\n",
      "loss:  0.06744189998313864 iter:  1046\n",
      "loss:  0.06744421252628376 iter:  1047\n",
      "loss:  0.06743500070834375 iter:  1048\n",
      "loss:  0.0674429789390132 iter:  1049\n",
      "loss:  0.06743767329152936 iter:  1050\n",
      "loss:  0.06744415782099228 iter:  1051\n",
      "loss:  0.06743536669762941 iter:  1052\n",
      "loss:  0.067437095879637 iter:  1053\n",
      "loss:  0.06743335857023547 iter:  1054\n",
      "loss:  0.06744171736164102 iter:  1055\n",
      "loss:  0.06743968157384748 iter:  1056\n",
      "loss:  0.06743378967012882 iter:  1057\n",
      "loss:  0.06743600774563613 iter:  1058\n",
      "loss:  0.06743366743036176 iter:  1059\n",
      "loss:  0.0674419313303625 iter:  1060\n",
      "loss:  0.06743231217635236 iter:  1061\n",
      "loss:  0.06743435445380205 iter:  1062\n",
      "loss:  0.06743400842535843 iter:  1063\n",
      "loss:  0.06743587709262161 iter:  1064\n",
      "loss:  0.06743199319681256 iter:  1065\n",
      "loss:  0.067435928482959 iter:  1066\n",
      "loss:  0.06743164624928288 iter:  1067\n",
      "loss:  0.06743455348324236 iter:  1068\n",
      "loss:  0.06743176038814994 iter:  1069\n",
      "loss:  0.06743322839581083 iter:  1070\n",
      "loss:  0.06743659408625863 iter:  1071\n",
      "loss:  0.06743140670904081 iter:  1072\n",
      "loss:  0.06743450851889815 iter:  1073\n",
      "loss:  0.06743152379870271 iter:  1074\n",
      "loss:  0.06743412284569576 iter:  1075\n",
      "loss:  0.06743151874582062 iter:  1076\n",
      "loss:  0.06743209667903723 iter:  1077\n",
      "loss:  0.06743125874881807 iter:  1078\n",
      "loss:  0.06743146201199285 iter:  1079\n",
      "loss:  0.06743061307601436 iter:  1080\n",
      "loss:  0.06743106219388582 iter:  1081\n",
      "loss:  0.06743296939770078 iter:  1082\n",
      "loss:  0.06743086367016173 iter:  1083\n",
      "loss:  0.0674317463598496 iter:  1084\n",
      "loss:  0.06743095375219994 iter:  1085\n",
      "loss:  0.06743070240580058 iter:  1086\n",
      "loss:  0.06743197286167378 iter:  1087\n",
      "loss:  0.06743082398458965 iter:  1088\n",
      "loss:  0.06743102969343465 iter:  1089\n",
      "loss:  0.06743138430339826 iter:  1090\n",
      "loss:  0.06743076681932075 iter:  1091\n",
      "loss:  0.06743125376918885 iter:  1092\n",
      "loss:  0.06743069762996477 iter:  1093\n",
      "loss:  0.06743082886802662 iter:  1094\n",
      "loss:  0.06743032597937676 iter:  1095\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.067430\n",
      "  -> Conv Check: dS=4.0e-06, dPhi=1.5e-02, dLoss=1.2e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_iters_tot = 1300\n",
    "filename_results = \"results/results_hier0_train_V4.h5\"\n",
    "\n",
    "pipeline = [\n",
    "    ('decompose_exact', {'percent_info': 0.90, 'tau': 1e-4}),\n",
    "    ('optimize_stiff', {'max_iter': 70}),\n",
    "    ('realign_sloppy', {}),\n",
    "    ('optimize_sloppy', {'max_iter': 130}),\n",
    "    ('check_convergence', {'tol_s': 1e-4})\n",
    "]\n",
    "\n",
    "opt_hier = ha.HierarchicalOptimizer(optimizer, params_default_norm, pipeline=pipeline)\n",
    "opt_hier.run(max_cycles=5, max_iter=max_iters_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with h5py.File(filename_results, \"w\") as f:\n",
    "    \n",
    "    f.create_dataset(\"best_loss\", data=opt_hier.history['best_loss'])\n",
    "    f.create_dataset(\"iters\", data=opt_hier.history['iters'])\n",
    "    f.create_dataset(\"best_params\", data=opt_hier.history['best_params'])\n",
    "    \n",
    "    f.create_dataset(\"best_params_end\", data=opt_hier.phi)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qp_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
