{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PATH = os.path.dirname(os.path.abspath(os.curdir))\n",
    "if PATH not in sys.path:\n",
    "    sys.path.insert(0, PATH)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import h5py\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "import src.Optimizer as opt\n",
    "import src.simulation_setup as setup\n",
    "import hierarchical_algorithm as ha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Buffer:  /Users/joseafonso/Desktop/PlasmaDM/Buffer_Data/Experimental_data_CO_O_merged_train.hdf5\n",
      "  d[CO2_F]/dt = -CO2_F*r_29 + r_28*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_F]/dt = -CO_F*O_F*r_35 - 0.02*CO_F*O_S*r_40 - 0.02*CO_F*Odb_S*r_61 - 0.02*CO_F*Vdb_S*r_60 - CO_F*r_31 - CO_F*r_33 - 0.02*CO_F*r_36*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_30*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_S]/dt = CO_F*r_36*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) - CO_S*O_F*r_39 - CO_S*r_37 - CO_S*r_43 - CO_S*r_44 - CO_S*r_45 - CO_S*r_46 + r_32*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[COdb_S]/dt = CO_F*Vdb_S*r_60 - COdb_S*O_F*r_62 - COdb_S*r_54 - COdb_S*r_55 - COdb_S*r_56 - COdb_S*r_57 - COdb_S*r_59 + Vdb_S*r_49\n",
      "  d[O2_F]/dt = -O2_F*O_F*r_15 - O2_F*r_10 - O2_F*r_12 - O2_F*r_14 + r_9*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_F]/dt = -CO_F*O_F*r_35 - 0.02*CO_S*O_F*r_39 - 0.02*COdb_S*O_F*r_62 - O2_F*O_F*r_15 - 2*O_F**2*r_8 - 0.02*O_F*O_S*r_7 - 0.02*O_F*Odb_S*r_27 - 0.02*O_F*Vdb_S*r_26 - O_F*r_11 - O_F*r_2 - O_F*r_34 - O_F*r_4 - 0.02*O_F*r_5*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_1*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_S]/dt = -CO_F*O_S*r_40 - O_F*O_S*r_7 + O_F*r_5*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) - O_S*r_16 - O_S*r_17 - O_S*r_38 - O_S*r_41 - O_S*r_42 - O_S*r_6 + r_3*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[Odb_S]/dt = -CO_F*Odb_S*r_61 - O_F*Odb_S*r_27 + O_F*Vdb_S*r_26 - Odb_S*r_23 - Odb_S*r_24 - Odb_S*r_25 - Odb_S*r_52 - Odb_S*r_53 - Odb_S*r_58 + Vdb_S*r_20\n",
      "  d[Vdb_S]/dt = CO_F*Odb_S*r_61 - CO_F*Vdb_S*r_60 + CO_S*r_43 + CO_S*r_44 + CO_S*r_45 + CO_S*r_46 + COdb_S*O_F*r_62 + COdb_S*r_59 + O_F*Odb_S*r_27 - O_F*Vdb_S*r_26 + O_S*r_16 + O_S*r_17 + O_S*r_41 + O_S*r_42 + Odb_S*r_25 + Odb_S*r_58 - Vdb_S*r_20 - Vdb_S*r_21 - Vdb_S*r_22 - Vdb_S*r_49 - Vdb_S*r_50 - Vdb_S*r_51 + r_18*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_19*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_47*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_48*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##* create simulator \n",
    "\n",
    "buffer_train = \"Experimental_data_CO_O_merged_train.hdf5\"\n",
    "\n",
    "const_dict, sim = setup.create_common_simulator(PATH, data_file=buffer_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Define Parameters and Bounds\n",
    "lower_bounds_dict = {\n",
    "    'A_d': 1e-8, 'B_d': 1e-8, 'E_d': 0.0, \n",
    "    'SF_30': 1e-5, 'SF_31': 1e-5, 'SF_32': 1e-5, 'SF_33': 1e-5, 'SF_34': 1e-5, 'SF_35': 1e-5, 'SF_36': 1e-5, 'SF_37': 1e-5, 'SF_38': 1e-5, 'SF_39': 1e-5,\n",
    "    'SF_49': 1e-5, 'SF_50': 1e-5, 'SF_51': 1e-5, 'SF_52': 1e-5, 'SF_53': 1e-5, 'SF_54': 1e-5, 'SF_55': 1e-5, 'SF_56': 1e-5, 'SF_57': 1e-5, 'SF_58': 1e-5, 'SF_59': 1e-5, 'SF_60': 1e-5, 'SF_61': 1e-5, 'SF_62': 1e-5,\n",
    "    'Emin': 1.0, 'Ealpha': 2000\n",
    "}\n",
    "\n",
    "upper_bounds_dict = {\n",
    "    'A_d': 5e-1, 'B_d': 1e-2, 'E_d': 30.0, \n",
    "    'SF_30': 1.0, 'SF_31': 1.0, 'SF_32': 1.0,  'SF_33': 1.0, 'SF_34': 1.0, 'SF_35': 1.0, 'SF_36': 1.0, 'SF_37': 1.0, 'SF_38': 1.0, 'SF_39': 1.0,\n",
    "    'SF_49': 1.0, 'SF_50': 1.0, 'SF_51': 1.0, 'SF_52': 1.0, 'SF_53': 1.0, 'SF_54': 1.0, 'SF_55': 1.0, 'SF_56': 1.0, 'SF_57': 1.0, 'SF_58': 1.0, 'SF_59': 1.0, 'SF_60': 1.0, 'SF_61': 1.0, 'SF_62': 1.0,\n",
    "    'Emin': 5.0, 'Ealpha': 5000\n",
    "}\n",
    "\n",
    "params_default_dict = {\n",
    "    'A_d': 0.02634, 'B_d': 7.67e-4, 'E_d': 10.75, \n",
    "    'SF_30': 1.0, 'SF_31': 1.0, 'SF_32': 1e-2,  'SF_33': 1e-1, 'SF_34': 1e-1, 'SF_35': 1e-2, 'SF_36': 1e-1, 'SF_37': 1e-1, 'SF_38': 1e-1, 'SF_39': 1e-1,\n",
    "    'SF_49': 1e-2, 'SF_50': 1.0, 'SF_51': 1.0, 'SF_52': 1.0, 'SF_53': 1e-1, 'SF_54': 1e-1, 'SF_55': 1.0, 'SF_56': 1.0, 'SF_57': 1.0, 'SF_58': 1e-1, 'SF_59': 1e-1, 'SF_60': 1e-2, 'SF_61': 1e-1, 'SF_62': 1e-1,\n",
    "    'Emin': 3.4, 'Ealpha': 3000\n",
    "}\n",
    "\n",
    "lower_bounds = np.array(list(lower_bounds_dict.values()))\n",
    "upper_bounds = np.array(list(upper_bounds_dict.values()))\n",
    "params_default_init = np.array(list(params_default_dict.values()))\n",
    "params_default_norm = (params_default_init - lower_bounds) * np.reciprocal(upper_bounds - lower_bounds)\n",
    "\n",
    "\n",
    "def func_optimization(params_input, flag='numpy'):\n",
    "    \n",
    "    ##! normalize variables\n",
    "    params = [0] * len(params_input)\n",
    "    for idx, param in enumerate(params_input):\n",
    "        params[idx] = lower_bounds[idx] + (upper_bounds[idx] - lower_bounds[idx]) * param\n",
    "    \n",
    "    A_d, B_d, E_d = params[0:3]\n",
    "    SF_30, SF_31, SF_32, SF_33, SF_34, SF_35, SF_36, SF_37, SF_38, SF_39 = params[3:13]\n",
    "    SF_49, SF_50, SF_51, SF_52, SF_53, SF_54, SF_55, SF_56, SF_57, SF_58, SF_59, SF_60, SF_61, SF_62 = params[13:27]\n",
    "    Emin, Ealpha = params[27:]\n",
    "    \n",
    "    if flag=='numpy':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * np.exp(E_d/(const_dict['R'] * T)))\n",
    "    elif flag=='torch':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * torch.exp(E_d/(const_dict['R'] * T)))\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "    \n",
    "    dict_mod_vec = [\n",
    "    {\"id\": 2, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 10, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 16, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    {\"id\": 18, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    \n",
    "    {\"id\": 31, \"rate\": None, \"model_dict\": {\"SF\": SF_31, \"nu_d\": nu_d_mod}},\n",
    "    \n",
    "    {\"id\": 30, \"rate\": None, \"model_dict\": {\"SF\": SF_30}},\n",
    "    {\"id\": 32, \"rate\": None, \"model_dict\": {\"SF\": SF_32}},\n",
    "    {\"id\": 33, \"rate\": None, \"model_dict\": {\"SF\": SF_33}},\n",
    "    {\"id\": 34, \"rate\": None, \"model_dict\": {\"SF\": SF_34}},\n",
    "    \n",
    "    {\"id\": 35, \"rate\": None, \"model_dict\": {\"SF\": SF_35}},\n",
    "    {\"id\": 36, \"rate\": None, \"model_dict\": {\"SF\": SF_36}},\n",
    "    {\"id\": 37, \"rate\": None, \"model_dict\": {\"SF\": SF_37}},\n",
    "    {\"id\": 38, \"rate\": None, \"model_dict\": {\"SF\": SF_38}},\n",
    "    {\"id\": 39, \"rate\": None, \"model_dict\": {\"SF\": SF_39}},\n",
    "    \n",
    "    {\"id\": 44, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    \n",
    "    {\"id\": 49, \"rate\": None, \"model_dict\": {\"SF\": SF_49}},\n",
    "    {\"id\": 50, \"rate\": None, \"model_dict\": {\"SF\": SF_50, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 51, \"rate\": None, \"model_dict\": {\"SF\": SF_51, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 52, \"rate\": None, \"model_dict\": {\"SF\": SF_52, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 53, \"rate\": None, \"model_dict\": {\"SF\": SF_53, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 54, \"rate\": None, \"model_dict\": {\"SF\": SF_54, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 55, \"rate\": None, \"model_dict\": {\"SF\": SF_55, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 56, \"rate\": None, \"model_dict\": {\"SF\": SF_56, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 57, \"rate\": None, \"model_dict\": {\"SF\": SF_57, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 58, \"rate\": None, \"model_dict\": {\"SF\": SF_58, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 59, \"rate\": None, \"model_dict\": {\"SF\": SF_59, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 60, \"rate\": None, \"model_dict\": {\"SF\": SF_60}},\n",
    "    {\"id\": 61, \"rate\": None, \"model_dict\": {\"SF\": SF_61}},\n",
    "    {\"id\": 62, \"rate\": None, \"model_dict\": {\"SF\": SF_62}}\n",
    "    ]\n",
    "    \n",
    "    return dict_mod_vec\n",
    "\n",
    "def loss_function(exp, teo, flag='numpy'):\n",
    "    func = ((teo-exp)**2)/(exp**2)\n",
    "    if flag == 'numpy':\n",
    "        return np.mean(func)\n",
    "    elif flag == 'torch':\n",
    "        return torch.mean(func)\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "\n",
    "\n",
    "# 4. Instantiate and Run Optimizer\n",
    "optimizer = opt.Optimizer(sim, \n",
    "                        lambda params: func_optimization(params, 'numpy'), \n",
    "                        lambda exp, teo: loss_function(exp, teo, 'numpy')\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pipeline with 5 steps...\n",
      "\n",
      "==================== CYCLE 1 ====================\n",
      "loss:  783.7419346722897 iter:  1\n",
      "\n",
      "[Step] Stochastic Decomposition (k=18)\n",
      "loss:  783.7419346722897 iter:  2\n",
      "loss:  783.6726338875525 iter:  3\n",
      "loss:  783.7755353952942 iter:  4\n",
      "loss:  783.6947982268321 iter:  5\n",
      "loss:  783.6819223388482 iter:  6\n",
      "loss:  783.8125782868298 iter:  7\n",
      "loss:  783.7012338606789 iter:  8\n",
      "loss:  783.8640711599718 iter:  9\n",
      "loss:  783.6881913320784 iter:  10\n",
      "loss:  783.6308763326184 iter:  11\n",
      "loss:  783.8874710803897 iter:  12\n",
      "loss:  783.6701100530283 iter:  13\n",
      "loss:  783.6682873495741 iter:  14\n",
      "loss:  783.7075884591732 iter:  15\n",
      "loss:  783.7660036097889 iter:  16\n",
      "loss:  783.6812442472258 iter:  17\n",
      "loss:  783.8650933446237 iter:  18\n",
      "loss:  783.7798783919552 iter:  19\n",
      "loss:  783.7249369410641 iter:  20\n",
      "  -> Split: Stiff=1, Sloppy=4\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  783.7419346722897 iter:  21\n",
      "loss:  16516.072569440486 iter:  22\n",
      "loss:  0.37679242215402853 iter:  23\n",
      "loss:  0.5733292712944095 iter:  24\n",
      "loss:  0.579449146263075 iter:  25\n",
      "loss:  47.48868719861976 iter:  26\n",
      "loss:  0.1223529162332322 iter:  27\n",
      "loss:  1.0441129658679078 iter:  28\n",
      "loss:  0.1950208665524012 iter:  29\n",
      "loss:  0.19790572786297334 iter:  30\n",
      "loss:  0.12557671789561795 iter:  31\n",
      "loss:  0.12250510121649744 iter:  32\n",
      "loss:  0.12225382576326461 iter:  33\n",
      "loss:  0.12225266242985988 iter:  34\n",
      "loss:  0.12225272958394097 iter:  35\n",
      "loss:  0.12225287538933122 iter:  36\n",
      "loss:  0.5700838125673909 iter:  37\n",
      "loss:  16516.072569440486 iter:  38\n",
      "loss:  0.37679242215402853 iter:  39\n",
      "loss:  0.5733292712944095 iter:  40\n",
      "loss:  0.579449146263075 iter:  41\n",
      "loss:  47.488687198515656 iter:  42\n",
      "loss:  0.1223529162332322 iter:  43\n",
      "loss:  1.0441129658630488 iter:  44\n",
      "loss:  0.19502086655232237 iter:  45\n",
      "loss:  0.19790572786297334 iter:  46\n",
      "loss:  0.12557671789636266 iter:  47\n",
      "loss:  0.12250510121640142 iter:  48\n",
      "loss:  0.12225382576337956 iter:  49\n",
      "loss:  0.12225266242743184 iter:  50\n",
      "loss:  0.12225265301849074 iter:  51\n",
      "loss:  0.12225265984259398 iter:  52\n",
      "loss:  16516.07256914523 iter:  53\n",
      "loss:  0.37679242215402853 iter:  54\n",
      "loss:  0.5733292712944095 iter:  55\n",
      "loss:  0.5794491462623816 iter:  56\n",
      "loss:  47.48868719861976 iter:  57\n",
      "loss:  0.1223529162331527 iter:  58\n",
      "loss:  1.0441129658630488 iter:  59\n",
      "loss:  0.19502086655232237 iter:  60\n",
      "loss:  0.19790572786297334 iter:  61\n",
      "loss:  0.12557671789379876 iter:  62\n",
      "loss:  0.12250510121413581 iter:  63\n",
      "loss:  0.12225382576243035 iter:  64\n",
      "loss:  0.12225266242969567 iter:  65\n",
      "loss:  0.12225265301925338 iter:  66\n",
      "loss:  0.12225265296127617 iter:  67\n",
      "loss:  0.12225265296080404 iter:  68\n",
      "loss:  0.12225265434563967 iter:  69\n",
      "loss:  0.12225265298291355 iter:  70\n",
      "loss:  0.12225265296375558 iter:  71\n",
      "loss:  0.12225265296122985 iter:  72\n",
      "loss:  0.12225265296191234 iter:  73\n",
      "loss:  0.12225265296120047 iter:  74\n",
      "loss:  0.12225265296098971 iter:  75\n",
      "loss:  0.12225265296163168 iter:  76\n",
      "loss:  0.12225265296001925 iter:  77\n",
      "loss:  0.1222526529606455 iter:  78\n",
      "  -> Loss: 0.122253 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.12225265296001925 iter:  79\n",
      "loss:  0.12223488222588211 iter:  80\n",
      "loss:  0.12221358438534821 iter:  81\n",
      "loss:  0.12225151395674744 iter:  82\n",
      "loss:  0.12225141088916246 iter:  83\n",
      "  -> Realigned. Top Eigenvals: [7.29624867e+04 4.69779985e+03 1.30074029e+01]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:4\n",
      "loss:  0.12225265296001925 iter:  84\n",
      "loss:  0.12331638336120299 iter:  85\n",
      "loss:  0.12241300735509265 iter:  86\n",
      "loss:  0.12223971941079961 iter:  87\n",
      "loss:  0.12224338092913557 iter:  88\n",
      "loss:  0.12126422353537901 iter:  89\n",
      "loss:  0.12025129418093514 iter:  90\n",
      "loss:  0.12107111651304492 iter:  91\n",
      "loss:  0.12064578237696869 iter:  92\n",
      "loss:  0.11986511573663318 iter:  93\n",
      "loss:  0.11870743146452288 iter:  94\n",
      "loss:  0.11812374122125231 iter:  95\n",
      "loss:  0.11625535732883417 iter:  96\n",
      "loss:  0.11694172949380176 iter:  97\n",
      "loss:  0.11560373911188755 iter:  98\n",
      "loss:  0.11352036742292151 iter:  99\n",
      "loss:  0.11295751007414903 iter:  100\n",
      "loss:  0.11102331974739332 iter:  101\n",
      "loss:  0.11115551558437785 iter:  102\n",
      "loss:  0.111112785240673 iter:  103\n",
      "loss:  0.11717430659678085 iter:  104\n",
      "loss:  0.11318093158335037 iter:  105\n",
      "loss:  0.1117288885550785 iter:  106\n",
      "loss:  0.11804665908989563 iter:  107\n",
      "loss:  0.11147905036684735 iter:  108\n",
      "loss:  0.11253463570147607 iter:  109\n",
      "loss:  0.11098423751248815 iter:  110\n",
      "loss:  0.11180285463550213 iter:  111\n",
      "loss:  0.11107550069360608 iter:  112\n",
      "loss:  0.1109270683424383 iter:  113\n",
      "loss:  0.11126785836532256 iter:  114\n",
      "loss:  0.11105696788317104 iter:  115\n",
      "loss:  0.11092066658760112 iter:  116\n",
      "loss:  0.1113102111631162 iter:  117\n",
      "loss:  0.11160332803565826 iter:  118\n",
      "loss:  0.11087629353504841 iter:  119\n",
      "loss:  0.11139620531394334 iter:  120\n",
      "loss:  0.11088223249250784 iter:  121\n",
      "loss:  0.11077646875361577 iter:  122\n",
      "loss:  0.1107700769064084 iter:  123\n",
      "loss:  0.11099480041392298 iter:  124\n",
      "loss:  0.11082867645589213 iter:  125\n",
      "loss:  0.11102498791667756 iter:  126\n",
      "loss:  0.11082474561612901 iter:  127\n",
      "loss:  0.11071120333330131 iter:  128\n",
      "loss:  0.11063184334490796 iter:  129\n",
      "loss:  0.11066889309026015 iter:  130\n",
      "loss:  0.11059860208644087 iter:  131\n",
      "loss:  0.11053712131782092 iter:  132\n",
      "loss:  0.11048455255438568 iter:  133\n",
      "loss:  0.11042267056647687 iter:  134\n",
      "loss:  0.1102925419333103 iter:  135\n",
      "loss:  0.11013437991349966 iter:  136\n",
      "loss:  0.11027766783168427 iter:  137\n",
      "loss:  0.11011002228801697 iter:  138\n",
      "loss:  0.11010094193759809 iter:  139\n",
      "loss:  0.10980691732504526 iter:  140\n",
      "loss:  0.10960060694757144 iter:  141\n",
      "loss:  0.10944760930189419 iter:  142\n",
      "loss:  0.10911967257784541 iter:  143\n",
      "loss:  0.10909126282512507 iter:  144\n",
      "loss:  0.10882822918322259 iter:  145\n",
      "loss:  0.109944089945006 iter:  146\n",
      "loss:  0.10888946720036634 iter:  147\n",
      "loss:  0.10923291333022814 iter:  148\n",
      "loss:  0.10883207894114694 iter:  149\n",
      "loss:  0.10936624392387573 iter:  150\n",
      "loss:  0.10884647306889003 iter:  151\n",
      "loss:  0.10891333830577855 iter:  152\n",
      "loss:  0.108735328376341 iter:  153\n",
      "loss:  0.10909375370468205 iter:  154\n",
      "loss:  0.1087371207249796 iter:  155\n",
      "loss:  0.10891346785623891 iter:  156\n",
      "loss:  0.10873227700536293 iter:  157\n",
      "loss:  0.10897512063019939 iter:  158\n",
      "loss:  0.10871997891746327 iter:  159\n",
      "loss:  0.10884613468606814 iter:  160\n",
      "loss:  0.10873528875904799 iter:  161\n",
      "loss:  0.10876747872968187 iter:  162\n",
      "loss:  0.10871016902140865 iter:  163\n",
      "loss:  0.10878693721152453 iter:  164\n",
      "loss:  0.10870808255556887 iter:  165\n",
      "loss:  0.10873754878958823 iter:  166\n",
      "loss:  0.10871220155725453 iter:  167\n",
      "loss:  0.10874671879191844 iter:  168\n",
      "loss:  0.1087096964304925 iter:  169\n",
      "loss:  0.10873480933458587 iter:  170\n",
      "loss:  0.1087066785050797 iter:  171\n",
      "loss:  0.10870800382667878 iter:  172\n",
      "loss:  0.10872972784445573 iter:  173\n",
      "loss:  0.10870390642025472 iter:  174\n",
      "loss:  0.10872547656568009 iter:  175\n",
      "loss:  0.10870433268543964 iter:  176\n",
      "loss:  0.10870332872148787 iter:  177\n",
      "loss:  0.10870612321097856 iter:  178\n",
      "loss:  0.10871008085395673 iter:  179\n",
      "loss:  0.10870441293380675 iter:  180\n",
      "loss:  0.10870150816024625 iter:  181\n",
      "loss:  0.10870226928819307 iter:  182\n",
      "loss:  0.10870621911028891 iter:  183\n",
      "loss:  0.10870279664281503 iter:  184\n",
      "loss:  0.10870118593891417 iter:  185\n",
      "loss:  0.10870139131620032 iter:  186\n",
      "loss:  0.10870166468104768 iter:  187\n",
      "loss:  0.10870036796716966 iter:  188\n",
      "loss:  0.10870112977192554 iter:  189\n",
      "loss:  0.1086997206100431 iter:  190\n",
      "loss:  0.10870044970837746 iter:  191\n",
      "loss:  0.1087052811981694 iter:  192\n",
      "loss:  0.10870030489571045 iter:  193\n",
      "loss:  0.10869895791875982 iter:  194\n",
      "loss:  0.10869823510228278 iter:  195\n",
      "loss:  0.10869739934266881 iter:  196\n",
      "loss:  0.1086958286424539 iter:  197\n",
      "loss:  0.10869645755097039 iter:  198\n",
      "loss:  0.10869459557297101 iter:  199\n",
      "loss:  0.10869285468254941 iter:  200\n",
      "loss:  0.10869115515844781 iter:  201\n",
      "loss:  0.10868781057235141 iter:  202\n",
      "loss:  0.10868825035021143 iter:  203\n",
      "loss:  0.10868516254109378 iter:  204\n",
      "loss:  0.10868099374542031 iter:  205\n",
      "loss:  0.10867903800060705 iter:  206\n",
      "loss:  0.1086736841701235 iter:  207\n",
      "loss:  0.10867052959272022 iter:  208\n",
      "loss:  0.10866158625486205 iter:  209\n",
      "loss:  0.10867243408775923 iter:  210\n",
      "loss:  0.10865849602314649 iter:  211\n",
      "loss:  0.10865201880460963 iter:  212\n",
      "loss:  0.10864965724425422 iter:  213\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.108650\n",
      "\n",
      "==================== CYCLE 2 ====================\n",
      "\n",
      "[Step] Stochastic Decomposition (k=18)\n",
      "loss:  0.10864965724425422 iter:  214\n",
      "loss:  0.10864920273453228 iter:  215\n",
      "loss:  0.10864998098462525 iter:  216\n",
      "loss:  0.10864944015234078 iter:  217\n",
      "loss:  0.10864979498179946 iter:  218\n",
      "loss:  0.10864978482118635 iter:  219\n",
      "loss:  0.10864907768815857 iter:  220\n",
      "loss:  0.10864981099953679 iter:  221\n",
      "loss:  0.10864849426185737 iter:  222\n",
      "loss:  0.10865018738197837 iter:  223\n",
      "loss:  0.10864982909796152 iter:  224\n",
      "loss:  0.10864932037793279 iter:  225\n",
      "loss:  0.10864952336920454 iter:  226\n",
      "loss:  0.10864779163417307 iter:  227\n",
      "loss:  0.10864912979377236 iter:  228\n",
      "loss:  0.10864977370121412 iter:  229\n",
      "loss:  0.10864943172551905 iter:  230\n",
      "loss:  0.10864884267889616 iter:  231\n",
      "loss:  0.10864995342153902 iter:  232\n",
      "  -> Split: Stiff=1, Sloppy=5\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.10864965724425422 iter:  233\n",
      "loss:  0.26022613244517206 iter:  234\n",
      "loss:  0.24409387693331258 iter:  235\n",
      "loss:  0.24483321025977212 iter:  236\n",
      "loss:  0.24573591855387145 iter:  237\n",
      "loss:  0.21892011034176823 iter:  238\n",
      "loss:  0.22068645035058054 iter:  239\n",
      "loss:  0.17022245984035742 iter:  240\n",
      "loss:  0.10930491293182464 iter:  241\n",
      "loss:  0.1676160672161931 iter:  242\n",
      "loss:  0.30237601902873124 iter:  243\n",
      "loss:  0.1369488565334229 iter:  244\n",
      "loss:  0.11870493553520715 iter:  245\n",
      "loss:  0.11215979262754404 iter:  246\n",
      "loss:  0.10896556077210917 iter:  247\n",
      "loss:  0.10867721504086492 iter:  248\n",
      "loss:  0.10890639909728085 iter:  249\n",
      "loss:  0.10864432450785316 iter:  250\n",
      "loss:  0.1086439791913268 iter:  251\n",
      "loss:  0.10864834427940148 iter:  252\n",
      "  -> Loss: 0.108644 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.1086439791913268 iter:  253\n",
      "loss:  0.10864360123017278 iter:  254\n",
      "loss:  0.10864539175409332 iter:  255\n",
      "loss:  0.10864438058748165 iter:  256\n",
      "loss:  0.10864370200828546 iter:  257\n",
      "loss:  0.10864403301138396 iter:  258\n",
      "  -> Realigned. Top Eigenvals: [14570.39576963    38.71462993    20.72607811]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:5\n",
      "loss:  0.1086439791913268 iter:  259\n",
      "loss:  0.10863947768142711 iter:  260\n",
      "loss:  0.10867910411831241 iter:  261\n",
      "loss:  0.10865381624000696 iter:  262\n",
      "loss:  0.10863705974714179 iter:  263\n",
      "loss:  0.10864264557843534 iter:  264\n",
      "loss:  0.10860603282283338 iter:  265\n",
      "loss:  0.10856945738934123 iter:  266\n",
      "loss:  0.10859888607720276 iter:  267\n",
      "loss:  0.1085917908980926 iter:  268\n",
      "loss:  0.108575028783522 iter:  269\n",
      "loss:  0.10854858236471988 iter:  270\n",
      "loss:  0.10850413443605357 iter:  271\n",
      "loss:  0.10850102423825021 iter:  272\n",
      "loss:  0.10843843911050474 iter:  273\n",
      "loss:  0.10846847958913877 iter:  274\n",
      "loss:  0.10842443719334888 iter:  275\n",
      "loss:  0.10833767723803862 iter:  276\n",
      "loss:  0.10834474709939354 iter:  277\n",
      "loss:  0.10826309015498069 iter:  278\n",
      "loss:  0.10810644876980627 iter:  279\n",
      "loss:  0.10818942689389223 iter:  280\n",
      "loss:  0.10808988545928801 iter:  281\n",
      "loss:  0.10788950801417183 iter:  282\n",
      "loss:  0.10788571195101145 iter:  283\n",
      "loss:  0.10756999635291019 iter:  284\n",
      "loss:  0.1077020602710489 iter:  285\n",
      "loss:  0.10741693803293825 iter:  286\n",
      "loss:  0.10731440340029512 iter:  287\n",
      "loss:  0.1071136507820194 iter:  288\n",
      "loss:  0.10733789277078166 iter:  289\n",
      "loss:  0.10742682010728528 iter:  290\n",
      "loss:  0.10745792079364623 iter:  291\n",
      "loss:  0.10755267884148267 iter:  292\n",
      "loss:  0.10777614180673917 iter:  293\n",
      "loss:  0.10714038966443229 iter:  294\n",
      "loss:  0.10752899455352573 iter:  295\n",
      "loss:  0.10716866287953095 iter:  296\n",
      "loss:  0.10752047115071854 iter:  297\n",
      "loss:  0.10735097280994539 iter:  298\n",
      "loss:  0.10729054463494272 iter:  299\n",
      "loss:  0.10749523742636329 iter:  300\n",
      "loss:  0.10724622013248829 iter:  301\n",
      "loss:  0.10730894726590531 iter:  302\n",
      "loss:  0.10719474784584786 iter:  303\n",
      "loss:  0.10728231353887016 iter:  304\n",
      "loss:  0.10720791711941421 iter:  305\n",
      "loss:  0.10729198018546732 iter:  306\n",
      "loss:  0.1071845361746388 iter:  307\n",
      "loss:  0.10722067742825606 iter:  308\n",
      "loss:  0.10716261441325424 iter:  309\n",
      "loss:  0.10726332535157357 iter:  310\n",
      "loss:  0.10712119185582615 iter:  311\n",
      "loss:  0.10718455215649504 iter:  312\n",
      "loss:  0.10715422140063162 iter:  313\n",
      "loss:  0.10714769541439766 iter:  314\n",
      "loss:  0.10709348779738562 iter:  315\n",
      "loss:  0.10707535433550253 iter:  316\n",
      "loss:  0.10706771326193384 iter:  317\n",
      "loss:  0.10709576364298393 iter:  318\n",
      "loss:  0.10720225391745138 iter:  319\n",
      "loss:  0.1071204667234956 iter:  320\n",
      "loss:  0.10703770342981339 iter:  321\n",
      "loss:  0.10701515320805902 iter:  322\n",
      "loss:  0.10705848850018426 iter:  323\n",
      "loss:  0.10704330874137781 iter:  324\n",
      "loss:  0.10706136287008138 iter:  325\n",
      "loss:  0.10698091181054686 iter:  326\n",
      "loss:  0.10693907770847634 iter:  327\n",
      "loss:  0.10693718906911172 iter:  328\n",
      "loss:  0.10687921906597919 iter:  329\n",
      "loss:  0.10695232693364641 iter:  330\n",
      "loss:  0.10694408862817312 iter:  331\n",
      "loss:  0.1068239944102184 iter:  332\n",
      "loss:  0.1067549908229851 iter:  333\n",
      "loss:  0.10674697803703269 iter:  334\n",
      "loss:  0.10666370852162413 iter:  335\n",
      "loss:  0.10681791491353579 iter:  336\n",
      "loss:  0.1067422197681903 iter:  337\n",
      "loss:  0.10660009107600076 iter:  338\n",
      "loss:  0.10652527171306839 iter:  339\n",
      "loss:  0.10658211038886538 iter:  340\n",
      "loss:  0.106581704393454 iter:  341\n",
      "loss:  0.10660290366105221 iter:  342\n",
      "loss:  0.106494378660264 iter:  343\n",
      "loss:  0.10652814522159547 iter:  344\n",
      "loss:  0.10665289424438881 iter:  345\n",
      "loss:  0.10656856252433035 iter:  346\n",
      "loss:  0.10648045489052274 iter:  347\n",
      "loss:  0.10644458936293108 iter:  348\n",
      "loss:  0.10642218578191771 iter:  349\n",
      "loss:  0.10634777676520192 iter:  350\n",
      "loss:  0.10645815965414754 iter:  351\n",
      "loss:  0.10633098501663439 iter:  352\n",
      "loss:  0.10630797454784874 iter:  353\n",
      "loss:  0.10619963994728081 iter:  354\n",
      "loss:  0.10605201321161076 iter:  355\n",
      "loss:  0.10607137197506522 iter:  356\n",
      "loss:  0.10617759913111051 iter:  357\n",
      "loss:  0.10585461405417003 iter:  358\n",
      "loss:  0.10557438901038324 iter:  359\n",
      "loss:  0.10576190570466998 iter:  360\n",
      "loss:  0.10556405211364948 iter:  361\n",
      "loss:  0.10525633633816739 iter:  362\n",
      "loss:  0.10542300650809627 iter:  363\n",
      "loss:  0.10512339978311408 iter:  364\n",
      "loss:  0.10473221663089159 iter:  365\n",
      "loss:  0.10452472641451488 iter:  366\n",
      "loss:  0.10376110537015712 iter:  367\n",
      "loss:  0.10456890138815668 iter:  368\n",
      "loss:  0.1039396285591253 iter:  369\n",
      "loss:  0.10337120712755316 iter:  370\n",
      "loss:  0.1023498186751391 iter:  371\n",
      "loss:  0.10267872162729894 iter:  372\n",
      "loss:  0.10210109955070269 iter:  373\n",
      "loss:  0.10084085510597622 iter:  374\n",
      "loss:  0.1007646136698622 iter:  375\n",
      "loss:  0.09890919111633165 iter:  376\n",
      "loss:  0.0993341120309633 iter:  377\n",
      "loss:  0.09841670913669821 iter:  378\n",
      "loss:  0.09612647894177057 iter:  379\n",
      "loss:  0.09600896636763534 iter:  380\n",
      "loss:  0.09342047634953149 iter:  381\n",
      "loss:  0.09347114787539357 iter:  382\n",
      "loss:  0.09262640219184227 iter:  383\n",
      "loss:  0.09365786770445197 iter:  384\n",
      "loss:  0.09348903055537094 iter:  385\n",
      "loss:  0.10030389360581143 iter:  386\n",
      "loss:  0.09544240874349733 iter:  387\n",
      "loss:  0.09166017496797767 iter:  388\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.091660\n",
      "  -> Conv Check: dS=9.7e-01, dPhi=2.0e-01, dLoss=1.7e-02\n",
      "\n",
      "==================== CYCLE 3 ====================\n",
      "\n",
      "[Step] Stochastic Decomposition (k=18)\n",
      "loss:  0.09166017496797767 iter:  389\n",
      "loss:  0.09164477456193627 iter:  390\n",
      "loss:  0.09168375134306614 iter:  391\n",
      "loss:  0.09166164625855927 iter:  392\n",
      "loss:  0.0916601132784679 iter:  393\n",
      "loss:  0.09168461428986796 iter:  394\n",
      "loss:  0.09163867350785734 iter:  395\n",
      "loss:  0.09168223433657847 iter:  396\n",
      "loss:  0.09164911462871225 iter:  397\n",
      "loss:  0.09165965410037516 iter:  398\n",
      "loss:  0.09163594198456156 iter:  399\n",
      "loss:  0.0916478148469665 iter:  400\n",
      "loss:  0.09166939291496239 iter:  401\n",
      "loss:  0.09166825945754759 iter:  402\n",
      "loss:  0.09167031320778676 iter:  403\n",
      "loss:  0.0916460135606228 iter:  404\n",
      "loss:  0.09164921922967939 iter:  405\n",
      "loss:  0.09169600794249586 iter:  406\n",
      "loss:  0.09165748974170597 iter:  407\n",
      "  -> Split: Stiff=1, Sloppy=5\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.09166017496797767 iter:  408\n",
      "loss:  0.30437657238825266 iter:  409\n",
      "loss:  0.23197715422137566 iter:  410\n",
      "loss:  0.256210027561399 iter:  411\n",
      "loss:  0.23285698363225044 iter:  412\n",
      "loss:  0.21648369903100664 iter:  413\n",
      "loss:  0.2357886253872606 iter:  414\n",
      "loss:  0.2213503039014729 iter:  415\n",
      "loss:  0.1746799241610078 iter:  416\n",
      "loss:  0.1591290658409241 iter:  417\n",
      "loss:  0.20700387480738355 iter:  418\n",
      "loss:  0.10388024677070268 iter:  419\n",
      "loss:  0.08829739941628077 iter:  420\n",
      "loss:  0.13457698381685806 iter:  421\n",
      "loss:  0.08825198211394335 iter:  422\n",
      "loss:  0.0881959105351181 iter:  423\n",
      "loss:  0.08815950478927802 iter:  424\n",
      "loss:  0.08816618566722448 iter:  425\n",
      "loss:  0.09692356793873519 iter:  426\n",
      "loss:  0.3043765723882857 iter:  427\n",
      "loss:  0.23197715422481843 iter:  428\n",
      "loss:  0.2562100275636253 iter:  429\n",
      "loss:  0.2328569836303584 iter:  430\n",
      "loss:  0.21648369903160522 iter:  431\n",
      "loss:  0.23578862538655151 iter:  432\n",
      "loss:  0.22135030390137686 iter:  433\n",
      "loss:  0.17467992416179415 iter:  434\n",
      "loss:  0.15912906584089856 iter:  435\n",
      "loss:  0.20700387480689142 iter:  436\n",
      "loss:  0.10388024676097184 iter:  437\n",
      "loss:  0.08829739941775962 iter:  438\n",
      "loss:  0.1345769838188217 iter:  439\n",
      "loss:  0.08825198211234994 iter:  440\n",
      "loss:  0.08819591054092624 iter:  441\n",
      "loss:  0.08815950478908244 iter:  442\n",
      "loss:  0.08816618566100479 iter:  443\n",
      "  -> Loss: 0.088160 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.08815950478908244 iter:  444\n",
      "loss:  0.08815933671867754 iter:  445\n",
      "loss:  0.08815756928020976 iter:  446\n",
      "loss:  0.08815973406647812 iter:  447\n",
      "loss:  0.08815949472461206 iter:  448\n",
      "loss:  0.0881592089577115 iter:  449\n",
      "  -> Realigned. Top Eigenvals: [27280.65534154   237.84746007    47.1930445 ]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:5\n",
      "loss:  0.08815950478908244 iter:  450\n",
      "loss:  0.08817408960210657 iter:  451\n",
      "loss:  0.08811376420517401 iter:  452\n",
      "loss:  0.08814901879979752 iter:  453\n",
      "loss:  0.0881464281182535 iter:  454\n",
      "loss:  0.08815186655482413 iter:  455\n",
      "loss:  0.08813287893151614 iter:  456\n",
      "loss:  0.08811587497607493 iter:  457\n",
      "loss:  0.08810973440695612 iter:  458\n",
      "loss:  0.08809052883565853 iter:  459\n",
      "loss:  0.08809105884735322 iter:  460\n",
      "loss:  0.08807595152368462 iter:  461\n",
      "loss:  0.08805156718183 iter:  462\n",
      "loss:  0.0880455337744315 iter:  463\n",
      "loss:  0.08800260614615436 iter:  464\n",
      "loss:  0.08801934636279025 iter:  465\n",
      "loss:  0.08800337297425412 iter:  466\n",
      "loss:  0.08797128828739721 iter:  467\n",
      "loss:  0.08791522624614333 iter:  468\n",
      "loss:  0.08790723842437961 iter:  469\n",
      "loss:  0.08782850646983884 iter:  470\n",
      "loss:  0.08784065978031261 iter:  471\n",
      "loss:  0.08781046340332845 iter:  472\n",
      "loss:  0.0877150766336489 iter:  473\n",
      "loss:  0.08769997907900362 iter:  474\n",
      "loss:  0.08754673423659644 iter:  475\n",
      "loss:  0.08759506476233671 iter:  476\n",
      "loss:  0.08748422957882061 iter:  477\n",
      "loss:  0.08727707922006096 iter:  478\n",
      "loss:  0.08738289554431239 iter:  479\n",
      "loss:  0.08715782027753202 iter:  480\n",
      "loss:  0.08682465802154352 iter:  481\n",
      "loss:  0.08692950859116816 iter:  482\n",
      "loss:  0.08675791615381843 iter:  483\n",
      "loss:  0.08632842002269367 iter:  484\n",
      "loss:  0.08651692974020764 iter:  485\n",
      "loss:  0.08611029439613924 iter:  486\n",
      "loss:  0.08552323972274516 iter:  487\n",
      "loss:  0.08556215629219087 iter:  488\n",
      "loss:  0.08554106719676677 iter:  489\n",
      "loss:  0.08541398254388746 iter:  490\n",
      "loss:  0.08541806490978937 iter:  491\n",
      "loss:  0.08503969749419535 iter:  492\n",
      "loss:  0.08454441981614012 iter:  493\n",
      "loss:  0.08530657949557031 iter:  494\n",
      "loss:  0.0848470641729299 iter:  495\n",
      "loss:  0.08458624959003701 iter:  496\n",
      "loss:  0.08443476556604844 iter:  497\n",
      "loss:  0.08524291482244749 iter:  498\n",
      "loss:  0.08378269285653918 iter:  499\n",
      "loss:  0.08290291775698135 iter:  500\n",
      "loss:  0.08325534647876122 iter:  501\n",
      "loss:  0.08283356823221998 iter:  502\n",
      "loss:  0.08186839789044219 iter:  503\n",
      "loss:  0.08194809172360992 iter:  504\n",
      "loss:  0.08438164720251082 iter:  505\n",
      "loss:  0.08097946916714097 iter:  506\n",
      "loss:  0.1409932054350976 iter:  507\n",
      "loss:  0.08327861676500138 iter:  508\n",
      "loss:  0.08251916425548683 iter:  509\n",
      "loss:  0.08188784504259446 iter:  510\n",
      "loss:  0.08084068958168772 iter:  511\n",
      "loss:  0.09267127541169727 iter:  512\n",
      "loss:  0.14649571395918048 iter:  513\n",
      "loss:  0.0816209782079311 iter:  514\n",
      "loss:  0.08414269726432037 iter:  515\n",
      "loss:  0.08138390194869756 iter:  516\n",
      "loss:  0.08167715612466726 iter:  517\n",
      "loss:  0.08084561324923724 iter:  518\n",
      "loss:  0.08404189251047381 iter:  519\n",
      "loss:  0.08117588422362453 iter:  520\n",
      "loss:  0.08235396190653134 iter:  521\n",
      "loss:  0.08111650865222131 iter:  522\n",
      "loss:  0.0812537591655596 iter:  523\n",
      "loss:  0.08080691913321214 iter:  524\n",
      "loss:  0.08288190297613252 iter:  525\n",
      "loss:  0.08086632420280296 iter:  526\n",
      "loss:  0.08248344268395634 iter:  527\n",
      "loss:  0.08082399075172127 iter:  528\n",
      "loss:  0.08098504766130403 iter:  529\n",
      "loss:  0.08077195862659009 iter:  530\n",
      "loss:  0.0811690921550063 iter:  531\n",
      "loss:  0.0807622097659461 iter:  532\n",
      "loss:  0.08083348428783972 iter:  533\n",
      "loss:  0.08088360211640948 iter:  534\n",
      "loss:  0.08074676257202479 iter:  535\n",
      "loss:  0.0808505438905953 iter:  536\n",
      "loss:  0.08075270724959531 iter:  537\n",
      "loss:  0.08099326627683784 iter:  538\n",
      "loss:  0.08075115713591947 iter:  539\n",
      "loss:  0.0808423874977508 iter:  540\n",
      "loss:  0.08074817376324395 iter:  541\n",
      "loss:  0.08074690397817283 iter:  542\n",
      "loss:  0.08075414635267923 iter:  543\n",
      "loss:  0.0807328642258288 iter:  544\n",
      "loss:  0.08074585959864232 iter:  545\n",
      "loss:  0.08076003666826105 iter:  546\n",
      "loss:  0.08073284745890953 iter:  547\n",
      "loss:  0.08072188742315066 iter:  548\n",
      "loss:  0.08073729885739704 iter:  549\n",
      "loss:  0.08076841392008906 iter:  550\n",
      "loss:  0.08072787005909184 iter:  551\n",
      "loss:  0.08076939179548198 iter:  552\n",
      "loss:  0.08072553225710875 iter:  553\n",
      "loss:  0.08075229151787522 iter:  554\n",
      "loss:  0.08072831468619941 iter:  555\n",
      "loss:  0.08074160670383254 iter:  556\n",
      "loss:  0.08072434754979232 iter:  557\n",
      "loss:  0.08071169294367816 iter:  558\n",
      "loss:  0.08070400442782949 iter:  559\n",
      "loss:  0.08071607566616903 iter:  560\n",
      "loss:  0.08072104392464009 iter:  561\n",
      "loss:  0.08070668190267086 iter:  562\n",
      "loss:  0.08069618698284735 iter:  563\n",
      "loss:  0.08068580691666144 iter:  564\n",
      "loss:  0.08070637044555097 iter:  565\n",
      "loss:  0.08068698964791915 iter:  566\n",
      "loss:  0.08066830798221614 iter:  567\n",
      "loss:  0.08064470697698914 iter:  568\n",
      "loss:  0.08065913975586404 iter:  569\n",
      "loss:  0.08066392303363842 iter:  570\n",
      "loss:  0.08063812238223567 iter:  571\n",
      "loss:  0.0806258781877994 iter:  572\n",
      "loss:  0.08060807529279328 iter:  573\n",
      "loss:  0.08056999847971412 iter:  574\n",
      "loss:  0.08056190323315934 iter:  575\n",
      "loss:  0.08050019179258826 iter:  576\n",
      "loss:  0.08054647613221604 iter:  577\n",
      "loss:  0.08049055313069474 iter:  578\n",
      "loss:  0.0804180357981894 iter:  579\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.080418\n",
      "  -> Conv Check: dS=5.1e-01, dPhi=6.0e-02, dLoss=1.1e-02\n",
      "\n",
      "==================== CYCLE 4 ====================\n",
      "\n",
      "[Step] Stochastic Decomposition (k=18)\n",
      "loss:  0.0804180357981894 iter:  580\n",
      "loss:  0.08049553071149494 iter:  581\n",
      "loss:  0.0803826119816379 iter:  582\n",
      "loss:  0.08041488914416328 iter:  583\n",
      "loss:  0.08041108302459178 iter:  584\n",
      "loss:  0.08042824105060216 iter:  585\n",
      "loss:  0.08051318364256949 iter:  586\n",
      "loss:  0.08032264023546626 iter:  587\n",
      "loss:  0.08043235378438747 iter:  588\n",
      "loss:  0.08048128181561193 iter:  589\n",
      "loss:  0.08041826303741247 iter:  590\n",
      "loss:  0.08042415765191153 iter:  591\n",
      "loss:  0.08038400831511051 iter:  592\n",
      "loss:  0.08042557080397265 iter:  593\n",
      "loss:  0.0803993754883775 iter:  594\n",
      "loss:  0.08040617955923567 iter:  595\n",
      "loss:  0.08042455689687845 iter:  596\n",
      "loss:  0.08038981810794148 iter:  597\n",
      "loss:  0.0804147047162371 iter:  598\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.0804180357981894 iter:  599\n",
      "loss:  0.5568235622746455 iter:  600\n",
      "loss:  3.2316417089481257 iter:  601\n",
      "loss:  0.7349961359801133 iter:  602\n",
      "loss:  0.6474213639372265 iter:  603\n",
      "loss:  0.30142502043404445 iter:  604\n",
      "loss:  0.2012056348368415 iter:  605\n",
      "loss:  0.4314762609410302 iter:  606\n",
      "loss:  0.1794873273620733 iter:  607\n",
      "loss:  0.18256170007981182 iter:  608\n",
      "loss:  0.1881491987007285 iter:  609\n",
      "loss:  0.15713437224559101 iter:  610\n",
      "loss:  0.08778621556523378 iter:  611\n",
      "loss:  0.12306131023112313 iter:  612\n",
      "loss:  0.09535867603012914 iter:  613\n",
      "loss:  0.14750134570388948 iter:  614\n",
      "loss:  0.07976247297954721 iter:  615\n",
      "loss:  0.0894686154161834 iter:  616\n",
      "loss:  0.08068299011551915 iter:  617\n",
      "loss:  0.08077812818151121 iter:  618\n",
      "loss:  0.07971994833002327 iter:  619\n",
      "loss:  0.07975449953614691 iter:  620\n",
      "loss:  0.10080098765732264 iter:  621\n",
      "loss:  0.556823562273194 iter:  622\n",
      "loss:  3.2316417089482865 iter:  623\n",
      "loss:  0.7349961359799838 iter:  624\n",
      "loss:  0.6474213639303945 iter:  625\n",
      "loss:  0.30142502043237357 iter:  626\n",
      "loss:  0.2012056348367171 iter:  627\n",
      "loss:  0.43147626094387187 iter:  628\n",
      "loss:  0.17948732735875292 iter:  629\n",
      "loss:  0.18256170007864125 iter:  630\n",
      "loss:  0.18814919870472346 iter:  631\n",
      "loss:  0.15713437224245438 iter:  632\n",
      "loss:  0.0877862155496874 iter:  633\n",
      "loss:  0.12306131023760933 iter:  634\n",
      "loss:  0.09535867602713635 iter:  635\n",
      "loss:  0.1475013455488056 iter:  636\n",
      "loss:  0.07976247297618741 iter:  637\n",
      "loss:  0.08946861545463189 iter:  638\n",
      "loss:  0.08068299011718917 iter:  639\n",
      "loss:  0.08077812819365913 iter:  640\n",
      "loss:  0.07971994832793826 iter:  641\n",
      "loss:  0.0797544994277948 iter:  642\n",
      "  -> Loss: 0.079720 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.07971994832793826 iter:  643\n",
      "loss:  0.07970862247829659 iter:  644\n",
      "loss:  0.07972216128409006 iter:  645\n",
      "loss:  0.07971941101871144 iter:  646\n",
      "loss:  0.07972035114802607 iter:  647\n",
      "loss:  0.079719690374016 iter:  648\n",
      "loss:  0.07971998750032191 iter:  649\n",
      "  -> Realigned. Top Eigenvals: [21484.09884729  4118.39124995   125.72920384]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.07971994832793826 iter:  650\n",
      "loss:  0.08001228348981722 iter:  651\n",
      "loss:  0.07977228079677236 iter:  652\n",
      "loss:  0.07972082481293344 iter:  653\n",
      "loss:  0.07970395058115923 iter:  654\n",
      "loss:  0.07971742533514536 iter:  655\n",
      "loss:  0.07972587705177764 iter:  656\n",
      "loss:  0.0794571341306209 iter:  657\n",
      "loss:  0.07920363102144402 iter:  658\n",
      "loss:  0.07948572825778567 iter:  659\n",
      "loss:  0.07945216385669096 iter:  660\n",
      "loss:  0.07937049458394702 iter:  661\n",
      "loss:  0.07925973255551723 iter:  662\n",
      "loss:  0.07911834260826946 iter:  663\n",
      "loss:  0.07884458962228413 iter:  664\n",
      "loss:  0.07886273673701633 iter:  665\n",
      "loss:  0.07886201055755897 iter:  666\n",
      "loss:  0.07870627836651936 iter:  667\n",
      "loss:  0.07838563750195025 iter:  668\n",
      "loss:  0.07846935861610856 iter:  669\n",
      "loss:  0.07832936752307186 iter:  670\n",
      "loss:  0.07796355354007212 iter:  671\n",
      "loss:  0.07798719155006277 iter:  672\n",
      "loss:  0.07799945847354371 iter:  673\n",
      "loss:  0.0777539177630894 iter:  674\n",
      "loss:  0.07735744479011113 iter:  675\n",
      "loss:  0.07741372015004899 iter:  676\n",
      "loss:  0.07733511461224596 iter:  677\n",
      "loss:  0.07702251557307768 iter:  678\n",
      "loss:  0.07706236013803693 iter:  679\n",
      "loss:  0.07701094432127169 iter:  680\n",
      "loss:  0.07682003561396904 iter:  681\n",
      "loss:  0.07689284604147135 iter:  682\n",
      "loss:  0.07682554950904798 iter:  683\n",
      "loss:  0.0767957338855507 iter:  684\n",
      "loss:  0.07703906141211786 iter:  685\n",
      "loss:  0.07707203226005892 iter:  686\n",
      "loss:  0.07687047069677193 iter:  687\n",
      "loss:  0.07695380990249179 iter:  688\n",
      "loss:  0.0771711274484826 iter:  689\n",
      "loss:  0.07685479290374242 iter:  690\n",
      "loss:  0.07698282286339157 iter:  691\n",
      "loss:  0.07685336125315854 iter:  692\n",
      "loss:  0.07679217762914924 iter:  693\n",
      "loss:  0.07682241096243073 iter:  694\n",
      "loss:  0.07674552748975878 iter:  695\n",
      "loss:  0.07670961375449317 iter:  696\n",
      "loss:  0.07681518218282303 iter:  697\n",
      "loss:  0.07669912592338782 iter:  698\n",
      "loss:  0.07665468626038097 iter:  699\n",
      "loss:  0.07665880530874893 iter:  700\n",
      "loss:  0.07668481488831842 iter:  701\n",
      "loss:  0.07669219230195899 iter:  702\n",
      "loss:  0.0765806476870899 iter:  703\n",
      "loss:  0.07653589205704568 iter:  704\n",
      "loss:  0.07664252195866975 iter:  705\n",
      "loss:  0.07649897579975609 iter:  706\n",
      "loss:  0.07640221251901251 iter:  707\n",
      "loss:  0.07643911769633341 iter:  708\n",
      "loss:  0.07676504922893497 iter:  709\n",
      "loss:  0.07656560645696177 iter:  710\n",
      "loss:  0.07640496917378159 iter:  711\n",
      "loss:  0.07632458346735806 iter:  712\n",
      "loss:  0.07621018596939134 iter:  713\n",
      "loss:  0.0762840285492851 iter:  714\n",
      "loss:  0.07625931987035683 iter:  715\n",
      "loss:  0.07613588738261541 iter:  716\n",
      "loss:  0.0760402363197271 iter:  717\n",
      "loss:  0.07608363315877785 iter:  718\n",
      "loss:  0.07603080766994932 iter:  719\n",
      "loss:  0.07601679340927915 iter:  720\n",
      "loss:  0.07600845160424251 iter:  721\n",
      "loss:  0.07588118902327985 iter:  722\n",
      "loss:  0.07617935363747899 iter:  723\n",
      "loss:  0.07602996747142554 iter:  724\n",
      "loss:  0.07597101992054031 iter:  725\n",
      "loss:  0.07614158789376257 iter:  726\n",
      "loss:  0.07605600795786843 iter:  727\n",
      "loss:  0.07696885541180504 iter:  728\n",
      "loss:  0.07597847073211313 iter:  729\n",
      "loss:  0.07613977785368733 iter:  730\n",
      "loss:  0.07605151631310392 iter:  731\n",
      "loss:  0.07609295755253613 iter:  732\n",
      "loss:  0.07605549233663185 iter:  733\n",
      "loss:  0.07581443231244935 iter:  734\n",
      "loss:  0.07606300007706199 iter:  735\n",
      "loss:  0.07610026193362654 iter:  736\n",
      "loss:  0.07594546612857324 iter:  737\n",
      "loss:  0.07602036756757408 iter:  738\n",
      "loss:  0.07615173801503736 iter:  739\n",
      "loss:  0.07613567766826297 iter:  740\n",
      "loss:  0.07617563688724273 iter:  741\n",
      "loss:  0.07582155926834652 iter:  742\n",
      "loss:  0.07584340860800588 iter:  743\n",
      "loss:  0.07616976926684789 iter:  744\n",
      "loss:  0.0760567201147355 iter:  745\n",
      "loss:  0.07601632134634546 iter:  746\n",
      "loss:  0.07593615009489721 iter:  747\n",
      "loss:  0.0758121290745284 iter:  748\n",
      "loss:  0.07602653855372944 iter:  749\n",
      "loss:  0.0758579426245894 iter:  750\n",
      "loss:  0.07591822746397196 iter:  751\n",
      "loss:  0.0760151864208393 iter:  752\n",
      "loss:  0.07583469649082372 iter:  753\n",
      "loss:  0.07596095915018543 iter:  754\n",
      "loss:  0.07583158750937001 iter:  755\n",
      "loss:  0.07585573514789384 iter:  756\n",
      "loss:  0.07582097283290755 iter:  757\n",
      "loss:  0.0758160445559288 iter:  758\n",
      "loss:  0.07583119806726887 iter:  759\n",
      "loss:  0.07580769833921984 iter:  760\n",
      "loss:  0.07584454881478525 iter:  761\n",
      "loss:  0.07586242175144678 iter:  762\n",
      "loss:  0.07580599906251059 iter:  763\n",
      "loss:  0.07583224575957426 iter:  764\n",
      "loss:  0.07580591901346803 iter:  765\n",
      "loss:  0.07584076965032048 iter:  766\n",
      "loss:  0.07580505321270391 iter:  767\n",
      "loss:  0.07582137164665242 iter:  768\n",
      "loss:  0.07580511156119019 iter:  769\n",
      "loss:  0.07578973391898389 iter:  770\n",
      "loss:  0.07578212599458643 iter:  771\n",
      "loss:  0.07581117972480535 iter:  772\n",
      "loss:  0.07580031293412792 iter:  773\n",
      "loss:  0.07580027723758978 iter:  774\n",
      "loss:  0.07580357102833352 iter:  775\n",
      "loss:  0.07578655356933942 iter:  776\n",
      "loss:  0.07579703677919701 iter:  777\n",
      "loss:  0.07577963325237164 iter:  778\n",
      "loss:  0.07577501942173641 iter:  779\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.075775\n",
      "  -> Conv Check: dS=5.7e-01, dPhi=1.1e-02, dLoss=4.6e-03\n",
      "\n",
      "==================== CYCLE 5 ====================\n",
      "\n",
      "[Step] Stochastic Decomposition (k=18)\n",
      "loss:  0.07577501942173641 iter:  780\n",
      "loss:  0.07577246907357452 iter:  781\n",
      "loss:  0.07579159577216894 iter:  782\n",
      "loss:  0.07578063839579446 iter:  783\n",
      "loss:  0.0757849186375642 iter:  784\n",
      "loss:  0.075794502882393 iter:  785\n",
      "loss:  0.07578095643774978 iter:  786\n",
      "loss:  0.07577974957325115 iter:  787\n",
      "loss:  0.07577576423229279 iter:  788\n",
      "loss:  0.07577663285663148 iter:  789\n",
      "loss:  0.07577216863582703 iter:  790\n",
      "loss:  0.0757758455677898 iter:  791\n",
      "loss:  0.07577773803623365 iter:  792\n",
      "loss:  0.07577456958111366 iter:  793\n",
      "loss:  0.0757690281878463 iter:  794\n",
      "loss:  0.07577850198100927 iter:  795\n",
      "loss:  0.07577726221671388 iter:  796\n",
      "loss:  0.07578323665680906 iter:  797\n",
      "loss:  0.07578059134015737 iter:  798\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.07577501942173641 iter:  799\n",
      "loss:  0.463242514124176 iter:  800\n",
      "loss:  0.35070758361306387 iter:  801\n",
      "loss:  2.7761397759115742 iter:  802\n",
      "loss:  0.20302830592958251 iter:  803\n",
      "loss:  0.2192185195227057 iter:  804\n",
      "loss:  0.32517813275990054 iter:  805\n",
      "loss:  0.10617265767552427 iter:  806\n",
      "loss:  0.2646688735753686 iter:  807\n",
      "loss:  0.21872863394373837 iter:  808\n",
      "loss:  0.07578092503053895 iter:  809\n",
      "loss:  0.16900283495755486 iter:  810\n",
      "loss:  0.09730960398241252 iter:  811\n",
      "loss:  0.1697532755232587 iter:  812\n",
      "loss:  0.08544671538446522 iter:  813\n",
      "loss:  0.0778436972194313 iter:  814\n",
      "loss:  0.07736058015365077 iter:  815\n",
      "loss:  0.07584566148960505 iter:  816\n",
      "loss:  0.07610158351836122 iter:  817\n",
      "  -> Loss: 0.075781 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.07578092503053895 iter:  818\n",
      "loss:  0.07578071583222798 iter:  819\n",
      "loss:  0.07578027133906637 iter:  820\n",
      "loss:  0.07578162883506201 iter:  821\n",
      "loss:  0.07578112476817918 iter:  822\n",
      "loss:  0.07578076539123578 iter:  823\n",
      "loss:  0.07578067245719576 iter:  824\n",
      "  -> Realigned. Top Eigenvals: [24682.32357881 12592.95462385   368.64348767]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.07578092503053895 iter:  825\n",
      "loss:  0.07579469161324966 iter:  826\n",
      "loss:  0.07576819588991797 iter:  827\n",
      "loss:  0.07578462846572073 iter:  828\n",
      "loss:  0.07576280587646998 iter:  829\n",
      "loss:  0.07578440222993678 iter:  830\n",
      "loss:  0.07578738543226836 iter:  831\n",
      "loss:  0.07577730823695175 iter:  832\n",
      "loss:  0.07576288321866786 iter:  833\n",
      "loss:  0.07575927643887122 iter:  834\n",
      "loss:  0.07574900252231236 iter:  835\n",
      "loss:  0.07574891827816366 iter:  836\n",
      "loss:  0.07573598982938697 iter:  837\n",
      "loss:  0.07574061504748145 iter:  838\n",
      "loss:  0.07573054509799247 iter:  839\n",
      "loss:  0.07571611099774254 iter:  840\n",
      "loss:  0.07571617963058237 iter:  841\n",
      "loss:  0.07570619241401341 iter:  842\n",
      "loss:  0.07568225304892735 iter:  843\n",
      "loss:  0.07569824516970579 iter:  844\n",
      "loss:  0.07567735615209607 iter:  845\n",
      "loss:  0.07564834438605247 iter:  846\n",
      "loss:  0.0756534845231493 iter:  847\n",
      "loss:  0.07563507252590357 iter:  848\n",
      "loss:  0.07559749816342883 iter:  849\n",
      "loss:  0.07563282170436669 iter:  850\n",
      "loss:  0.07561154824671516 iter:  851\n",
      "loss:  0.07557677594374523 iter:  852\n",
      "loss:  0.07553291031578926 iter:  853\n",
      "loss:  0.07555839142855479 iter:  854\n",
      "loss:  0.07554899817413364 iter:  855\n",
      "loss:  0.07553225200793533 iter:  856\n",
      "loss:  0.07564027730136896 iter:  857\n",
      "loss:  0.07552198144611905 iter:  858\n",
      "loss:  0.07557806650757465 iter:  859\n",
      "loss:  0.07558779039474804 iter:  860\n",
      "loss:  0.07561729406897387 iter:  861\n",
      "loss:  0.07555698278272655 iter:  862\n",
      "loss:  0.07559609750616693 iter:  863\n",
      "loss:  0.07553251394891132 iter:  864\n",
      "loss:  0.07554414051203988 iter:  865\n",
      "loss:  0.07557267901608758 iter:  866\n",
      "loss:  0.07553612268576831 iter:  867\n",
      "loss:  0.07554353923560811 iter:  868\n",
      "loss:  0.07553087499527458 iter:  869\n",
      "loss:  0.07556078809508059 iter:  870\n",
      "loss:  0.07552425808263319 iter:  871\n",
      "loss:  0.07553471133277843 iter:  872\n",
      "loss:  0.07552322584594563 iter:  873\n",
      "loss:  0.07555841581777673 iter:  874\n",
      "loss:  0.07552129274410899 iter:  875\n",
      "loss:  0.07550415688211899 iter:  876\n",
      "loss:  0.07550298725488329 iter:  877\n",
      "loss:  0.07548788394861106 iter:  878\n",
      "loss:  0.07547467669538649 iter:  879\n",
      "loss:  0.07551903748444143 iter:  880\n",
      "loss:  0.07549260058588302 iter:  881\n",
      "loss:  0.07549033218211301 iter:  882\n",
      "loss:  0.07548959174244406 iter:  883\n",
      "loss:  0.07549698849105432 iter:  884\n",
      "loss:  0.07550635663348605 iter:  885\n",
      "loss:  0.0754889276955558 iter:  886\n",
      "loss:  0.0754770684844818 iter:  887\n",
      "loss:  0.07550444130954816 iter:  888\n",
      "loss:  0.07548576972788906 iter:  889\n",
      "loss:  0.07547428176047971 iter:  890\n",
      "loss:  0.07548978589818241 iter:  891\n",
      "loss:  0.07547322255613233 iter:  892\n",
      "loss:  0.07548298180803108 iter:  893\n",
      "loss:  0.07547125046192799 iter:  894\n",
      "loss:  0.07547286736067214 iter:  895\n",
      "loss:  0.07547615200857818 iter:  896\n",
      "loss:  0.07546927607571659 iter:  897\n",
      "loss:  0.07548922618847893 iter:  898\n",
      "loss:  0.07546603229296363 iter:  899\n",
      "loss:  0.0754771984005352 iter:  900\n",
      "loss:  0.0754873722886867 iter:  901\n",
      "loss:  0.0754712420422768 iter:  902\n",
      "loss:  0.075481281214607 iter:  903\n",
      "loss:  0.07546843074333105 iter:  904\n",
      "loss:  0.07546424696803931 iter:  905\n",
      "loss:  0.07546620989872499 iter:  906\n",
      "loss:  0.07546901529115654 iter:  907\n",
      "loss:  0.07547622016507183 iter:  908\n",
      "loss:  0.07546730120240078 iter:  909\n",
      "loss:  0.07546201282884357 iter:  910\n",
      "loss:  0.07546410284535726 iter:  911\n",
      "loss:  0.075468044484402 iter:  912\n",
      "loss:  0.0754710575106759 iter:  913\n",
      "loss:  0.07546673949328123 iter:  914\n",
      "loss:  0.07546203131812423 iter:  915\n",
      "loss:  0.07546854267756258 iter:  916\n",
      "loss:  0.07546491760963293 iter:  917\n",
      "loss:  0.07546586508118176 iter:  918\n",
      "loss:  0.07546123258715509 iter:  919\n",
      "loss:  0.0754699330623416 iter:  920\n",
      "loss:  0.07546237362727412 iter:  921\n",
      "loss:  0.07546190735523421 iter:  922\n",
      "loss:  0.07546131441087298 iter:  923\n",
      "loss:  0.07545793106782187 iter:  924\n",
      "loss:  0.07545499280763998 iter:  925\n",
      "loss:  0.07546304697686665 iter:  926\n",
      "loss:  0.0754608630747494 iter:  927\n",
      "loss:  0.07545953131921716 iter:  928\n",
      "loss:  0.07545618009783803 iter:  929\n",
      "loss:  0.07546668770033564 iter:  930\n",
      "loss:  0.07545935661904349 iter:  931\n",
      "loss:  0.07545631366093769 iter:  932\n",
      "loss:  0.07545452165775098 iter:  933\n",
      "loss:  0.07545217327991323 iter:  934\n",
      "loss:  0.07545085111328877 iter:  935\n",
      "loss:  0.0754478233988766 iter:  936\n",
      "loss:  0.07545051958190649 iter:  937\n",
      "loss:  0.07544567737434792 iter:  938\n",
      "loss:  0.07543935785216765 iter:  939\n",
      "loss:  0.07544467329634201 iter:  940\n",
      "loss:  0.07543983453069435 iter:  941\n",
      "loss:  0.0754371396385574 iter:  942\n",
      "loss:  0.07543106402697303 iter:  943\n",
      "loss:  0.07543034809003131 iter:  944\n",
      "loss:  0.07542375551105504 iter:  945\n",
      "loss:  0.07542256573271508 iter:  946\n",
      "loss:  0.07541853125143784 iter:  947\n",
      "loss:  0.07541572721994143 iter:  948\n",
      "loss:  0.0754038919459777 iter:  949\n",
      "loss:  0.07540267510499415 iter:  950\n",
      "loss:  0.07538499284659908 iter:  951\n",
      "loss:  0.07538990409647398 iter:  952\n",
      "loss:  0.07538274369866661 iter:  953\n",
      "loss:  0.07537180957475324 iter:  954\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.075372\n",
      "  -> Conv Check: dS=3.6e-01, dPhi=9.7e-03, dLoss=4.0e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_iters_tot = 1300\n",
    "filename_results = \"results/results_hier1_train_V4.h5\"\n",
    "\n",
    "pipeline = [\n",
    "    ('decompose_stochastic', {'percent_info': 0.90, 'k_samples': 18}),\n",
    "    ('optimize_stiff', {'max_iter': 70, 'bound_range': 1.2}),\n",
    "    ('realign_sloppy', {}),\n",
    "    ('optimize_sloppy', {'max_iter': 130}),\n",
    "    ('check_convergence', {'tol_s': 1e-4})\n",
    "]\n",
    "\n",
    "# Instantiate\n",
    "opt_hier = ha.HierarchicalOptimizer(optimizer, params_default_norm, pipeline=pipeline)\n",
    "opt_hier.run(max_cycles=5, max_iter=max_iters_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filename_results, \"w\") as f:\n",
    "    \n",
    "    f.create_dataset(\"best_loss\", data=opt_hier.history['best_loss'])\n",
    "    f.create_dataset(\"iters\", data=opt_hier.history['iters'])\n",
    "    f.create_dataset(\"best_params\", data=opt_hier.history['best_params'])\n",
    "    f.create_dataset(\"best_params_end\", data=opt_hier.phi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qp_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
