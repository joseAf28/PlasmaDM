{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PATH = os.path.dirname(os.path.abspath(os.curdir))\n",
    "if PATH not in sys.path:\n",
    "    sys.path.insert(0, PATH)\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "import src.Optimizer as opt\n",
    "import src.simulation_setup as setup\n",
    "import hierarchical_algorithm as ha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Buffer:  /Users/joseafonso/Desktop/PlasmaDM/Buffer_Data/Experimental_data_CO_O_merged_train.hdf5\n",
      "  d[CO2_F]/dt = -CO2_F*r_29 + r_28*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_F]/dt = -CO_F*O_F*r_35 - 0.02*CO_F*O_S*r_40 - 0.02*CO_F*Odb_S*r_61 - 0.02*CO_F*Vdb_S*r_60 - CO_F*r_31 - CO_F*r_33 - 0.02*CO_F*r_36*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_30*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_S]/dt = CO_F*r_36*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) - CO_S*O_F*r_39 - CO_S*r_37 - CO_S*r_43 - CO_S*r_44 - CO_S*r_45 - CO_S*r_46 + r_32*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[COdb_S]/dt = CO_F*Vdb_S*r_60 - COdb_S*O_F*r_62 - COdb_S*r_54 - COdb_S*r_55 - COdb_S*r_56 - COdb_S*r_57 - COdb_S*r_59 + Vdb_S*r_49\n",
      "  d[O2_F]/dt = -O2_F*O_F*r_15 - O2_F*r_10 - O2_F*r_12 - O2_F*r_14 + r_9*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_F]/dt = -CO_F*O_F*r_35 - 0.02*CO_S*O_F*r_39 - 0.02*COdb_S*O_F*r_62 - O2_F*O_F*r_15 - 2*O_F**2*r_8 - 0.02*O_F*O_S*r_7 - 0.02*O_F*Odb_S*r_27 - 0.02*O_F*Vdb_S*r_26 - O_F*r_11 - O_F*r_2 - O_F*r_34 - O_F*r_4 - 0.02*O_F*r_5*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_1*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_S]/dt = -CO_F*O_S*r_40 - O_F*O_S*r_7 + O_F*r_5*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) - O_S*r_16 - O_S*r_17 - O_S*r_38 - O_S*r_41 - O_S*r_42 - O_S*r_6 + r_3*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[Odb_S]/dt = -CO_F*Odb_S*r_61 - O_F*Odb_S*r_27 + O_F*Vdb_S*r_26 - Odb_S*r_23 - Odb_S*r_24 - Odb_S*r_25 - Odb_S*r_52 - Odb_S*r_53 - Odb_S*r_58 + Vdb_S*r_20\n",
      "  d[Vdb_S]/dt = CO_F*Odb_S*r_61 - CO_F*Vdb_S*r_60 + CO_S*r_43 + CO_S*r_44 + CO_S*r_45 + CO_S*r_46 + COdb_S*O_F*r_62 + COdb_S*r_59 + O_F*Odb_S*r_27 - O_F*Vdb_S*r_26 + O_S*r_16 + O_S*r_17 + O_S*r_41 + O_S*r_42 + Odb_S*r_25 + Odb_S*r_58 - Vdb_S*r_20 - Vdb_S*r_21 - Vdb_S*r_22 - Vdb_S*r_49 - Vdb_S*r_50 - Vdb_S*r_51 + r_18*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_19*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_47*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_48*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n"
     ]
    }
   ],
   "source": [
    "##* create simulator \n",
    "\n",
    "buffer_train = \"Experimental_data_CO_O_merged_train.hdf5\"\n",
    "\n",
    "const_dict, sim = setup.create_common_simulator(PATH, data_file=buffer_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Define Parameters and Bounds\n",
    "lower_bounds_dict = {\n",
    "    'A_d': 1e-8, 'B_d': 1e-8, 'E_d': 0.0, \n",
    "    'SF_30': 1e-5, 'SF_31': 1e-5, 'SF_32': 1e-5, 'SF_33': 1e-5, 'SF_34': 1e-5, 'SF_35': 1e-5, 'SF_36': 1e-5, 'SF_37': 1e-5, 'SF_38': 1e-5, 'SF_39': 1e-5,\n",
    "    'SF_49': 1e-5, 'SF_50': 1e-5, 'SF_51': 1e-5, 'SF_52': 1e-5, 'SF_53': 1e-5, 'SF_54': 1e-5, 'SF_55': 1e-5, 'SF_56': 1e-5, 'SF_57': 1e-5, 'SF_58': 1e-5, 'SF_59': 1e-5, 'SF_60': 1e-5, 'SF_61': 1e-5, 'SF_62': 1e-5,\n",
    "    'Emin': 1.0, 'Ealpha': 2000\n",
    "}\n",
    "\n",
    "upper_bounds_dict = {\n",
    "    'A_d': 5e-1, 'B_d': 1e-2, 'E_d': 30.0, \n",
    "    'SF_30': 1.0, 'SF_31': 1.0, 'SF_32': 1.0,  'SF_33': 1.0, 'SF_34': 1.0, 'SF_35': 1.0, 'SF_36': 1.0, 'SF_37': 1.0, 'SF_38': 1.0, 'SF_39': 1.0,\n",
    "    'SF_49': 1.0, 'SF_50': 1.0, 'SF_51': 1.0, 'SF_52': 1.0, 'SF_53': 1.0, 'SF_54': 1.0, 'SF_55': 1.0, 'SF_56': 1.0, 'SF_57': 1.0, 'SF_58': 1.0, 'SF_59': 1.0, 'SF_60': 1.0, 'SF_61': 1.0, 'SF_62': 1.0,\n",
    "    'Emin': 5.0, 'Ealpha': 5000\n",
    "}\n",
    "\n",
    "params_default_dict = {\n",
    "    'A_d': 0.02634, 'B_d': 7.67e-4, 'E_d': 10.75, \n",
    "    'SF_30': 1.0, 'SF_31': 1.0, 'SF_32': 1e-2,  'SF_33': 1e-1, 'SF_34': 1e-1, 'SF_35': 1e-2, 'SF_36': 1e-1, 'SF_37': 1e-1, 'SF_38': 1e-1, 'SF_39': 1e-1,\n",
    "    'SF_49': 1e-2, 'SF_50': 1.0, 'SF_51': 1.0, 'SF_52': 1.0, 'SF_53': 1e-1, 'SF_54': 1e-1, 'SF_55': 1.0, 'SF_56': 1.0, 'SF_57': 1.0, 'SF_58': 1e-1, 'SF_59': 1e-1, 'SF_60': 1e-2, 'SF_61': 1e-1, 'SF_62': 1e-1,\n",
    "    'Emin': 3.4, 'Ealpha': 3000\n",
    "}\n",
    "\n",
    "lower_bounds = np.array(list(lower_bounds_dict.values()))\n",
    "upper_bounds = np.array(list(upper_bounds_dict.values()))\n",
    "params_default_init = np.array(list(params_default_dict.values()))\n",
    "params_default_norm = (params_default_init - lower_bounds) * np.reciprocal(upper_bounds - lower_bounds)\n",
    "\n",
    "\n",
    "def func_optimization(params_input, flag='numpy'):\n",
    "    \n",
    "    ##! normalize variables\n",
    "    params = [0] * len(params_input)\n",
    "    for idx, param in enumerate(params_input):\n",
    "        params[idx] = lower_bounds[idx] + (upper_bounds[idx] - lower_bounds[idx]) * param\n",
    "    \n",
    "    A_d, B_d, E_d = params[0:3]\n",
    "    SF_30, SF_31, SF_32, SF_33, SF_34, SF_35, SF_36, SF_37, SF_38, SF_39 = params[3:13]\n",
    "    SF_49, SF_50, SF_51, SF_52, SF_53, SF_54, SF_55, SF_56, SF_57, SF_58, SF_59, SF_60, SF_61, SF_62 = params[13:27]\n",
    "    Emin, Ealpha = params[27:]\n",
    "    \n",
    "    if flag=='numpy':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * np.exp(E_d/(const_dict['R'] * T)))\n",
    "    elif flag=='torch':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * torch.exp(E_d/(const_dict['R'] * T)))\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "    \n",
    "    dict_mod_vec = [\n",
    "    {\"id\": 2, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 10, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 16, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    {\"id\": 18, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    \n",
    "    {\"id\": 31, \"rate\": None, \"model_dict\": {\"SF\": SF_31, \"nu_d\": nu_d_mod}},\n",
    "    \n",
    "    {\"id\": 30, \"rate\": None, \"model_dict\": {\"SF\": SF_30}},\n",
    "    {\"id\": 32, \"rate\": None, \"model_dict\": {\"SF\": SF_32}},\n",
    "    {\"id\": 33, \"rate\": None, \"model_dict\": {\"SF\": SF_33}},\n",
    "    {\"id\": 34, \"rate\": None, \"model_dict\": {\"SF\": SF_34}},\n",
    "    \n",
    "    {\"id\": 35, \"rate\": None, \"model_dict\": {\"SF\": SF_35}},\n",
    "    {\"id\": 36, \"rate\": None, \"model_dict\": {\"SF\": SF_36}},\n",
    "    {\"id\": 37, \"rate\": None, \"model_dict\": {\"SF\": SF_37}},\n",
    "    {\"id\": 38, \"rate\": None, \"model_dict\": {\"SF\": SF_38}},\n",
    "    {\"id\": 39, \"rate\": None, \"model_dict\": {\"SF\": SF_39}},\n",
    "    \n",
    "    {\"id\": 44, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    \n",
    "    {\"id\": 49, \"rate\": None, \"model_dict\": {\"SF\": SF_49}},\n",
    "    {\"id\": 50, \"rate\": None, \"model_dict\": {\"SF\": SF_50, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 51, \"rate\": None, \"model_dict\": {\"SF\": SF_51, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 52, \"rate\": None, \"model_dict\": {\"SF\": SF_52, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 53, \"rate\": None, \"model_dict\": {\"SF\": SF_53, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 54, \"rate\": None, \"model_dict\": {\"SF\": SF_54, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 55, \"rate\": None, \"model_dict\": {\"SF\": SF_55, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 56, \"rate\": None, \"model_dict\": {\"SF\": SF_56, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 57, \"rate\": None, \"model_dict\": {\"SF\": SF_57, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 58, \"rate\": None, \"model_dict\": {\"SF\": SF_58, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 59, \"rate\": None, \"model_dict\": {\"SF\": SF_59, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 60, \"rate\": None, \"model_dict\": {\"SF\": SF_60}},\n",
    "    {\"id\": 61, \"rate\": None, \"model_dict\": {\"SF\": SF_61}},\n",
    "    {\"id\": 62, \"rate\": None, \"model_dict\": {\"SF\": SF_62}}\n",
    "    ]\n",
    "    \n",
    "    return dict_mod_vec\n",
    "\n",
    "def loss_function(exp, teo, flag='numpy'):\n",
    "    func = ((teo-exp)**2)/(exp**2)\n",
    "    if flag == 'numpy':\n",
    "        return np.mean(func)\n",
    "    elif flag == 'torch':\n",
    "        return torch.mean(func)\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "\n",
    "\n",
    "# 4. Instantiate and Run Optimizer\n",
    "optimizer = opt.Optimizer(sim, \n",
    "                        lambda params: func_optimization(params, 'numpy'), \n",
    "                        lambda exp, teo: loss_function(exp, teo, 'numpy')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pipeline with 5 steps...\n",
      "\n",
      "==================== CYCLE 1 ====================\n",
      "loss:  783.7419346722897 iter:  1\n",
      "\n",
      "[Step] Stochastic Decomposition (k=10)\n",
      "loss:  783.7419346722897 iter:  2\n",
      "loss:  783.6477232387426 iter:  3\n",
      "loss:  783.8540639018727 iter:  4\n",
      "loss:  783.79198456167 iter:  5\n",
      "loss:  783.6713895954373 iter:  6\n",
      "loss:  783.6544235764359 iter:  7\n",
      "loss:  783.713281156303 iter:  8\n",
      "loss:  783.7224044232455 iter:  9\n",
      "loss:  783.7040864809961 iter:  10\n",
      "loss:  783.7868304321756 iter:  11\n",
      "loss:  783.7595508468631 iter:  12\n",
      "  -> Split: Stiff=1, Sloppy=4\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  783.7419346722897 iter:  13\n",
      "loss:  99110.03165285637 iter:  14\n",
      "loss:  0.37188850673330226 iter:  15\n",
      "loss:  0.7204504049428238 iter:  16\n",
      "loss:  0.5108130578492018 iter:  17\n",
      "loss:  142.07581399704213 iter:  18\n",
      "loss:  4.264181416801184 iter:  19\n",
      "loss:  0.25436370030571726 iter:  20\n",
      "loss:  0.26173180049552297 iter:  21\n",
      "loss:  0.231631705431093 iter:  22\n",
      "loss:  0.2350756309924057 iter:  23\n",
      "loss:  0.2280947566930261 iter:  24\n",
      "loss:  0.2280601615913298 iter:  25\n",
      "loss:  0.22804723160995038 iter:  26\n",
      "loss:  0.22804696316829343 iter:  27\n",
      "loss:  0.22804701651662862 iter:  28\n",
      "loss:  0.22804703067621235 iter:  29\n",
      "loss:  0.7298162477841845 iter:  30\n",
      "loss:  99110.03165310551 iter:  31\n",
      "loss:  0.3718885067385311 iter:  32\n",
      "loss:  0.7204504049404554 iter:  33\n",
      "loss:  0.5108130578492018 iter:  34\n",
      "loss:  142.07581412858573 iter:  35\n",
      "loss:  4.26418141679507 iter:  36\n",
      "loss:  0.2543637003061367 iter:  37\n",
      "loss:  0.2617318004950627 iter:  38\n",
      "loss:  0.2316317054334001 iter:  39\n",
      "loss:  0.2350756309883972 iter:  40\n",
      "loss:  0.2280947566918623 iter:  41\n",
      "loss:  0.22806016159210454 iter:  42\n",
      "loss:  0.22804723160995824 iter:  43\n",
      "loss:  0.2280469631680535 iter:  44\n",
      "loss:  0.22804696725866108 iter:  45\n",
      "loss:  0.22804697184852735 iter:  46\n",
      "loss:  0.3718885067360613 iter:  47\n",
      "loss:  99110.03165314838 iter:  48\n",
      "loss:  0.7204504049404554 iter:  49\n",
      "loss:  0.5108130578588966 iter:  50\n",
      "loss:  142.07581418255043 iter:  51\n",
      "loss:  4.264181416812913 iter:  52\n",
      "loss:  0.25436370030214567 iter:  53\n",
      "loss:  0.2617318004922058 iter:  54\n",
      "loss:  0.2316317054297783 iter:  55\n",
      "loss:  0.2350756309900109 iter:  56\n",
      "loss:  0.22809475669377807 iter:  57\n",
      "loss:  0.22806016159420117 iter:  58\n",
      "loss:  0.228047231606791 iter:  59\n",
      "loss:  0.22804696316935782 iter:  60\n",
      "loss:  0.22804696296633042 iter:  61\n",
      "loss:  0.22804696296474425 iter:  62\n",
      "loss:  0.2280469629620287 iter:  63\n",
      "loss:  0.22804696296274443 iter:  64\n",
      "loss:  0.22804696296124183 iter:  65\n",
      "loss:  0.22804696296385807 iter:  66\n",
      "loss:  0.2280469629638998 iter:  67\n",
      "loss:  0.2280469629608971 iter:  68\n",
      "loss:  0.2280469629641904 iter:  69\n",
      "loss:  0.22804696296388052 iter:  70\n",
      "loss:  0.22804696296447186 iter:  71\n",
      "loss:  0.22804696296185756 iter:  72\n",
      "loss:  0.228046962961419 iter:  73\n",
      "loss:  0.22804696296133004 iter:  74\n",
      "loss:  0.22804696296465446 iter:  75\n",
      "loss:  0.22804696296179044 iter:  76\n",
      "loss:  0.22804696296408547 iter:  77\n",
      "loss:  0.22804696296051735 iter:  78\n",
      "loss:  0.22804696296465898 iter:  79\n",
      "loss:  0.22804696296352445 iter:  80\n",
      "loss:  0.22804696296306548 iter:  81\n",
      "loss:  0.2280469629614075 iter:  82\n",
      "  -> Loss: 0.228047 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.2280469631680535 iter:  83\n",
      "loss:  0.22805021069580994 iter:  84\n",
      "loss:  0.22805773822737274 iter:  85\n",
      "loss:  0.22804455132833926 iter:  86\n",
      "loss:  0.22804460162066686 iter:  87\n",
      "  -> Realigned. Top Eigenvals: [2559.11214765  540.48942329   32.75686201]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:4\n",
      "loss:  0.2280469631680535 iter:  88\n",
      "loss:  0.22811523345090867 iter:  89\n",
      "loss:  0.22833126261245565 iter:  90\n",
      "loss:  0.228037598679372 iter:  91\n",
      "loss:  0.22804642053802354 iter:  92\n",
      "loss:  0.2277900402339098 iter:  93\n",
      "loss:  0.22751701550118125 iter:  94\n",
      "loss:  0.22770827408552982 iter:  95\n",
      "loss:  0.22760752944449317 iter:  96\n",
      "loss:  0.22738671682092726 iter:  97\n",
      "loss:  0.22705288050092476 iter:  98\n",
      "loss:  0.22689643758377645 iter:  99\n",
      "loss:  0.22631114104183223 iter:  100\n",
      "loss:  0.22653998068998307 iter:  101\n",
      "loss:  0.22609524941021758 iter:  102\n",
      "loss:  0.22531789798589966 iter:  103\n",
      "loss:  0.22506220841383748 iter:  104\n",
      "loss:  0.22377061854855265 iter:  105\n",
      "loss:  0.22388393466874965 iter:  106\n",
      "loss:  0.22303825557646478 iter:  107\n",
      "loss:  0.22114256138784114 iter:  108\n",
      "loss:  0.22060854136622857 iter:  109\n",
      "loss:  0.21741861763968914 iter:  110\n",
      "loss:  0.2175540935451429 iter:  111\n",
      "loss:  0.21580206406534969 iter:  112\n",
      "loss:  0.2110127002227419 iter:  113\n",
      "loss:  0.2086373670931352 iter:  114\n",
      "loss:  0.19818994722452465 iter:  115\n",
      "loss:  0.19964868712004702 iter:  116\n",
      "loss:  0.1938696408295431 iter:  117\n",
      "loss:  0.17494119896694357 iter:  118\n",
      "loss:  0.1624356564981378 iter:  119\n",
      "loss:  0.10464948349819313 iter:  120\n",
      "loss:  0.10043420433072868 iter:  121\n",
      "loss:  0.14056156309018333 iter:  122\n",
      "loss:  0.10287524103119448 iter:  123\n",
      "loss:  0.15386882386602194 iter:  124\n",
      "loss:  0.17336980374502137 iter:  125\n",
      "loss:  0.14675533401346566 iter:  126\n",
      "loss:  0.14581843673470277 iter:  127\n",
      "loss:  0.18407806299342738 iter:  128\n",
      "loss:  0.10705925652389994 iter:  129\n",
      "loss:  0.13909842975715403 iter:  130\n",
      "loss:  0.1121816040367651 iter:  131\n",
      "loss:  0.11008284496761382 iter:  132\n",
      "loss:  0.10468196950175272 iter:  133\n",
      "loss:  0.12852549716036882 iter:  134\n",
      "loss:  0.11127267035816067 iter:  135\n",
      "loss:  0.3390667910746837 iter:  136\n",
      "loss:  0.1011920830610989 iter:  137\n",
      "loss:  0.10107712489143722 iter:  138\n",
      "loss:  0.1625385477139055 iter:  139\n",
      "loss:  0.10124270421329876 iter:  140\n",
      "loss:  0.12347153293089955 iter:  141\n",
      "loss:  0.10966816376692602 iter:  142\n",
      "loss:  0.1619040796091688 iter:  143\n",
      "loss:  0.10356218179286915 iter:  144\n",
      "loss:  0.10821348133705 iter:  145\n",
      "loss:  0.10140223597136405 iter:  146\n",
      "loss:  0.10207020139191082 iter:  147\n",
      "loss:  0.10075569378841931 iter:  148\n",
      "loss:  0.10230039122903331 iter:  149\n",
      "loss:  0.10067815952662124 iter:  150\n",
      "loss:  0.10097408191314344 iter:  151\n",
      "loss:  0.1025033532982019 iter:  152\n",
      "loss:  0.10048987514621457 iter:  153\n",
      "loss:  0.10080920389388097 iter:  154\n",
      "loss:  0.10057702589798254 iter:  155\n",
      "loss:  0.10049587322003674 iter:  156\n",
      "loss:  0.10056918478044115 iter:  157\n",
      "loss:  0.10028849581084023 iter:  158\n",
      "loss:  0.10015898200178378 iter:  159\n",
      "loss:  0.10038373364198697 iter:  160\n",
      "loss:  0.10029483239001266 iter:  161\n",
      "loss:  0.10016335676936525 iter:  162\n",
      "loss:  0.09994963574548978 iter:  163\n",
      "loss:  0.09972715840031711 iter:  164\n",
      "loss:  0.09969304649286506 iter:  165\n",
      "loss:  0.09940785699056841 iter:  166\n",
      "loss:  0.09952137762164062 iter:  167\n",
      "loss:  0.0999874874406445 iter:  168\n",
      "loss:  0.09896510000851795 iter:  169\n",
      "loss:  0.09839761551679946 iter:  170\n",
      "loss:  0.09918273354591797 iter:  171\n",
      "loss:  0.09841442010218585 iter:  172\n",
      "loss:  0.09810629746445972 iter:  173\n",
      "loss:  0.0975480907376797 iter:  174\n",
      "loss:  0.09721203898324036 iter:  175\n",
      "loss:  0.09624324483047259 iter:  176\n",
      "loss:  0.09628007430161348 iter:  177\n",
      "loss:  0.09570073399749954 iter:  178\n",
      "loss:  0.0946012282459167 iter:  179\n",
      "loss:  0.09444692725133155 iter:  180\n",
      "loss:  0.09357198852869873 iter:  181\n",
      "loss:  0.09234960180172595 iter:  182\n",
      "loss:  0.09022264107125184 iter:  183\n",
      "loss:  0.09290734258261853 iter:  184\n",
      "loss:  0.09066194368626047 iter:  185\n",
      "loss:  0.09106632961411112 iter:  186\n",
      "loss:  0.08902469537854467 iter:  187\n",
      "loss:  0.08802576487506397 iter:  188\n",
      "loss:  0.08656215982601279 iter:  189\n",
      "loss:  0.08432100292311027 iter:  190\n",
      "loss:  0.08470028614826587 iter:  191\n",
      "loss:  0.08253403247089469 iter:  192\n",
      "loss:  0.08219523438368206 iter:  193\n",
      "loss:  0.08187614737610382 iter:  194\n",
      "loss:  0.08280952294009497 iter:  195\n",
      "loss:  0.08798012404806353 iter:  196\n",
      "loss:  0.08123188924227263 iter:  197\n",
      "loss:  0.08061697698621248 iter:  198\n",
      "loss:  0.0940796122506726 iter:  199\n",
      "loss:  0.12322635818274033 iter:  200\n",
      "loss:  0.08178043655181952 iter:  201\n",
      "loss:  0.08351999309410191 iter:  202\n",
      "loss:  0.08082995994982052 iter:  203\n",
      "loss:  0.08296324728233763 iter:  204\n",
      "loss:  0.08082195755947387 iter:  205\n",
      "loss:  0.08435015789554046 iter:  206\n",
      "loss:  0.08087476030868375 iter:  207\n",
      "loss:  0.08126519150533071 iter:  208\n",
      "loss:  0.08066671048075118 iter:  209\n",
      "loss:  0.08085133512290892 iter:  210\n",
      "loss:  0.08049652434181162 iter:  211\n",
      "loss:  0.08051038788535969 iter:  212\n",
      "loss:  0.08223740965263625 iter:  213\n",
      "loss:  0.08045464866256385 iter:  214\n",
      "loss:  0.08079562865955502 iter:  215\n",
      "loss:  0.08042395957062366 iter:  216\n",
      "loss:  0.08058811658402122 iter:  217\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.080424\n",
      "\n",
      "==================== CYCLE 2 ====================\n",
      "\n",
      "[Step] Stochastic Decomposition (k=10)\n",
      "loss:  0.08042395957062366 iter:  218\n",
      "loss:  0.08042641500596384 iter:  219\n",
      "loss:  0.08042106703141408 iter:  220\n",
      "loss:  0.08042508520342656 iter:  221\n",
      "loss:  0.08043178924663899 iter:  222\n",
      "loss:  0.08042471341714584 iter:  223\n",
      "loss:  0.08042765467279273 iter:  224\n",
      "loss:  0.08043028905644259 iter:  225\n",
      "loss:  0.08041829398199779 iter:  226\n",
      "loss:  0.08043568940091789 iter:  227\n",
      "loss:  0.08042245701941989 iter:  228\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.08042395957062366 iter:  229\n",
      "loss:  0.6634240409778092 iter:  230\n",
      "loss:  6.716305390893611 iter:  231\n",
      "loss:  0.7827458657779983 iter:  232\n",
      "loss:  0.743443469496024 iter:  233\n",
      "loss:  0.38540892904197704 iter:  234\n",
      "loss:  0.2285261630600333 iter:  235\n",
      "loss:  0.6135394262211273 iter:  236\n",
      "loss:  0.2126640522728979 iter:  237\n",
      "loss:  0.2177901916818352 iter:  238\n",
      "loss:  0.23308044342406287 iter:  239\n",
      "loss:  0.18034495795500066 iter:  240\n",
      "loss:  0.2530264384784121 iter:  241\n",
      "loss:  0.20001724118793318 iter:  242\n",
      "loss:  0.15591148300096055 iter:  243\n",
      "loss:  0.1298575895444774 iter:  244\n",
      "loss:  0.10590152174005314 iter:  245\n",
      "loss:  0.08804367266607321 iter:  246\n",
      "loss:  0.0800941864231867 iter:  247\n",
      "loss:  0.0847223672891127 iter:  248\n",
      "loss:  0.08036606231752723 iter:  249\n",
      "loss:  0.07996585281373049 iter:  250\n",
      "loss:  0.0803545468115271 iter:  251\n",
      "loss:  0.07996622635161717 iter:  252\n",
      "loss:  0.11344773699363878 iter:  253\n",
      "loss:  0.6634240409792164 iter:  254\n",
      "loss:  6.716305390877143 iter:  255\n",
      "loss:  0.7827458657724768 iter:  256\n",
      "loss:  0.7434434694877992 iter:  257\n",
      "loss:  0.38540892903961466 iter:  258\n",
      "loss:  0.22852616306168458 iter:  259\n",
      "loss:  0.6135394262184652 iter:  260\n",
      "loss:  0.21266405227274368 iter:  261\n",
      "loss:  0.21779019168307273 iter:  262\n",
      "loss:  0.2330804434228468 iter:  263\n",
      "loss:  0.18034495795578287 iter:  264\n",
      "loss:  0.25302643875437614 iter:  265\n",
      "loss:  0.20001724118861167 iter:  266\n",
      "loss:  0.1559114829956639 iter:  267\n",
      "loss:  0.12985758954123136 iter:  268\n",
      "loss:  0.10590152173652416 iter:  269\n",
      "loss:  0.08804367266816994 iter:  270\n",
      "loss:  0.08009418642034084 iter:  271\n",
      "loss:  0.08472236729823522 iter:  272\n",
      "loss:  0.08036606232463689 iter:  273\n",
      "loss:  0.07996585286388834 iter:  274\n",
      "loss:  0.08035454665890902 iter:  275\n",
      "loss:  0.07996622626071657 iter:  276\n",
      "  -> Loss: 0.079966 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.07996585286388834 iter:  277\n",
      "loss:  0.07997097617405931 iter:  278\n",
      "loss:  0.07996259586897879 iter:  279\n",
      "loss:  0.07996590470238003 iter:  280\n",
      "loss:  0.07996557287735742 iter:  281\n",
      "loss:  0.07996569825728216 iter:  282\n",
      "loss:  0.07996580350983677 iter:  283\n",
      "  -> Realigned. Top Eigenvals: [6691.18742084 1472.1052473   122.45545191]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.07996585286388834 iter:  284\n",
      "loss:  0.07984023042309568 iter:  285\n",
      "loss:  0.07988396308348694 iter:  286\n",
      "loss:  0.07996966449989255 iter:  287\n",
      "loss:  0.07997303734753294 iter:  288\n",
      "loss:  0.07996502824691896 iter:  289\n",
      "loss:  0.07996410618916963 iter:  290\n",
      "loss:  0.07988946371299005 iter:  291\n",
      "loss:  0.07986624769267212 iter:  292\n",
      "loss:  0.07983700030800991 iter:  293\n",
      "loss:  0.07977312644692365 iter:  294\n",
      "loss:  0.07977422528814569 iter:  295\n",
      "loss:  0.07971261730751475 iter:  296\n",
      "loss:  0.07958913135816144 iter:  297\n",
      "loss:  0.07968598545445048 iter:  298\n",
      "loss:  0.07962975839849415 iter:  299\n",
      "loss:  0.07956715591539994 iter:  300\n",
      "loss:  0.07942286331218507 iter:  301\n",
      "loss:  0.07945064205421291 iter:  302\n",
      "loss:  0.07941215890727267 iter:  303\n",
      "loss:  0.07923834086967327 iter:  304\n",
      "loss:  0.07923979052785353 iter:  305\n",
      "loss:  0.07917836404787874 iter:  306\n",
      "loss:  0.07894114729012071 iter:  307\n",
      "loss:  0.07899831844998781 iter:  308\n",
      "loss:  0.0788588995237992 iter:  309\n",
      "loss:  0.07853043431281545 iter:  310\n",
      "loss:  0.07869273112671618 iter:  311\n",
      "loss:  0.07847912249882387 iter:  312\n",
      "loss:  0.07806397896006774 iter:  313\n",
      "loss:  0.07826623850680305 iter:  314\n",
      "loss:  0.07798703388914376 iter:  315\n",
      "loss:  0.07749450390376486 iter:  316\n",
      "loss:  0.07773953310133284 iter:  317\n",
      "loss:  0.07743232798165302 iter:  318\n",
      "loss:  0.07693542437854377 iter:  319\n",
      "loss:  0.07707439965139025 iter:  320\n",
      "loss:  0.07685869424781605 iter:  321\n",
      "loss:  0.0765129333513929 iter:  322\n",
      "loss:  0.07660401217627527 iter:  323\n",
      "loss:  0.07656552845729839 iter:  324\n",
      "loss:  0.07642759995546745 iter:  325\n",
      "loss:  0.07685355668238135 iter:  326\n",
      "loss:  0.07664567177598994 iter:  327\n",
      "loss:  0.0768530262028693 iter:  328\n",
      "loss:  0.07720842167329355 iter:  329\n",
      "loss:  0.07658741963820119 iter:  330\n",
      "loss:  0.07689951733114635 iter:  331\n",
      "loss:  0.07657435252848818 iter:  332\n",
      "loss:  0.07680668728751304 iter:  333\n",
      "loss:  0.07651642730033663 iter:  334\n",
      "loss:  0.07657849699424328 iter:  335\n",
      "loss:  0.07671618668379268 iter:  336\n",
      "loss:  0.07650705566813058 iter:  337\n",
      "loss:  0.07656624608132946 iter:  338\n",
      "loss:  0.076602129698475 iter:  339\n",
      "loss:  0.07651094082271065 iter:  340\n",
      "loss:  0.07654593671391105 iter:  341\n",
      "loss:  0.07641802280074804 iter:  342\n",
      "loss:  0.07637853309308781 iter:  343\n",
      "loss:  0.0764410373726394 iter:  344\n",
      "loss:  0.0764042119522704 iter:  345\n",
      "loss:  0.07640762233197876 iter:  346\n",
      "loss:  0.07629782018513076 iter:  347\n",
      "loss:  0.07620698795217021 iter:  348\n",
      "loss:  0.07622354845665448 iter:  349\n",
      "loss:  0.07629833361135212 iter:  350\n",
      "loss:  0.07615088161967157 iter:  351\n",
      "loss:  0.0760168560587497 iter:  352\n",
      "loss:  0.07606571065725043 iter:  353\n",
      "loss:  0.07611165003547612 iter:  354\n",
      "loss:  0.07589869313348682 iter:  355\n",
      "loss:  0.07570670397781708 iter:  356\n",
      "loss:  0.07584773848011488 iter:  357\n",
      "loss:  0.07572103154431302 iter:  358\n",
      "loss:  0.0756084441038775 iter:  359\n",
      "loss:  0.07542370632675659 iter:  360\n",
      "loss:  0.07568797125671244 iter:  361\n",
      "loss:  0.07531674657969688 iter:  362\n",
      "loss:  0.07498966402874231 iter:  363\n",
      "loss:  0.0751132143251953 iter:  364\n",
      "loss:  0.07497511856511084 iter:  365\n",
      "loss:  0.07467317529615966 iter:  366\n",
      "loss:  0.07474124005260321 iter:  367\n",
      "loss:  0.07452672077182675 iter:  368\n",
      "loss:  0.07439576995772858 iter:  369\n",
      "loss:  0.07487264330979589 iter:  370\n",
      "loss:  0.07426139315343862 iter:  371\n",
      "loss:  0.07452909564396172 iter:  372\n",
      "loss:  0.07504347998201177 iter:  373\n",
      "loss:  0.07453314838219606 iter:  374\n",
      "loss:  0.07441525852541317 iter:  375\n",
      "loss:  0.07435066713729067 iter:  376\n",
      "loss:  0.07426278889311602 iter:  377\n",
      "loss:  0.07455592200095144 iter:  378\n",
      "loss:  0.07464458035299266 iter:  379\n",
      "loss:  0.07441178905187518 iter:  380\n",
      "loss:  0.07428628504394975 iter:  381\n",
      "loss:  0.07429500330456278 iter:  382\n",
      "loss:  0.07446277099682277 iter:  383\n",
      "loss:  0.07434132385620934 iter:  384\n",
      "loss:  0.07439280965514354 iter:  385\n",
      "loss:  0.07436763458240159 iter:  386\n",
      "loss:  0.0745487496422794 iter:  387\n",
      "loss:  0.07429069486461683 iter:  388\n",
      "loss:  0.07426292423593564 iter:  389\n",
      "loss:  0.07447385902456537 iter:  390\n",
      "loss:  0.07428834320031791 iter:  391\n",
      "loss:  0.07425068033096247 iter:  392\n",
      "loss:  0.07431251825013843 iter:  393\n",
      "loss:  0.07428219876657476 iter:  394\n",
      "loss:  0.0743234470889426 iter:  395\n",
      "loss:  0.07425813527019193 iter:  396\n",
      "loss:  0.0742593051737853 iter:  397\n",
      "loss:  0.07428994812857648 iter:  398\n",
      "loss:  0.07425802091095589 iter:  399\n",
      "loss:  0.07427319076021416 iter:  400\n",
      "loss:  0.07425161216572758 iter:  401\n",
      "loss:  0.07427991740410217 iter:  402\n",
      "loss:  0.074248298131825 iter:  403\n",
      "loss:  0.07423978413712962 iter:  404\n",
      "loss:  0.07424638952648209 iter:  405\n",
      "loss:  0.07425724061954889 iter:  406\n",
      "loss:  0.07423657862966919 iter:  407\n",
      "loss:  0.07424322545497068 iter:  408\n",
      "loss:  0.07423846204448237 iter:  409\n",
      "loss:  0.07426994376186895 iter:  410\n",
      "loss:  0.07424099501193873 iter:  411\n",
      "loss:  0.07424282398767727 iter:  412\n",
      "loss:  0.07424553435198049 iter:  413\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.074237\n",
      "  -> Conv Check: dS=9.7e-01, dPhi=3.2e-02, dLoss=6.2e-03\n",
      "\n",
      "==================== CYCLE 3 ====================\n",
      "\n",
      "[Step] Stochastic Decomposition (k=10)\n",
      "loss:  0.07423657862966919 iter:  414\n",
      "loss:  0.07418991136960786 iter:  415\n",
      "loss:  0.07423854153983826 iter:  416\n",
      "loss:  0.07420494119395359 iter:  417\n",
      "loss:  0.07421669959617877 iter:  418\n",
      "loss:  0.07423276604741173 iter:  419\n",
      "loss:  0.07421746191548663 iter:  420\n",
      "loss:  0.07420667625130128 iter:  421\n",
      "loss:  0.07428319913901235 iter:  422\n",
      "loss:  0.07428023517904761 iter:  423\n",
      "loss:  0.07419545602017573 iter:  424\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.07423657862966919 iter:  425\n",
      "loss:  0.7541156715350723 iter:  426\n",
      "loss:  74.73670906028913 iter:  427\n",
      "loss:  0.8361002707367801 iter:  428\n",
      "loss:  0.8154782927908851 iter:  429\n",
      "loss:  0.4392829875812947 iter:  430\n",
      "loss:  0.31637444919948493 iter:  431\n",
      "loss:  2.885587072334769 iter:  432\n",
      "loss:  0.2027170689120263 iter:  433\n",
      "loss:  0.19744068578016452 iter:  434\n",
      "loss:  0.2796974699645189 iter:  435\n",
      "loss:  0.18585281959685634 iter:  436\n",
      "loss:  0.13967711628601676 iter:  437\n",
      "loss:  0.22240147287507156 iter:  438\n",
      "loss:  0.1151827206868668 iter:  439\n",
      "loss:  0.11177859806069977 iter:  440\n",
      "loss:  0.24642111937996256 iter:  441\n",
      "loss:  0.09187879488317709 iter:  442\n",
      "loss:  0.07808230482326602 iter:  443\n",
      "loss:  0.07437679171063917 iter:  444\n",
      "loss:  0.08184921005764534 iter:  445\n",
      "loss:  0.07435266215308492 iter:  446\n",
      "loss:  0.07494200775257426 iter:  447\n",
      "loss:  0.07408020992523222 iter:  448\n",
      "loss:  0.10041981529485677 iter:  449\n",
      "loss:  0.754115671535114 iter:  450\n",
      "loss:  74.73670906083004 iter:  451\n",
      "loss:  0.8361002707367801 iter:  452\n",
      "loss:  0.8154782927881604 iter:  453\n",
      "loss:  0.43928298758048184 iter:  454\n",
      "loss:  0.31637444919913854 iter:  455\n",
      "loss:  2.8855870723158104 iter:  456\n",
      "loss:  0.20271706891094388 iter:  457\n",
      "loss:  0.1974406857806376 iter:  458\n",
      "loss:  0.2796974699634281 iter:  459\n",
      "loss:  0.18585281960051395 iter:  460\n",
      "loss:  0.1396771162674999 iter:  461\n",
      "loss:  0.22240147286779402 iter:  462\n",
      "loss:  0.11518272070034696 iter:  463\n",
      "loss:  0.1117785980438485 iter:  464\n",
      "loss:  0.24642112279058054 iter:  465\n",
      "loss:  0.0918787948828076 iter:  466\n",
      "loss:  0.07808230483528723 iter:  467\n",
      "loss:  0.07437679169997018 iter:  468\n",
      "loss:  0.08184921033423247 iter:  469\n",
      "loss:  0.07435266216172719 iter:  470\n",
      "loss:  0.07494200752415096 iter:  471\n",
      "loss:  0.07408020995456936 iter:  472\n",
      "  -> Loss: 0.074080 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.07408020995456936 iter:  473\n",
      "loss:  0.07408061242097629 iter:  474\n",
      "loss:  0.07408017109822443 iter:  475\n",
      "loss:  0.07408027718977615 iter:  476\n",
      "loss:  0.07407991286917234 iter:  477\n",
      "loss:  0.0740800709815216 iter:  478\n",
      "loss:  0.07408023317640834 iter:  479\n",
      "  -> Realigned. Top Eigenvals: [13190.94204396  7464.81187247   488.70120405]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.07408020995456936 iter:  480\n",
      "loss:  0.07407439013184823 iter:  481\n",
      "loss:  0.07408021071515737 iter:  482\n",
      "loss:  0.07407846090149076 iter:  483\n",
      "loss:  0.07408749504437383 iter:  484\n",
      "loss:  0.07408398888101053 iter:  485\n",
      "loss:  0.07408075649042987 iter:  486\n",
      "loss:  0.07407035382544122 iter:  487\n",
      "loss:  0.07406226023640776 iter:  488\n",
      "loss:  0.07406695375553349 iter:  489\n",
      "loss:  0.07406621061155906 iter:  490\n",
      "loss:  0.07406554736431029 iter:  491\n",
      "loss:  0.07405895683169167 iter:  492\n",
      "loss:  0.07405273954911247 iter:  493\n",
      "loss:  0.07405527254710831 iter:  494\n",
      "loss:  0.07404629538420479 iter:  495\n",
      "loss:  0.0740336235676511 iter:  496\n",
      "loss:  0.07404467238789947 iter:  497\n",
      "loss:  0.07403864722804161 iter:  498\n",
      "loss:  0.07403531658331676 iter:  499\n",
      "loss:  0.07403547458343739 iter:  500\n",
      "loss:  0.07402247519223665 iter:  501\n",
      "loss:  0.07400817837537535 iter:  502\n",
      "loss:  0.07400985070097096 iter:  503\n",
      "loss:  0.07400857443863046 iter:  504\n",
      "loss:  0.07400932799332254 iter:  505\n",
      "loss:  0.0740065660780279 iter:  506\n",
      "loss:  0.07400667459724683 iter:  507\n",
      "loss:  0.07398807794636336 iter:  508\n",
      "loss:  0.07396785452393619 iter:  509\n",
      "loss:  0.07397853513700815 iter:  510\n",
      "loss:  0.07398323621318027 iter:  511\n",
      "loss:  0.07397227580247895 iter:  512\n",
      "loss:  0.07396541087508604 iter:  513\n",
      "loss:  0.0739535264101821 iter:  514\n",
      "loss:  0.07395219553861428 iter:  515\n",
      "loss:  0.07394376593378152 iter:  516\n",
      "loss:  0.07392998140938807 iter:  517\n",
      "loss:  0.07391656415951726 iter:  518\n",
      "loss:  0.07391449557099984 iter:  519\n",
      "loss:  0.07389129673405308 iter:  520\n",
      "loss:  0.0739181560573555 iter:  521\n",
      "loss:  0.07392136463944045 iter:  522\n",
      "loss:  0.07393713880085745 iter:  523\n",
      "loss:  0.07391890851764973 iter:  524\n",
      "loss:  0.07390961836969162 iter:  525\n",
      "loss:  0.07388891179488351 iter:  526\n",
      "loss:  0.07389965576582441 iter:  527\n",
      "loss:  0.07387506663734345 iter:  528\n",
      "loss:  0.07386445058967253 iter:  529\n",
      "loss:  0.07391902829273053 iter:  530\n",
      "loss:  0.07389485482925481 iter:  531\n",
      "loss:  0.07388694260059797 iter:  532\n",
      "loss:  0.07385362545106659 iter:  533\n",
      "loss:  0.07384341501252521 iter:  534\n",
      "loss:  0.07386828753019319 iter:  535\n",
      "loss:  0.07385306098299724 iter:  536\n",
      "loss:  0.07383995572661044 iter:  537\n",
      "loss:  0.07385215647014501 iter:  538\n",
      "loss:  0.07382475546770068 iter:  539\n",
      "loss:  0.07382793932847412 iter:  540\n",
      "loss:  0.07381913278137592 iter:  541\n",
      "loss:  0.0738337689296818 iter:  542\n",
      "loss:  0.0738347758315569 iter:  543\n",
      "loss:  0.07379921409748086 iter:  544\n",
      "loss:  0.07379699089030332 iter:  545\n",
      "loss:  0.07383819230389463 iter:  546\n",
      "loss:  0.07382368548768442 iter:  547\n",
      "loss:  0.07380753981190985 iter:  548\n",
      "loss:  0.07382461628696772 iter:  549\n",
      "loss:  0.0737815697934091 iter:  550\n",
      "loss:  0.07378594535115973 iter:  551\n",
      "loss:  0.07380023585006665 iter:  552\n",
      "loss:  0.0737974760528994 iter:  553\n",
      "loss:  0.07379290259879724 iter:  554\n",
      "loss:  0.07384501727329017 iter:  555\n",
      "loss:  0.0737893912876147 iter:  556\n",
      "loss:  0.07377322378151174 iter:  557\n",
      "loss:  0.07378514018757597 iter:  558\n",
      "loss:  0.07377553224231144 iter:  559\n",
      "loss:  0.07378680627512052 iter:  560\n",
      "loss:  0.07380027024553656 iter:  561\n",
      "loss:  0.07377798929557676 iter:  562\n",
      "loss:  0.07381124267636885 iter:  563\n",
      "loss:  0.07377639960623249 iter:  564\n",
      "loss:  0.07375138169510459 iter:  565\n",
      "loss:  0.07373298297806116 iter:  566\n",
      "loss:  0.07377007495631324 iter:  567\n",
      "loss:  0.07378548688230128 iter:  568\n",
      "loss:  0.07376634877299784 iter:  569\n",
      "loss:  0.07374557782756518 iter:  570\n",
      "loss:  0.07373905946452056 iter:  571\n",
      "loss:  0.0737578634514315 iter:  572\n",
      "loss:  0.0737305793503841 iter:  573\n",
      "loss:  0.07372620996304445 iter:  574\n",
      "loss:  0.07372815967592661 iter:  575\n",
      "loss:  0.07369538031227801 iter:  576\n",
      "loss:  0.073663133741205 iter:  577\n",
      "loss:  0.07370436883530096 iter:  578\n",
      "loss:  0.07368246648245583 iter:  579\n",
      "loss:  0.07365736230984123 iter:  580\n",
      "loss:  0.07361991994730757 iter:  581\n",
      "loss:  0.07363651635134208 iter:  582\n",
      "loss:  0.07367939683621252 iter:  583\n",
      "loss:  0.0735864379505573 iter:  584\n",
      "loss:  0.07352271084486595 iter:  585\n",
      "loss:  0.07356511166824196 iter:  586\n",
      "loss:  0.07353784828654714 iter:  587\n",
      "loss:  0.07356008106977173 iter:  588\n",
      "loss:  0.07347718634877258 iter:  589\n",
      "loss:  0.0734040553440803 iter:  590\n",
      "loss:  0.07341846410219945 iter:  591\n",
      "loss:  0.0733612205706709 iter:  592\n",
      "loss:  0.07323858772106018 iter:  593\n",
      "loss:  0.07332858037720376 iter:  594\n",
      "loss:  0.07331752700807023 iter:  595\n",
      "loss:  0.0731945370587031 iter:  596\n",
      "loss:  0.07304890267179243 iter:  597\n",
      "loss:  0.07304750109259052 iter:  598\n",
      "loss:  0.07284311520107559 iter:  599\n",
      "loss:  0.07297317542201859 iter:  600\n",
      "loss:  0.07283152042899736 iter:  601\n",
      "loss:  0.07259166618366537 iter:  602\n",
      "loss:  0.07269768616929197 iter:  603\n",
      "loss:  0.07250561924992592 iter:  604\n",
      "loss:  0.07221514001382665 iter:  605\n",
      "loss:  0.072283715546857 iter:  606\n",
      "loss:  0.07218503563658782 iter:  607\n",
      "loss:  0.07194512005636755 iter:  608\n",
      "loss:  0.07190619144586206 iter:  609\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.071906\n",
      "  -> Conv Check: dS=5.6e-01, dPhi=1.1e-01, dLoss=2.3e-03\n",
      "\n",
      "==================== CYCLE 4 ====================\n",
      "\n",
      "[Step] Stochastic Decomposition (k=10)\n",
      "loss:  0.07190619144586206 iter:  610\n",
      "loss:  0.07194010996613463 iter:  611\n",
      "loss:  0.07185975471401217 iter:  612\n",
      "loss:  0.07190297412678276 iter:  613\n",
      "loss:  0.07188705179437738 iter:  614\n",
      "loss:  0.07192913872287804 iter:  615\n",
      "loss:  0.07192830214439606 iter:  616\n",
      "loss:  0.07190860614125211 iter:  617\n",
      "loss:  0.07192098217758629 iter:  618\n",
      "loss:  0.0719223569422687 iter:  619\n",
      "loss:  0.07188795717629372 iter:  620\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.07190619144586206 iter:  621\n",
      "loss:  0.328064567342799 iter:  622\n",
      "loss:  0.2625719881657935 iter:  623\n",
      "loss:  1.4640066158653313 iter:  624\n",
      "loss:  0.21093283552863273 iter:  625\n",
      "loss:  0.23735031164173376 iter:  626\n",
      "loss:  0.28733888280090975 iter:  627\n",
      "loss:  0.2430415957944018 iter:  628\n",
      "loss:  0.2127045694131771 iter:  629\n",
      "loss:  0.11819113689893136 iter:  630\n",
      "loss:  0.20753591879137434 iter:  631\n",
      "loss:  0.08891231383033317 iter:  632\n",
      "loss:  0.1774868729944444 iter:  633\n",
      "loss:  0.08718799491595879 iter:  634\n",
      "loss:  0.08186110212849299 iter:  635\n",
      "loss:  0.0856928011021203 iter:  636\n",
      "loss:  0.15111185801157695 iter:  637\n",
      "loss:  0.07775285354721678 iter:  638\n",
      "loss:  0.07293939461715696 iter:  639\n",
      "loss:  0.0718146105656382 iter:  640\n",
      "loss:  0.07194582301349195 iter:  641\n",
      "loss:  0.07201254443788939 iter:  642\n",
      "loss:  0.07187253547893742 iter:  643\n",
      "loss:  0.2625719881652397 iter:  644\n",
      "loss:  0.32806456734293826 iter:  645\n",
      "loss:  1.4640066158653313 iter:  646\n",
      "loss:  0.21093283553111813 iter:  647\n",
      "loss:  0.2373503116409917 iter:  648\n",
      "loss:  0.2873388827998502 iter:  649\n",
      "loss:  0.24304159579491755 iter:  650\n",
      "loss:  0.21270456941633972 iter:  651\n",
      "loss:  0.11819113690067676 iter:  652\n",
      "loss:  0.20753591879112346 iter:  653\n",
      "loss:  0.08891231383884768 iter:  654\n",
      "loss:  0.17748687299532862 iter:  655\n",
      "loss:  0.0871879949087499 iter:  656\n",
      "loss:  0.08186110183771278 iter:  657\n",
      "loss:  0.0856928011427244 iter:  658\n",
      "loss:  0.15111186563238507 iter:  659\n",
      "loss:  0.07256119788912992 iter:  660\n",
      "loss:  0.07365417618448321 iter:  661\n",
      "loss:  0.07209176377097323 iter:  662\n",
      "loss:  0.07212597492646414 iter:  663\n",
      "loss:  0.07181555565322088 iter:  664\n",
      "loss:  0.07181530342909308 iter:  665\n",
      "loss:  0.07181414451468308 iter:  666\n",
      "loss:  0.07185745997829157 iter:  667\n",
      "loss:  0.0718141187359114 iter:  668\n",
      "loss:  0.07181411872275048 iter:  669\n",
      "loss:  0.07181411872343704 iter:  670\n",
      "loss:  0.0718141187254212 iter:  671\n",
      "loss:  0.07181411872025334 iter:  672\n",
      "loss:  0.07181411872242334 iter:  673\n",
      "loss:  0.2625719881652353 iter:  674\n",
      "loss:  0.3280645673421643 iter:  675\n",
      "loss:  1.4640066438665407 iter:  676\n",
      "loss:  0.21093283476361752 iter:  677\n",
      "loss:  0.23735031159449893 iter:  678\n",
      "loss:  0.2873388828789992 iter:  679\n",
      "loss:  0.24304159616809842 iter:  680\n",
      "loss:  0.21270456872192842 iter:  681\n",
      "loss:  0.11819114420630268 iter:  682\n",
      "loss:  0.20753591993254802 iter:  683\n",
      "loss:  0.08891230444421007 iter:  684\n",
      "loss:  0.17748687093617785 iter:  685\n",
      "loss:  0.08718800043686936 iter:  686\n",
      "loss:  0.08186108629357951 iter:  687\n",
      "loss:  0.08569280742405212 iter:  688\n",
      "loss:  0.15111226748902248 iter:  689\n",
      "loss:  0.07256120017022823 iter:  690\n",
      "  -> Loss: 0.071814 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.07181411872025334 iter:  691\n",
      "loss:  0.07181518904604935 iter:  692\n",
      "loss:  0.07181363474788892 iter:  693\n",
      "loss:  0.07181421468638031 iter:  694\n",
      "loss:  0.07181432727660382 iter:  695\n",
      "loss:  0.07181385080805294 iter:  696\n",
      "loss:  0.07181410658670138 iter:  697\n",
      "  -> Realigned. Top Eigenvals: [13469.20325933  6984.38146011  1112.72275351]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.07181411872025334 iter:  698\n",
      "loss:  0.07179169049454276 iter:  699\n",
      "loss:  0.0718046223670252 iter:  700\n",
      "loss:  0.0718129930553193 iter:  701\n",
      "loss:  0.07181995264578796 iter:  702\n",
      "loss:  0.07180766675289516 iter:  703\n",
      "loss:  0.07181447432978985 iter:  704\n",
      "loss:  0.07179382502511847 iter:  705\n",
      "loss:  0.07179278941507404 iter:  706\n",
      "loss:  0.07178668525303536 iter:  707\n",
      "loss:  0.07177493594045581 iter:  708\n",
      "loss:  0.07177674423854669 iter:  709\n",
      "loss:  0.07177381924607062 iter:  710\n",
      "loss:  0.07176438162587571 iter:  711\n",
      "loss:  0.0717634761794896 iter:  712\n",
      "loss:  0.07175330640185766 iter:  713\n",
      "loss:  0.07176004403643024 iter:  714\n",
      "loss:  0.07175405452368885 iter:  715\n",
      "loss:  0.07174192052224462 iter:  716\n",
      "loss:  0.07173436297629582 iter:  717\n",
      "loss:  0.07174696370838336 iter:  718\n",
      "loss:  0.07175554104225605 iter:  719\n",
      "loss:  0.07174620181140258 iter:  720\n",
      "loss:  0.07174771792144084 iter:  721\n",
      "loss:  0.07173633372263527 iter:  722\n",
      "loss:  0.0717356565504782 iter:  723\n",
      "loss:  0.07175547807674684 iter:  724\n",
      "loss:  0.07174113006322147 iter:  725\n",
      "loss:  0.07174119744964418 iter:  726\n",
      "loss:  0.07172294855548708 iter:  727\n",
      "loss:  0.07171131387578163 iter:  728\n",
      "loss:  0.07172747610215313 iter:  729\n",
      "loss:  0.07172017238452036 iter:  730\n",
      "loss:  0.07170908915676708 iter:  731\n",
      "loss:  0.07169802901012551 iter:  732\n",
      "loss:  0.07171153343996843 iter:  733\n",
      "loss:  0.0717028241886308 iter:  734\n",
      "loss:  0.07168031549283228 iter:  735\n",
      "loss:  0.07165458989059356 iter:  736\n",
      "loss:  0.07168620150714183 iter:  737\n",
      "loss:  0.0716605867124968 iter:  738\n",
      "loss:  0.07166227725826012 iter:  739\n",
      "loss:  0.07164447864482261 iter:  740\n",
      "loss:  0.07162491729435345 iter:  741\n",
      "loss:  0.07162593881505053 iter:  742\n",
      "loss:  0.07159344405969711 iter:  743\n",
      "loss:  0.07154219407458101 iter:  744\n",
      "loss:  0.07158276530484918 iter:  745\n",
      "loss:  0.07157121309366203 iter:  746\n",
      "loss:  0.07152741620304008 iter:  747\n",
      "loss:  0.07146330748583983 iter:  748\n",
      "loss:  0.0714920310354713 iter:  749\n",
      "loss:  0.07147124015604128 iter:  750\n",
      "loss:  0.0714115530783802 iter:  751\n",
      "loss:  0.07131861973958158 iter:  752\n",
      "loss:  0.07138177143012658 iter:  753\n",
      "loss:  0.07130785332759278 iter:  754\n",
      "loss:  0.0711869642633829 iter:  755\n",
      "loss:  0.07122752233484132 iter:  756\n",
      "loss:  0.07119676447294278 iter:  757\n",
      "loss:  0.07112471198847986 iter:  758\n",
      "loss:  0.07098673887724874 iter:  759\n",
      "loss:  0.07095430300523176 iter:  760\n",
      "loss:  0.07072284852559642 iter:  761\n",
      "loss:  0.0708827647979728 iter:  762\n",
      "loss:  0.07072933752591369 iter:  763\n",
      "loss:  0.07073930343815006 iter:  764\n",
      "loss:  0.0705510586394693 iter:  765\n",
      "loss:  0.07027937544585255 iter:  766\n",
      "loss:  0.07032589403313264 iter:  767\n",
      "loss:  0.07030218862877104 iter:  768\n",
      "loss:  0.07014091460047715 iter:  769\n",
      "loss:  0.0698296682298299 iter:  770\n",
      "loss:  0.06996220434540196 iter:  771\n",
      "loss:  0.0698354199971704 iter:  772\n",
      "loss:  0.06962000848862132 iter:  773\n",
      "loss:  0.06946251162798557 iter:  774\n",
      "loss:  0.0694623473095361 iter:  775\n",
      "loss:  0.06919026525258788 iter:  776\n",
      "loss:  0.0692971504848296 iter:  777\n",
      "loss:  0.06914370209733528 iter:  778\n",
      "loss:  0.06935009379169028 iter:  779\n",
      "loss:  0.06940644273121974 iter:  780\n",
      "loss:  0.06917582282392411 iter:  781\n",
      "loss:  0.06989890268994056 iter:  782\n",
      "loss:  0.06938686141199048 iter:  783\n",
      "loss:  0.06895568753865486 iter:  784\n",
      "loss:  0.06878144860677607 iter:  785\n",
      "loss:  0.06909769296076303 iter:  786\n",
      "loss:  0.06887728581353181 iter:  787\n",
      "loss:  0.06883304283927202 iter:  788\n",
      "loss:  0.06889072850391566 iter:  789\n",
      "loss:  0.06873556861881022 iter:  790\n",
      "loss:  0.06880297611597395 iter:  791\n",
      "loss:  0.0685788784467231 iter:  792\n",
      "loss:  0.06850759304763075 iter:  793\n",
      "loss:  0.06892565757748793 iter:  794\n",
      "loss:  0.06871184341237035 iter:  795\n",
      "loss:  0.06859166645261196 iter:  796\n",
      "loss:  0.06848161644446465 iter:  797\n",
      "loss:  0.06847601371326986 iter:  798\n",
      "loss:  0.06864846894998909 iter:  799\n",
      "loss:  0.06846460054497015 iter:  800\n",
      "loss:  0.06856029870382598 iter:  801\n",
      "loss:  0.0684190046720758 iter:  802\n",
      "loss:  0.06856519813302374 iter:  803\n",
      "loss:  0.0689163693767109 iter:  804\n",
      "loss:  0.06848723019383948 iter:  805\n",
      "loss:  0.06843246250819084 iter:  806\n",
      "loss:  0.06856031427560742 iter:  807\n",
      "loss:  0.06844991872886068 iter:  808\n",
      "loss:  0.06833006331034762 iter:  809\n",
      "loss:  0.0682837174109465 iter:  810\n",
      "loss:  0.0684173770633818 iter:  811\n",
      "loss:  0.0684533636106305 iter:  812\n",
      "loss:  0.06838453331318425 iter:  813\n",
      "loss:  0.06835393737742415 iter:  814\n",
      "loss:  0.06827188892888457 iter:  815\n",
      "loss:  0.06828163555272873 iter:  816\n",
      "loss:  0.06840411690490535 iter:  817\n",
      "loss:  0.06828111421210013 iter:  818\n",
      "loss:  0.06822126132688203 iter:  819\n",
      "loss:  0.06824648560009777 iter:  820\n",
      "loss:  0.06843208792941158 iter:  821\n",
      "loss:  0.06829750823167692 iter:  822\n",
      "loss:  0.06838391220563136 iter:  823\n",
      "loss:  0.06829468268796454 iter:  824\n",
      "loss:  0.06826606588151388 iter:  825\n",
      "loss:  0.06830065482090746 iter:  826\n",
      "loss:  0.06826188849671558 iter:  827\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.068221\n",
      "  -> Conv Check: dS=6.2e-01, dPhi=1.8e-01, dLoss=3.7e-03\n",
      "\n",
      "==================== CYCLE 5 ====================\n",
      "\n",
      "[Step] Stochastic Decomposition (k=10)\n",
      "loss:  0.06822126132688203 iter:  828\n",
      "loss:  0.0682023651598657 iter:  829\n",
      "loss:  0.06820624946738005 iter:  830\n",
      "loss:  0.06821138131802235 iter:  831\n",
      "loss:  0.06828554003137448 iter:  832\n",
      "loss:  0.06824303885261293 iter:  833\n",
      "loss:  0.06823662707615177 iter:  834\n",
      "loss:  0.06821502512846297 iter:  835\n",
      "loss:  0.0681637791720773 iter:  836\n",
      "loss:  0.0681814705198014 iter:  837\n",
      "loss:  0.06823086622214686 iter:  838\n",
      "  -> Split: Stiff=1, Sloppy=6\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  0.06822126132688203 iter:  839\n",
      "loss:  0.309448866302707 iter:  840\n",
      "loss:  15.774310617815273 iter:  841\n",
      "loss:  0.2969078413445124 iter:  842\n",
      "loss:  0.30529723882440835 iter:  843\n",
      "loss:  0.28615844762324744 iter:  844\n",
      "loss:  0.3003681621933808 iter:  845\n",
      "loss:  0.28665514904037237 iter:  846\n",
      "loss:  0.28608440275799085 iter:  847\n",
      "loss:  0.2860566167728921 iter:  848\n",
      "loss:  0.28605624217289105 iter:  849\n",
      "loss:  0.28605623671637825 iter:  850\n",
      "loss:  0.2860562370000447 iter:  851\n",
      "loss:  0.28605623747295816 iter:  852\n",
      "  -> Loss: 0.286056 (Bounded)\n",
      "\n",
      "[Step] Realigning Sloppy Space\n",
      "loss:  0.28605623671637825 iter:  853\n",
      "loss:  0.2860662505081939 iter:  854\n",
      "loss:  0.2860536370439848 iter:  855\n",
      "loss:  0.2860585574699424 iter:  856\n",
      "loss:  0.286056689061124 iter:  857\n",
      "loss:  0.2860560969167282 iter:  858\n",
      "loss:  0.28605628669277183 iter:  859\n",
      "  -> Realigned. Top Eigenvals: [9.71225658e+03 1.28711622e+01 4.46981800e+00]\n",
      "\n",
      "[Step] Sloppy Opt (Nelder-Mead) Dim:6\n",
      "loss:  0.28605623671637825 iter:  860\n",
      "loss:  0.2863209754833738 iter:  861\n",
      "loss:  0.28609689058982724 iter:  862\n",
      "loss:  0.28607033552980593 iter:  863\n",
      "loss:  0.2860655019451723 iter:  864\n",
      "loss:  0.28605510980887244 iter:  865\n",
      "loss:  0.2860570627982808 iter:  866\n",
      "loss:  0.28581921182260606 iter:  867\n",
      "loss:  0.285578102273034 iter:  868\n",
      "loss:  0.2858609174553669 iter:  869\n",
      "loss:  0.28581829496506 iter:  870\n",
      "loss:  0.2857419398399804 iter:  871\n",
      "loss:  0.28564735809896746 iter:  872\n",
      "loss:  0.2855154885469483 iter:  873\n",
      "loss:  0.28525597423308974 iter:  874\n",
      "loss:  0.285257399113085 iter:  875\n",
      "loss:  0.2852452724102713 iter:  876\n",
      "loss:  0.28495516409998395 iter:  877\n",
      "loss:  0.28500467957282244 iter:  878\n",
      "loss:  0.28484173031138255 iter:  879\n",
      "loss:  0.2844307936626405 iter:  880\n",
      "loss:  0.28453768608724994 iter:  881\n",
      "loss:  0.2842737679819255 iter:  882\n",
      "loss:  0.28370371561167634 iter:  883\n",
      "loss:  0.2840571394499235 iter:  884\n",
      "loss:  0.28371064790979206 iter:  885\n",
      "loss:  0.2835237951727776 iter:  886\n",
      "loss:  0.2829329786697691 iter:  887\n",
      "loss:  0.2829686641799597 iter:  888\n",
      "loss:  0.2828265782802705 iter:  889\n",
      "loss:  0.2822265288074148 iter:  890\n",
      "loss:  0.282298114501117 iter:  891\n",
      "loss:  0.2820922343975659 iter:  892\n",
      "loss:  0.28161912843577647 iter:  893\n",
      "loss:  0.28173321461182704 iter:  894\n",
      "loss:  0.2815886847334463 iter:  895\n",
      "loss:  0.2819689567214339 iter:  896\n",
      "loss:  0.2815350418121301 iter:  897\n",
      "loss:  0.28179426478635755 iter:  898\n",
      "loss:  0.2815782395917158 iter:  899\n",
      "loss:  0.2816507014539058 iter:  900\n",
      "loss:  0.2820429116982474 iter:  901\n",
      "loss:  0.28162229123962157 iter:  902\n",
      "loss:  0.28199394262379757 iter:  903\n",
      "loss:  0.2815508135544769 iter:  904\n",
      "loss:  0.28168993753665916 iter:  905\n",
      "loss:  0.28154857392133104 iter:  906\n",
      "loss:  0.2817100625527945 iter:  907\n",
      "loss:  0.2815376445685739 iter:  908\n",
      "loss:  0.2816915275604022 iter:  909\n",
      "loss:  0.28154018003223763 iter:  910\n",
      "loss:  0.28148913983329227 iter:  911\n",
      "loss:  0.2815105773539118 iter:  912\n",
      "loss:  0.28158577355696685 iter:  913\n",
      "loss:  0.2815242848405925 iter:  914\n",
      "loss:  0.28163476219554867 iter:  915\n",
      "loss:  0.2815117839122728 iter:  916\n",
      "loss:  0.2815043818352237 iter:  917\n",
      "loss:  0.2815326972492548 iter:  918\n",
      "loss:  0.2814748323305507 iter:  919\n",
      "loss:  0.2814689441649081 iter:  920\n",
      "loss:  0.28145512226962793 iter:  921\n",
      "loss:  0.28145041876188104 iter:  922\n",
      "loss:  0.28146538065177784 iter:  923\n",
      "loss:  0.28143340108126447 iter:  924\n",
      "loss:  0.2814541460828846 iter:  925\n",
      "loss:  0.2813754073793154 iter:  926\n",
      "loss:  0.28131603869593236 iter:  927\n",
      "loss:  0.2813492571955453 iter:  928\n",
      "loss:  0.28134446521990597 iter:  929\n",
      "loss:  0.2813053835779584 iter:  930\n",
      "loss:  0.2812864073300903 iter:  931\n",
      "loss:  0.2812887486402675 iter:  932\n",
      "loss:  0.28120938514142346 iter:  933\n",
      "loss:  0.28117234284623915 iter:  934\n",
      "loss:  0.28116572395916434 iter:  935\n",
      "loss:  0.2811855918781985 iter:  936\n",
      "loss:  0.28108001549861333 iter:  937\n",
      "loss:  0.2809534999926532 iter:  938\n",
      "loss:  0.28112284699367945 iter:  939\n",
      "loss:  0.28092349340877354 iter:  940\n",
      "loss:  0.28074595156005105 iter:  941\n",
      "loss:  0.2807822003652688 iter:  942\n",
      "loss:  0.2806436470045851 iter:  943\n",
      "loss:  0.28039852423564127 iter:  944\n",
      "loss:  0.2807819716802053 iter:  945\n",
      "loss:  0.2803211542855604 iter:  946\n",
      "loss:  0.2799315155211125 iter:  947\n",
      "loss:  0.2801097348003067 iter:  948\n",
      "loss:  0.2798448563995913 iter:  949\n",
      "loss:  0.2793221197742426 iter:  950\n",
      "loss:  0.27950870016303514 iter:  951\n",
      "loss:  0.27956730478959735 iter:  952\n",
      "loss:  0.27901923352171093 iter:  953\n",
      "loss:  0.27853671865971397 iter:  954\n",
      "loss:  0.2783388890768758 iter:  955\n",
      "loss:  0.2773089860546882 iter:  956\n",
      "loss:  0.2776918354124505 iter:  957\n",
      "loss:  0.2771412481229476 iter:  958\n",
      "loss:  0.2757650363686503 iter:  959\n",
      "loss:  0.2763667434186543 iter:  960\n",
      "loss:  0.27546504470389244 iter:  961\n",
      "loss:  0.27373970619267546 iter:  962\n",
      "loss:  0.27425895500744535 iter:  963\n",
      "loss:  0.27322271488807454 iter:  964\n",
      "loss:  0.27110881455020613 iter:  965\n",
      "loss:  0.2713324215902516 iter:  966\n",
      "loss:  0.26978454076901165 iter:  967\n",
      "loss:  0.2660903621795404 iter:  968\n",
      "loss:  0.2678753259217045 iter:  969\n",
      "loss:  0.2651571421132269 iter:  970\n",
      "loss:  0.2597699315012495 iter:  971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Root finder converged (message: The solution converged.), but solution check failed.\n",
      "WARNING:root:Condition 6 ({'C': np.float64(0.0), 'CO': np.float64(0.0), 'CO2': np.int64(0), 'O': np.float64(1.055127347631181e+16), 'O2': np.int64(34191785973519152), 'O3': np.float64(1128037915895.378), 'Tgas': np.float64(440.9518449183849), 'Tnw': np.float64(337.843817904925), 'Tw': np.float64(323.15), 'current': np.int64(40), 'frac_CO2': np.float64(0.0), 'pressure': np.float64(2.0), 'fluxO': np.float64(1.763717084169756e+20), 'fluxO2': np.float64(4.041390633812239e+20), 'fluxO3': np.float64(1.0886470806177898e+16), 'fluxC': np.float64(0.0), 'fluxCO': np.float64(0.0), 'fluxCO2': np.float64(0.0), 'EavgMB': 0.001, 'Ion': np.float64(4000000000000000.0)}): Solver failed or solution check failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.26201817514452286 iter:  972\n",
      "loss:  0.25852052403838 iter:  973\n",
      "loss:  0.25105402617912237 iter:  974\n",
      "loss:  0.2537847928823587 iter:  975\n",
      "loss:  0.2502442230232553 iter:  976\n",
      "loss:  0.24137173065453316 iter:  977\n",
      "loss:  0.24222173278413617 iter:  978\n",
      "loss:  0.2356213672893012 iter:  979\n",
      "loss:  0.21993463095577398 iter:  980\n",
      "loss:  0.22566855350728632 iter:  981\n",
      "loss:  0.2168543571366808 iter:  982\n",
      "loss:  0.20027305592017897 iter:  983\n",
      "loss:  0.2030529948357098 iter:  984\n",
      "loss:  0.19780932567030757 iter:  985\n",
      "loss:  0.20647599372840447 iter:  986\n",
      "loss:  0.1967318850326978 iter:  987\n",
      "loss:  0.21362307392984625 iter:  988\n",
      "loss:  0.20691512075539367 iter:  989\n",
      "  -> Max evals reached.\n",
      "  -> Loss: 0.196732\n",
      "  -> Conv Check: dS=8.1e-01, dPhi=9.4e-01, dLoss=1.3e-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_iters_tot = 1300\n",
    "filename_results = \"results/results_hier2_train_V4.h5\"\n",
    "\n",
    "pipeline = [\n",
    "    ('decompose_stochastic', {'percent_info': 0.95, 'k_samples': 10}),\n",
    "    ('optimize_stiff', {'max_iter': 70, 'bound_range': 1.2}),\n",
    "    ('realign_sloppy', {}),\n",
    "    ('optimize_sloppy', {'max_iter': 130}),\n",
    "    ('check_convergence', {'tol_s': 1e-4})\n",
    "]\n",
    "\n",
    "# Instantiate\n",
    "opt_hier = ha.HierarchicalOptimizer(optimizer, params_default_norm, pipeline=pipeline)\n",
    "opt_hier.run(max_cycles=5, max_iter=max_iters_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filename_results, \"w\") as f:\n",
    "    \n",
    "    f.create_dataset(\"best_loss\", data=opt_hier.history['best_loss'])\n",
    "    f.create_dataset(\"iters\", data=opt_hier.history['iters'])\n",
    "    f.create_dataset(\"best_params\", data=opt_hier.history['best_params'])\n",
    "    \n",
    "    f.create_dataset(\"best_params_end\", data=opt_hier.phi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qp_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
