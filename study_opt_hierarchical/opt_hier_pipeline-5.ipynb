{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PATH = os.path.dirname(os.path.abspath(os.curdir))\n",
    "if PATH not in sys.path:\n",
    "    sys.path.insert(0, PATH)\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "import src.Optimizer as opt\n",
    "import src.simulation_setup as setup\n",
    "import hierarchical_algorithm as ha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Buffer:  /Users/joseafonso/Desktop/PlasmaDM/Buffer_Data/Experimental_data_CO_O_merged_train.hdf5\n",
      "  d[CO2_F]/dt = -CO2_F*r_29 + r_28*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_F]/dt = -CO_F*O_F*r_35 - 0.02*CO_F*O_S*r_40 - 0.02*CO_F*Odb_S*r_61 - 0.02*CO_F*Vdb_S*r_60 - CO_F*r_31 - CO_F*r_33 - 0.02*CO_F*r_36*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_30*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_S]/dt = CO_F*r_36*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) - CO_S*O_F*r_39 - CO_S*r_37 - CO_S*r_43 - CO_S*r_44 - CO_S*r_45 - CO_S*r_46 + r_32*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[COdb_S]/dt = CO_F*Vdb_S*r_60 - COdb_S*O_F*r_62 - COdb_S*r_54 - COdb_S*r_55 - COdb_S*r_56 - COdb_S*r_57 - COdb_S*r_59 + Vdb_S*r_49\n",
      "  d[O2_F]/dt = -O2_F*O_F*r_15 - O2_F*r_10 - O2_F*r_12 - O2_F*r_14 + r_9*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_F]/dt = -CO_F*O_F*r_35 - 0.02*CO_S*O_F*r_39 - 0.02*COdb_S*O_F*r_62 - O2_F*O_F*r_15 - 2*O_F**2*r_8 - 0.02*O_F*O_S*r_7 - 0.02*O_F*Odb_S*r_27 - 0.02*O_F*Vdb_S*r_26 - O_F*r_11 - O_F*r_2 - O_F*r_34 - O_F*r_4 - 0.02*O_F*r_5*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_1*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_S]/dt = -CO_F*O_S*r_40 - O_F*O_S*r_7 + O_F*r_5*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) - O_S*r_16 - O_S*r_17 - O_S*r_38 - O_S*r_41 - O_S*r_42 - O_S*r_6 + r_3*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[Odb_S]/dt = -CO_F*Odb_S*r_61 - O_F*Odb_S*r_27 + O_F*Vdb_S*r_26 - Odb_S*r_23 - Odb_S*r_24 - Odb_S*r_25 - Odb_S*r_52 - Odb_S*r_53 - Odb_S*r_58 + Vdb_S*r_20\n",
      "  d[Vdb_S]/dt = CO_F*Odb_S*r_61 - CO_F*Vdb_S*r_60 + CO_S*r_43 + CO_S*r_44 + CO_S*r_45 + CO_S*r_46 + COdb_S*O_F*r_62 + COdb_S*r_59 + O_F*Odb_S*r_27 - O_F*Vdb_S*r_26 + O_S*r_16 + O_S*r_17 + O_S*r_41 + O_S*r_42 + Odb_S*r_25 + Odb_S*r_58 - Vdb_S*r_20 - Vdb_S*r_21 - Vdb_S*r_22 - Vdb_S*r_49 - Vdb_S*r_50 - Vdb_S*r_51 + r_18*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_19*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_47*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0) + r_48*(-CO_S - COdb_S - O_S - Odb_S - Vdb_S + 1.0)\n"
     ]
    }
   ],
   "source": [
    "##* create simulator \n",
    "\n",
    "buffer_train = \"Experimental_data_CO_O_merged_train.hdf5\"\n",
    "\n",
    "const_dict, sim = setup.create_common_simulator(PATH, data_file=buffer_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Define Parameters and Bounds\n",
    "lower_bounds_dict = {\n",
    "    'A_d': 1e-8, 'B_d': 1e-8, 'E_d': 0.0, \n",
    "    'SF_30': 1e-5, 'SF_31': 1e-5, 'SF_32': 1e-5, 'SF_33': 1e-5, 'SF_34': 1e-5, 'SF_35': 1e-5, 'SF_36': 1e-5, 'SF_37': 1e-5, 'SF_38': 1e-5, 'SF_39': 1e-5,\n",
    "    'SF_49': 1e-5, 'SF_50': 1e-5, 'SF_51': 1e-5, 'SF_52': 1e-5, 'SF_53': 1e-5, 'SF_54': 1e-5, 'SF_55': 1e-5, 'SF_56': 1e-5, 'SF_57': 1e-5, 'SF_58': 1e-5, 'SF_59': 1e-5, 'SF_60': 1e-5, 'SF_61': 1e-5, 'SF_62': 1e-5,\n",
    "    'Emin': 1.0, 'Ealpha': 2000\n",
    "}\n",
    "\n",
    "upper_bounds_dict = {\n",
    "    'A_d': 5e-1, 'B_d': 1e-2, 'E_d': 30.0, \n",
    "    'SF_30': 1.0, 'SF_31': 1.0, 'SF_32': 1.0,  'SF_33': 1.0, 'SF_34': 1.0, 'SF_35': 1.0, 'SF_36': 1.0, 'SF_37': 1.0, 'SF_38': 1.0, 'SF_39': 1.0,\n",
    "    'SF_49': 1.0, 'SF_50': 1.0, 'SF_51': 1.0, 'SF_52': 1.0, 'SF_53': 1.0, 'SF_54': 1.0, 'SF_55': 1.0, 'SF_56': 1.0, 'SF_57': 1.0, 'SF_58': 1.0, 'SF_59': 1.0, 'SF_60': 1.0, 'SF_61': 1.0, 'SF_62': 1.0,\n",
    "    'Emin': 5.0, 'Ealpha': 5000\n",
    "}\n",
    "\n",
    "params_default_dict = {\n",
    "    'A_d': 0.02634, 'B_d': 7.67e-4, 'E_d': 10.75, \n",
    "    'SF_30': 1.0, 'SF_31': 1.0, 'SF_32': 1e-2,  'SF_33': 1e-1, 'SF_34': 1e-1, 'SF_35': 1e-2, 'SF_36': 1e-1, 'SF_37': 1e-1, 'SF_38': 1e-1, 'SF_39': 1e-1,\n",
    "    'SF_49': 1e-2, 'SF_50': 1.0, 'SF_51': 1.0, 'SF_52': 1.0, 'SF_53': 1e-1, 'SF_54': 1e-1, 'SF_55': 1.0, 'SF_56': 1.0, 'SF_57': 1.0, 'SF_58': 1e-1, 'SF_59': 1e-1, 'SF_60': 1e-2, 'SF_61': 1e-1, 'SF_62': 1e-1,\n",
    "    'Emin': 3.4, 'Ealpha': 3000\n",
    "}\n",
    "\n",
    "lower_bounds = np.array(list(lower_bounds_dict.values()))\n",
    "upper_bounds = np.array(list(upper_bounds_dict.values()))\n",
    "params_default_init = np.array(list(params_default_dict.values()))\n",
    "params_default_norm = (params_default_init - lower_bounds) * np.reciprocal(upper_bounds - lower_bounds)\n",
    "\n",
    "\n",
    "def func_optimization(params_input, flag='numpy'):\n",
    "    \n",
    "    ##! normalize variables\n",
    "    params = [0] * len(params_input)\n",
    "    for idx, param in enumerate(params_input):\n",
    "        params[idx] = lower_bounds[idx] + (upper_bounds[idx] - lower_bounds[idx]) * param\n",
    "    \n",
    "    A_d, B_d, E_d = params[0:3]\n",
    "    SF_30, SF_31, SF_32, SF_33, SF_34, SF_35, SF_36, SF_37, SF_38, SF_39 = params[3:13]\n",
    "    SF_49, SF_50, SF_51, SF_52, SF_53, SF_54, SF_55, SF_56, SF_57, SF_58, SF_59, SF_60, SF_61, SF_62 = params[13:27]\n",
    "    Emin, Ealpha = params[27:]\n",
    "    \n",
    "    if flag=='numpy':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * np.exp(E_d/(const_dict['R'] * T)))\n",
    "    elif flag=='torch':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * torch.exp(E_d/(const_dict['R'] * T)))\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "    \n",
    "    dict_mod_vec = [\n",
    "    {\"id\": 2, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 10, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 16, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    {\"id\": 18, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    \n",
    "    {\"id\": 31, \"rate\": None, \"model_dict\": {\"SF\": SF_31, \"nu_d\": nu_d_mod}},\n",
    "    \n",
    "    {\"id\": 30, \"rate\": None, \"model_dict\": {\"SF\": SF_30}},\n",
    "    {\"id\": 32, \"rate\": None, \"model_dict\": {\"SF\": SF_32}},\n",
    "    {\"id\": 33, \"rate\": None, \"model_dict\": {\"SF\": SF_33}},\n",
    "    {\"id\": 34, \"rate\": None, \"model_dict\": {\"SF\": SF_34}},\n",
    "    \n",
    "    {\"id\": 35, \"rate\": None, \"model_dict\": {\"SF\": SF_35}},\n",
    "    {\"id\": 36, \"rate\": None, \"model_dict\": {\"SF\": SF_36}},\n",
    "    {\"id\": 37, \"rate\": None, \"model_dict\": {\"SF\": SF_37}},\n",
    "    {\"id\": 38, \"rate\": None, \"model_dict\": {\"SF\": SF_38}},\n",
    "    {\"id\": 39, \"rate\": None, \"model_dict\": {\"SF\": SF_39}},\n",
    "    \n",
    "    {\"id\": 44, \"rate\": None, \"model_dict\": {\"Emin\": Emin}},\n",
    "    \n",
    "    {\"id\": 49, \"rate\": None, \"model_dict\": {\"SF\": SF_49}},\n",
    "    {\"id\": 50, \"rate\": None, \"model_dict\": {\"SF\": SF_50, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 51, \"rate\": None, \"model_dict\": {\"SF\": SF_51, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 52, \"rate\": None, \"model_dict\": {\"SF\": SF_52, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 53, \"rate\": None, \"model_dict\": {\"SF\": SF_53, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 54, \"rate\": None, \"model_dict\": {\"SF\": SF_54, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 55, \"rate\": None, \"model_dict\": {\"SF\": SF_55, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 56, \"rate\": None, \"model_dict\": {\"SF\": SF_56, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 57, \"rate\": None, \"model_dict\": {\"SF\": SF_57, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 58, \"rate\": None, \"model_dict\": {\"SF\": SF_58, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 59, \"rate\": None, \"model_dict\": {\"SF\": SF_59, \"Ealpha\": Ealpha}},\n",
    "    {\"id\": 60, \"rate\": None, \"model_dict\": {\"SF\": SF_60}},\n",
    "    {\"id\": 61, \"rate\": None, \"model_dict\": {\"SF\": SF_61}},\n",
    "    {\"id\": 62, \"rate\": None, \"model_dict\": {\"SF\": SF_62}}\n",
    "    ]\n",
    "    \n",
    "    return dict_mod_vec\n",
    "\n",
    "def loss_function(exp, teo, flag='numpy'):\n",
    "    func = ((teo-exp)**2)/(exp**2)\n",
    "    if flag == 'numpy':\n",
    "        return np.mean(func)\n",
    "    elif flag == 'torch':\n",
    "        return torch.mean(func)\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "\n",
    "\n",
    "# 4. Instantiate and Run Optimizer\n",
    "optimizer = opt.Optimizer(sim, \n",
    "                        lambda params: func_optimization(params, 'numpy'), \n",
    "                        lambda exp, teo: loss_function(exp, teo, 'numpy')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pipeline with 3 steps...\n",
      "\n",
      "==================== CYCLE 1 ====================\n",
      "loss:  783.7419346722897 iter:  1\n",
      "\n",
      "[Step] Exact Decomposition (N=29)\n",
      "loss:  783.7419346722897 iter:  2\n",
      "loss:  783.6131523007717 iter:  3\n",
      "loss:  783.4588661803213 iter:  4\n",
      "loss:  783.453832024195 iter:  5\n",
      "loss:  783.7419336532563 iter:  6\n",
      "loss:  783.741936985504 iter:  7\n",
      "loss:  783.7340133720129 iter:  8\n",
      "loss:  783.7419369463686 iter:  9\n",
      "loss:  783.7420760099274 iter:  10\n",
      "loss:  783.7419348499305 iter:  11\n",
      "loss:  783.7419246777588 iter:  12\n",
      "loss:  783.7422188437661 iter:  13\n",
      "loss:  783.741935576763 iter:  14\n",
      "loss:  783.7424510033659 iter:  15\n",
      "loss:  783.7419285330387 iter:  16\n",
      "loss:  783.7419345508315 iter:  17\n",
      "loss:  783.7419344957118 iter:  18\n",
      "loss:  783.7419345067668 iter:  19\n",
      "loss:  783.7419345616311 iter:  20\n",
      "loss:  783.7419359558129 iter:  21\n",
      "loss:  783.7419346595168 iter:  22\n",
      "loss:  783.7419346601969 iter:  23\n",
      "loss:  783.7419346323334 iter:  24\n",
      "loss:  783.7419349179166 iter:  25\n",
      "loss:  783.741936583019 iter:  26\n",
      "loss:  783.7419359623465 iter:  27\n",
      "loss:  783.7419359666237 iter:  28\n",
      "loss:  783.741936022117 iter:  29\n",
      "loss:  783.7418988237662 iter:  30\n",
      "loss:  783.7419406296566 iter:  31\n",
      "  -> Split: Stiff=1, Sloppy=4\n",
      "\n",
      "[Step] Stiff Opt (Powell) Dim:1\n",
      "loss:  783.7419346722897 iter:  32\n",
      "loss:  74606.32823493388 iter:  33\n",
      "loss:  0.6021741454008667 iter:  34\n",
      "loss:  0.8155411527160394 iter:  35\n",
      "loss:  0.7870810470999873 iter:  36\n",
      "loss:  28.589969339266574 iter:  37\n",
      "loss:  0.268213405638953 iter:  38\n",
      "loss:  0.30152982524362937 iter:  39\n",
      "loss:  0.19590094893108967 iter:  40\n",
      "loss:  0.17530032111198415 iter:  41\n",
      "loss:  0.17094286803532438 iter:  42\n",
      "loss:  0.16769946634465097 iter:  43\n",
      "loss:  0.16771191264907237 iter:  44\n",
      "loss:  0.16769832221457268 iter:  45\n",
      "loss:  0.16769847615504802 iter:  46\n",
      "loss:  0.16769868165383747 iter:  47\n",
      "loss:  0.7077451329855132 iter:  48\n",
      "loss:  74606.32824052573 iter:  49\n",
      "loss:  0.6021741454008667 iter:  50\n",
      "loss:  0.8155411527160394 iter:  51\n",
      "loss:  0.7870810471065836 iter:  52\n",
      "loss:  28.589969339266574 iter:  53\n",
      "loss:  0.268213405638953 iter:  54\n",
      "loss:  0.3015298252442995 iter:  55\n",
      "loss:  0.19590094893151067 iter:  56\n",
      "loss:  0.17530032111136326 iter:  57\n",
      "loss:  0.1709428680339194 iter:  58\n",
      "loss:  0.1676994663437506 iter:  59\n",
      "loss:  0.1677119126471622 iter:  60\n",
      "loss:  0.167698322214027 iter:  61\n",
      "loss:  0.16769831190012738 iter:  62\n",
      "loss:  0.16769831776920993 iter:  63\n",
      "loss:  0.6021741454000772 iter:  64\n",
      "loss:  74606.3282403286 iter:  65\n",
      "loss:  0.8155411527081019 iter:  66\n",
      "loss:  0.7870810471126306 iter:  67\n",
      "loss:  28.589969339287553 iter:  68\n",
      "loss:  0.26821340563997426 iter:  69\n",
      "loss:  0.30152982524537786 iter:  70\n",
      "loss:  0.19590094893288845 iter:  71\n",
      "loss:  0.17530032111051636 iter:  72\n",
      "loss:  0.17094286803413003 iter:  73\n",
      "loss:  0.16769946634684 iter:  74\n",
      "loss:  0.16771191264956592 iter:  75\n",
      "loss:  0.16769832221468578 iter:  76\n",
      "loss:  0.16769831190682177 iter:  77\n",
      "loss:  0.16769831189575232 iter:  78\n",
      "loss:  0.16769831189944992 iter:  79\n",
      "loss:  0.1676983118988042 iter:  80\n",
      "loss:  0.1676983118961618 iter:  81\n",
      "loss:  0.1676983118961034 iter:  82\n",
      "loss:  0.16769831189597323 iter:  83\n",
      "loss:  0.16769831189625006 iter:  84\n",
      "loss:  0.1676983118985976 iter:  85\n",
      "loss:  0.1676983118959947 iter:  86\n",
      "loss:  0.16769831190050902 iter:  87\n",
      "loss:  0.16769831189890533 iter:  88\n",
      "loss:  0.16769831189670117 iter:  89\n",
      "  -> Loss: 0.167698 (Bounded)\n",
      "\n",
      "[Step] Combined Manifold Opt (Dim:5): Aligning -> Nelder-Mead\n",
      "loss:  0.16769831189575232 iter:  90\n",
      "loss:  0.16769833503124834 iter:  91\n",
      "loss:  0.16771275228064855 iter:  92\n",
      "loss:  0.1677326519437265 iter:  93\n",
      "loss:  0.16769483663051482 iter:  94\n",
      "loss:  0.1676993040249285 iter:  95\n",
      "  -> Aligned Spectrum: [5.19308615e+04 1.04754535e+04 5.44767780e+01 1.64883082e+01\n",
      " 8.83749253e-01]\n",
      "  -> Optimizing (Nelder-Mead, Budget: 245)...\n",
      "loss:  0.16769831189575232 iter:  96\n",
      "loss:  0.19386888398374455 iter:  97\n",
      "loss:  0.11212324593475115 iter:  98\n",
      "loss:  0.16616210841571888 iter:  99\n",
      "loss:  0.1663956467741122 iter:  100\n",
      "loss:  0.1734501208386441 iter:  101\n",
      "loss:  0.1843740459985737 iter:  102\n",
      "loss:  0.17128101441443735 iter:  103\n",
      "loss:  0.14653593087858166 iter:  104\n",
      "loss:  0.17438319196904983 iter:  105\n",
      "loss:  0.16438514676845087 iter:  106\n",
      "loss:  0.13092699650631578 iter:  107\n",
      "loss:  0.12211989550177837 iter:  108\n",
      "loss:  0.3148826901924018 iter:  109\n",
      "loss:  0.15788526724441615 iter:  110\n",
      "loss:  0.13296551425270867 iter:  111\n",
      "loss:  0.15117575399976382 iter:  112\n",
      "loss:  0.1651814714591164 iter:  113\n",
      "loss:  0.11983029899025621 iter:  114\n",
      "loss:  0.12652181604176466 iter:  115\n",
      "loss:  0.11978220215504452 iter:  116\n",
      "loss:  0.1383215542589939 iter:  117\n",
      "loss:  0.151056098586761 iter:  118\n",
      "loss:  0.38952094899486817 iter:  119\n",
      "loss:  0.14174134499865376 iter:  120\n",
      "loss:  0.12715241803288851 iter:  121\n",
      "loss:  0.5373629583071495 iter:  122\n",
      "loss:  0.1289419842938401 iter:  123\n",
      "loss:  0.13239218930660593 iter:  124\n",
      "loss:  0.12267025038308334 iter:  125\n",
      "loss:  0.13642725590694404 iter:  126\n",
      "loss:  0.10910454911326865 iter:  127\n",
      "loss:  0.12214700936226934 iter:  128\n",
      "loss:  0.15184202208639924 iter:  129\n",
      "loss:  0.11741531345786806 iter:  130\n",
      "loss:  0.124085609542043 iter:  131\n",
      "loss:  0.1130611629373602 iter:  132\n",
      "loss:  0.15524641176463158 iter:  133\n",
      "loss:  0.11530346048175552 iter:  134\n",
      "loss:  0.11555407630227753 iter:  135\n",
      "loss:  0.1091909966597227 iter:  136\n",
      "loss:  0.1230651917147608 iter:  137\n",
      "loss:  0.11237323871373833 iter:  138\n",
      "loss:  0.12871332856466344 iter:  139\n",
      "loss:  0.11235866456480456 iter:  140\n",
      "loss:  0.1128551480233265 iter:  141\n",
      "loss:  0.11119835985491974 iter:  142\n",
      "loss:  0.10913027046535922 iter:  143\n",
      "loss:  0.11484534425492071 iter:  144\n",
      "loss:  0.1105683083150866 iter:  145\n",
      "loss:  0.1072984786544305 iter:  146\n",
      "loss:  0.10860959081297672 iter:  147\n",
      "loss:  0.123995910321949 iter:  148\n",
      "loss:  0.10912860733197796 iter:  149\n",
      "loss:  0.11658126277336768 iter:  150\n",
      "loss:  0.1089850484526243 iter:  151\n",
      "loss:  0.10920835896888512 iter:  152\n",
      "loss:  0.1082120936503147 iter:  153\n",
      "loss:  0.10736254518201661 iter:  154\n",
      "loss:  0.11152017801941222 iter:  155\n",
      "loss:  0.10813428587642117 iter:  156\n",
      "loss:  0.10848943855926928 iter:  157\n",
      "loss:  0.10651471965864465 iter:  158\n",
      "loss:  0.10676464015406589 iter:  159\n",
      "loss:  0.10913391439714698 iter:  160\n",
      "loss:  0.10766193519751012 iter:  161\n",
      "loss:  0.10699744589878703 iter:  162\n",
      "loss:  0.10599113831109652 iter:  163\n",
      "loss:  0.10615865714704058 iter:  164\n",
      "loss:  0.10643536013582901 iter:  165\n",
      "loss:  0.10752887109586769 iter:  166\n",
      "loss:  0.10665186359854452 iter:  167\n",
      "loss:  0.10683074151659508 iter:  168\n",
      "loss:  0.10751185289711182 iter:  169\n",
      "loss:  0.10641140584104075 iter:  170\n",
      "loss:  0.10764313938567803 iter:  171\n",
      "loss:  0.10627811815674697 iter:  172\n",
      "loss:  0.10578671009066885 iter:  173\n",
      "loss:  0.10602619180367646 iter:  174\n",
      "loss:  0.10539706093398586 iter:  175\n",
      "loss:  0.10560952687397712 iter:  176\n",
      "loss:  0.10720637568391207 iter:  177\n",
      "loss:  0.10580369474850065 iter:  178\n",
      "loss:  0.10644765313569593 iter:  179\n",
      "loss:  0.1059713809256912 iter:  180\n",
      "loss:  0.10643707736501437 iter:  181\n",
      "loss:  0.10589523597321472 iter:  182\n",
      "loss:  0.10527395106354495 iter:  183\n",
      "loss:  0.10524593574878302 iter:  184\n",
      "loss:  0.10530224811365767 iter:  185\n",
      "loss:  0.10588847882394299 iter:  186\n",
      "loss:  0.10544518979350777 iter:  187\n",
      "loss:  0.10474939414996823 iter:  188\n",
      "loss:  0.10464305000616565 iter:  189\n",
      "loss:  0.10615573979193156 iter:  190\n",
      "loss:  0.10536589898088551 iter:  191\n",
      "loss:  0.10541445108483774 iter:  192\n",
      "loss:  0.10519352965521477 iter:  193\n",
      "loss:  0.10484945178134168 iter:  194\n",
      "loss:  0.10479771142280679 iter:  195\n",
      "loss:  0.10570049127406468 iter:  196\n",
      "loss:  0.10498473981384174 iter:  197\n",
      "loss:  0.10469705227448622 iter:  198\n",
      "loss:  0.10436415603309813 iter:  199\n",
      "loss:  0.10430823648376045 iter:  200\n",
      "loss:  0.10433064416977712 iter:  201\n",
      "loss:  0.10428736972750392 iter:  202\n",
      "loss:  0.10448172841535334 iter:  203\n",
      "loss:  0.10452396754316773 iter:  204\n",
      "loss:  0.10389747629284642 iter:  205\n",
      "loss:  0.10380909031091345 iter:  206\n",
      "loss:  0.10370619628302698 iter:  207\n",
      "loss:  0.10365892338830918 iter:  208\n",
      "loss:  0.10393333675324314 iter:  209\n",
      "loss:  0.10494150295823294 iter:  210\n",
      "loss:  0.10406709789346244 iter:  211\n",
      "loss:  0.1037906323638938 iter:  212\n",
      "loss:  0.10310001131381874 iter:  213\n",
      "loss:  0.10288861846098413 iter:  214\n",
      "loss:  0.10371195770142841 iter:  215\n",
      "loss:  0.1030964852665015 iter:  216\n",
      "loss:  0.10278642452017761 iter:  217\n",
      "loss:  0.10273932109971264 iter:  218\n",
      "loss:  0.10328974183647396 iter:  219\n",
      "loss:  0.1035638213731753 iter:  220\n",
      "loss:  0.10195186800662093 iter:  221\n",
      "loss:  0.10162651816028898 iter:  222\n",
      "loss:  0.10302527408816534 iter:  223\n",
      "loss:  0.10276757479088314 iter:  224\n",
      "loss:  0.10177010879923115 iter:  225\n",
      "loss:  0.10216790507356108 iter:  226\n",
      "loss:  0.10199083283007736 iter:  227\n",
      "loss:  0.10159718655061124 iter:  228\n",
      "loss:  0.10195585254576124 iter:  229\n",
      "loss:  0.10051849871822505 iter:  230\n",
      "loss:  0.10025942598302345 iter:  231\n",
      "loss:  0.10167589030214808 iter:  232\n",
      "loss:  0.1007429845384079 iter:  233\n",
      "loss:  0.10146517094338674 iter:  234\n",
      "loss:  0.10257597947541627 iter:  235\n",
      "loss:  0.1008460887136848 iter:  236\n",
      "loss:  0.09958476544342217 iter:  237\n",
      "loss:  0.09920343194978061 iter:  238\n",
      "loss:  0.0988817311268568 iter:  239\n",
      "loss:  0.0984602037784072 iter:  240\n",
      "loss:  0.0996632078863246 iter:  241\n",
      "loss:  0.09969172977988441 iter:  242\n",
      "loss:  0.09786272968034264 iter:  243\n",
      "loss:  0.09739089037941401 iter:  244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Root finder converged (message: The solution converged.), but solution check failed.\n",
      "WARNING:root:Condition 179 ({'C': np.float64(0.0), 'CO': np.float64(0.0), 'CO2': np.int64(0), 'O': np.float64(1.09042204654276e+16), 'O2': np.int64(84292711097824800), 'O3': np.float64(0.0), 'Tgas': np.float64(0.0), 'Tnw': np.float64(393.1257681), 'Tw': np.float64(323.15), 'current': np.int64(40), 'frac_CO2': np.float64(0.0), 'pressure': np.float64(5.0), 'fluxO': np.float64(1.9661943023718675e+20), 'fluxO2': np.float64(1.0747484662893536e+21), 'fluxO3': np.float64(0.0), 'fluxC': np.float64(0.0), 'fluxCO': np.float64(0.0), 'fluxCO2': np.float64(0.0), 'EavgMB': 0.001, 'Ion': np.float64(4000000000000000.0)}): Solver failed or solution check failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.09664794456681987 iter:  245\n",
      "loss:  0.09582510970955645 iter:  246\n",
      "loss:  0.09754927879046102 iter:  247\n",
      "loss:  0.09595180962838418 iter:  248\n",
      "loss:  0.09482299383141223 iter:  249\n",
      "loss:  0.09439387356100719 iter:  250\n",
      "loss:  0.0929470178276652 iter:  251\n",
      "loss:  0.09229392155003367 iter:  252\n",
      "loss:  0.0937111305106395 iter:  253\n",
      "loss:  0.08955813315740567 iter:  254\n",
      "loss:  0.08850766775175616 iter:  255\n",
      "loss:  0.09328979936406676 iter:  256\n",
      "loss:  0.08976777305956248 iter:  257\n",
      "loss:  0.08634184997981084 iter:  258\n",
      "loss:  0.08487410635740097 iter:  259\n",
      "loss:  0.09644056139093414 iter:  260\n",
      "loss:  0.0914114923544313 iter:  261\n",
      "loss:  0.09067139041421587 iter:  262\n",
      "loss:  0.08181712576320621 iter:  263\n",
      "loss:  0.07914479238876287 iter:  264\n",
      "loss:  0.0925444081154228 iter:  265\n",
      "loss:  0.0891288531939615 iter:  266\n",
      "loss:  0.0900006177614663 iter:  267\n",
      "loss:  0.08772679613671812 iter:  268\n",
      "loss:  0.08608886732144572 iter:  269\n",
      "loss:  0.07885662267192328 iter:  270\n",
      "loss:  0.08006316466103763 iter:  271\n",
      "loss:  0.07726328289555581 iter:  272\n",
      "loss:  0.13025918485541735 iter:  273\n",
      "loss:  0.17033319827840934 iter:  274\n",
      "loss:  0.08476840768017241 iter:  275\n",
      "loss:  0.08478267476231237 iter:  276\n",
      "loss:  0.1000464156516657 iter:  277\n",
      "loss:  0.08293756956707724 iter:  278\n",
      "loss:  0.08585624059297112 iter:  279\n",
      "loss:  0.08530034520436397 iter:  280\n",
      "loss:  0.0775002765662436 iter:  281\n",
      "loss:  0.07818215721040875 iter:  282\n",
      "loss:  0.08166407377914119 iter:  283\n",
      "loss:  0.0833241864904408 iter:  284\n",
      "loss:  0.08215612660760155 iter:  285\n",
      "loss:  0.10916491558201208 iter:  286\n",
      "loss:  0.08170792175615268 iter:  287\n",
      "loss:  0.08230788293546787 iter:  288\n",
      "loss:  0.08502003505540817 iter:  289\n",
      "loss:  0.07704330213548673 iter:  290\n",
      "loss:  0.07775242571245623 iter:  291\n",
      "loss:  0.08081155056276967 iter:  292\n",
      "loss:  0.0809868388749546 iter:  293\n",
      "loss:  0.08033664485801156 iter:  294\n",
      "loss:  0.0794196491227186 iter:  295\n",
      "loss:  0.11983355409287072 iter:  296\n",
      "loss:  0.08002766374190923 iter:  297\n",
      "loss:  0.07876330779849583 iter:  298\n",
      "loss:  0.08945278835320182 iter:  299\n",
      "loss:  0.0788992688848563 iter:  300\n",
      "loss:  0.07858139904189677 iter:  301\n",
      "loss:  0.07698474663550134 iter:  302\n",
      "loss:  0.0783502777977398 iter:  303\n",
      "loss:  0.08091495136375709 iter:  304\n",
      "loss:  0.0771114951201574 iter:  305\n",
      "loss:  0.08244917694878301 iter:  306\n",
      "loss:  0.07764157093784935 iter:  307\n",
      "loss:  0.07623913806712526 iter:  308\n",
      "loss:  0.07757477434197732 iter:  309\n",
      "loss:  0.08581368689277749 iter:  310\n",
      "loss:  0.07697167928912606 iter:  311\n",
      "loss:  0.0861253575960097 iter:  312\n",
      "loss:  0.07643798113734493 iter:  313\n",
      "loss:  0.07712560588362306 iter:  314\n",
      "loss:  0.07660272778266888 iter:  315\n",
      "loss:  0.07622311976163246 iter:  316\n",
      "loss:  0.07654310775521742 iter:  317\n",
      "loss:  0.07722056713036922 iter:  318\n",
      "loss:  0.07643850608185063 iter:  319\n",
      "loss:  0.08093196145606307 iter:  320\n",
      "loss:  0.07655226841365352 iter:  321\n",
      "loss:  0.07609620857301781 iter:  322\n",
      "loss:  0.07655019123454936 iter:  323\n",
      "loss:  0.08095933616556832 iter:  324\n",
      "loss:  0.07628999233588184 iter:  325\n",
      "loss:  0.07658925980601648 iter:  326\n",
      "loss:  0.07613088909336836 iter:  327\n",
      "loss:  0.07994704156315113 iter:  328\n",
      "loss:  0.07654500844558475 iter:  329\n",
      "loss:  0.07606941617484221 iter:  330\n",
      "loss:  0.0761304350112261 iter:  331\n",
      "loss:  0.07619909681011465 iter:  332\n",
      "loss:  0.07623934290828245 iter:  333\n",
      "loss:  0.07630253108514418 iter:  334\n",
      "loss:  0.07798144632329118 iter:  335\n",
      "loss:  0.07637937975441254 iter:  336\n",
      "loss:  0.07618510532987334 iter:  337\n",
      "loss:  0.07609769407734575 iter:  338\n",
      "loss:  0.07613206366931513 iter:  339\n",
      "loss:  0.0761929465600979 iter:  340\n",
      "  -> Finished (Max Evals). Loss: 0.076069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_iters_tot = 1300\n",
    "filename_results = \"results/results_hier5_train_V4.h5\"\n",
    "\n",
    "pipeline = [\n",
    "    ('decompose_exact', {'percent_info': 0.90, 'tau': 1e-4}),\n",
    "    ('optimize_stiff', {'max_iter': 70, 'bound_range': 1.1}),\n",
    "    ('optimize_combined_subspace', {'max_iter': 250}),\n",
    "]\n",
    "\n",
    "# Instantiate\n",
    "opt_hier = ha.HierarchicalOptimizer(optimizer, params_default_norm, pipeline=pipeline)\n",
    "opt_hier.run(max_cycles=1, max_iter=max_iters_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filename_results, \"w\") as f:\n",
    "    \n",
    "    f.create_dataset(\"best_loss\", data=opt_hier.history['best_loss'])\n",
    "    f.create_dataset(\"iters\", data=opt_hier.history['iters'])\n",
    "    f.create_dataset(\"best_params\", data=opt_hier.history['best_params'])\n",
    "    \n",
    "    f.create_dataset(\"best_params_end\", data=opt_hier.phi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qp_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
