{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  d[CO2_F]/dt = -CO2_F*r_29 + r_28*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_F]/dt = -CO_F*O_F*r_34 - 0.02*CO_F*O_S*r_39 - CO_F*r_31 - CO_F*r_33 - 0.02*CO_F*r_35*(-CO_S - O_S - Odb_S - Vdb_S + 1.0) + r_30*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[CO_S]/dt = CO_F*r_35*(-CO_S - O_S - Odb_S - Vdb_S + 1.0) - CO_S*O_F*r_38 - CO_S*r_36 + r_32*(-CO_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[O2_F]/dt = -O2_F*O_F*r_15 - O2_F*r_10 - O2_F*r_12 - O2_F*r_14 + r_9*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_F]/dt = -CO_F*O_F*r_34 - 0.02*CO_S*O_F*r_38 - O2_F*O_F*r_15 - 2*O_F**2*r_8 - 0.02*O_F*O_S*r_7 - 0.02*O_F*Odb_S*r_27 - 0.02*O_F*Vdb_S*r_26 - O_F*r_11 - O_F*r_2 - O_F*r_4 - 0.02*O_F*r_5*(-CO_S - O_S - Odb_S - Vdb_S + 1.0) + r_1*(-CO2_F - CO_F - O2_F - O_F + 1.0)\n",
      "  d[O_S]/dt = -CO_F*O_S*r_39 - O_F*O_S*r_7 + O_F*r_5*(-CO_S - O_S - Odb_S - Vdb_S + 1.0) - O_S*r_16 - O_S*r_17 - O_S*r_37 - O_S*r_6 + r_3*(-CO_S - O_S - Odb_S - Vdb_S + 1.0)\n",
      "  d[Odb_S]/dt = -O_F*Odb_S*r_27 + O_F*Vdb_S*r_26 - Odb_S*r_23 - Odb_S*r_24 - Odb_S*r_25 + Vdb_S*r_20\n",
      "  d[Vdb_S]/dt = O_F*Odb_S*r_27 - O_F*Vdb_S*r_26 + O_S*r_16 + O_S*r_17 + Odb_S*r_25 - Vdb_S*r_20 - Vdb_S*r_21 - Vdb_S*r_22 + r_18*(-CO_S - O_S - Odb_S - Vdb_S + 1.0) + r_19*(-CO_S - O_S - Odb_S - Vdb_S + 1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "PATH = os.path.dirname(os.path.abspath(os.curdir))\n",
    "if PATH not in sys.path:\n",
    "    sys.path.insert(0, PATH)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "from pathos.multiprocessing import ProcessPool\n",
    "import src.Simulator as sim_system\n",
    "import src.Optimizer as opt\n",
    "import src.SimGrad as sim_diff\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "\n",
    "###* Create Simulator object\n",
    "reactions_file = \"../reactions/reactionsSimpleV1.json\"\n",
    "\n",
    "const_dict = {\n",
    "        \"F0\": 1.5e15,           # cm^-2\n",
    "        \"S0\": 3e13,             # cm^-2\n",
    "        \n",
    "        \"R\": 0.00831442,        # kJ/mol*K\n",
    "        \"kBoltz\": 1.380649e-23, # J/K\n",
    "}\n",
    "\n",
    "initial_state_dict = {'O_F': 0.1, 'O2_F':0.1 ,'O_S': 0.1, 'Vdb_S':0.1, \n",
    "                    'Odb_S': 0.1, 'CO_F': 0.1, 'CO2_F':0.1, 'CO_S': 0.1, \n",
    "                    'COdb_S': 0.0}\n",
    "\n",
    "###* Functions for the data transformation\n",
    "def compute_flux(const_dict, exp_dict, specie, molar_mass):\n",
    "    den = exp_dict.get(specie, 0.0)\n",
    "    v_th = np.sqrt((8.0 * const_dict['R'] * 1000 * exp_dict['Tnw'])/(molar_mass * np.pi))\n",
    "    flux = 0.25 * v_th * den * 100\n",
    "    return flux\n",
    "\n",
    "\n",
    "def compute_remaining_flux(const_dict, exp_dict, molar_mass): \n",
    "    den = exp_dict['N'] - exp_dict['O'] - exp_dict['CO']\n",
    "    v_th = np.sqrt((8.0 * const_dict['R'] * 1000 * exp_dict['Tnw'])/(molar_mass * np.pi))\n",
    "    flux = 0.25 * v_th * den * 100\n",
    "    return flux\n",
    "\n",
    "####? EavgMB data extracted from the Booth et al. 2019 paper\n",
    "p_data_exp = [0.2, 0.3, 0.4, 0.5, 0.6, 0.75, 1.5]\n",
    "EavgMB_data = [1.04, 0.91, 0.87, 0.83, 0.77, 0.5, 0.001]\n",
    "interpolator = sp.interpolate.interp1d(p_data_exp, EavgMB_data, kind='linear', fill_value=0.001, bounds_error=False)\n",
    "\n",
    "\n",
    "transformations_exp = {\n",
    "    'Tw':       lambda const_dict, exp_dict: exp_dict['Tw'] + 273.15,\n",
    "    'fluxO' :   lambda const_dict, exp_dict: compute_flux(const_dict, exp_dict,'O', 0.016),\n",
    "    'fluxO2' :  lambda const_dict, exp_dict: compute_flux(const_dict, exp_dict,'O2', 0.032),\n",
    "    'fluxO3' :  lambda const_dict, exp_dict: compute_flux(const_dict, exp_dict,'O3', 0.048),\n",
    "    'fluxC':    lambda const_dict, exp_dict: compute_flux(const_dict, exp_dict, 'C', 0.012),\n",
    "    'fluxCO':   lambda const_dict, exp_dict: compute_flux(const_dict, exp_dict, 'CO', 0.028),\n",
    "    'fluxCO2':  lambda const_dict, exp_dict: compute_flux(const_dict, exp_dict, 'CO2', 0.048),\n",
    "    'EavgMB':   lambda const_dict, exp_dict: interpolator(exp_dict['pressure']).item(),\n",
    "    'Ion':      lambda const_dict, exp_dict: 1e14 * exp_dict[\"current\"]\n",
    "}\n",
    "\n",
    "output_folder_path = \"../Buffer_Data\"\n",
    "exp_data_file = \"Experimental_data_CO_Jorge.hdf5\"\n",
    "exp_file = os.path.join(output_folder_path, exp_data_file)\n",
    "\n",
    "sim = sim_system.Simulator(reactions_file, const_dict, exp_file, initial_state_dict, transformations_exp=transformations_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_default:  (0.03267998065359961, 0.0166990166990167, 0.6583333333333333, 1.0, 1.0, 0.00999009990099901, 0.0999909999099991, 0.0999909999099991, 0.00999009990099901, 0.0999909999099991, 0.0999909999099991, 0.0999909999099991, 0.0999909999099991)\n"
     ]
    }
   ],
   "source": [
    "###* Create optimization and diff objects with the proper bounds\n",
    "lower_bounds = np.array([1e-8, 1e-8, 0.0, \\\n",
    "                    1e-5, 1e-5, 1e-5, 1e-5, 1e-5, \\\n",
    "                    1e-5, 1e-5, 1e-5, 1e-5, 1e-5\n",
    "                    ])\n",
    "\n",
    "upper_bounds = np.array([5e-1, 1e-2, 30.0, \\\n",
    "                    1.0, 1.0, 1.0, 1.0, 1.0, \\\n",
    "                    1.0, 1.0, 1.0, 1.0, 1.0\n",
    "                    ])\n",
    "\n",
    "##! define parameters to optimize\n",
    "def func_optimization(params, flag='numpy'):\n",
    "    \n",
    "    A_d, B_d, E_d, SF_1, SF_2, SF_3, SF_4, SF_5, SF_6, SF_7, SF_8, SF_9, SF_10 = params\n",
    "    \n",
    "    A_d = lower_bounds[0] + (upper_bounds[0] - lower_bounds[0]) * A_d\n",
    "    B_d = lower_bounds[1] + (upper_bounds[1] - lower_bounds[1]) * B_d\n",
    "    E_d = lower_bounds[2] + (upper_bounds[2] - lower_bounds[2]) * E_d\n",
    "    \n",
    "    SF_1 = lower_bounds[3] + (upper_bounds[3] - lower_bounds[3]) * SF_1\n",
    "    SF_2 = lower_bounds[4] + (upper_bounds[4] - lower_bounds[4]) * SF_2\n",
    "    SF_3 = lower_bounds[5] + (upper_bounds[5] - lower_bounds[5]) * SF_3\n",
    "    SF_4 = lower_bounds[6] + (upper_bounds[6] - lower_bounds[6]) * SF_4\n",
    "    SF_5 = lower_bounds[7] + (upper_bounds[7] - lower_bounds[7]) * SF_5\n",
    "    \n",
    "    SF_6 = lower_bounds[8] + (upper_bounds[8] - lower_bounds[8]) * SF_6\n",
    "    SF_7 = lower_bounds[9] + (upper_bounds[9] - lower_bounds[9]) * SF_7\n",
    "    SF_8 = lower_bounds[10] + (upper_bounds[10] - lower_bounds[10]) * SF_8\n",
    "    SF_9 = lower_bounds[11] + (upper_bounds[11] - lower_bounds[11]) * SF_9\n",
    "    SF_10 = lower_bounds[12] + (upper_bounds[12] - lower_bounds[12]) * SF_10\n",
    "    \n",
    "    if flag=='numpy':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * np.exp(E_d/(const_dict['R'] * T)))\n",
    "    elif flag=='torch':\n",
    "        nu_d_mod = lambda T: 1e15 * (A_d + B_d * torch.exp(E_d/(const_dict['R'] * T)))\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "    \n",
    "    dict_mod_vec = [\n",
    "    {\"id\": 2, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 10, \"rate\": None, \"model_dict\": {\"nu_d\": nu_d_mod}},\n",
    "    {\"id\": 31, \"rate\": None, \"model_dict\": {\"SF\": SF_2, \"nu_d\": nu_d_mod}},\n",
    "    \n",
    "    {\"id\": 30, \"rate\": None, \"model_dict\": {\"SF\": SF_1}},\n",
    "    # {\"id\": 31, \"rate\": None, \"model_dict\": {\"SF\": SF_2}},\n",
    "    {\"id\": 32, \"rate\": None, \"model_dict\": {\"SF\": SF_3}},\n",
    "    {\"id\": 33, \"rate\": None, \"model_dict\": {\"SF\": SF_4}},\n",
    "    {\"id\": 34, \"rate\": None, \"model_dict\": {\"SF\": SF_5}},\n",
    "    \n",
    "    {\"id\": 35, \"rate\": None, \"model_dict\": {\"SF\": SF_6}},\n",
    "    {\"id\": 36, \"rate\": None, \"model_dict\": {\"SF\": SF_7}},\n",
    "    {\"id\": 37, \"rate\": None, \"model_dict\": {\"SF\": SF_8}},\n",
    "    {\"id\": 38, \"rate\": None, \"model_dict\": {\"SF\": SF_9}},\n",
    "    {\"id\": 39, \"rate\": None, \"model_dict\": {\"SF\": SF_10}},\n",
    "    ]\n",
    "    \n",
    "    return dict_mod_vec\n",
    "\n",
    "##! define the default parameters\n",
    "params_default = []\n",
    "params_default_aux = list((0.01634, 1.67e-4, 19.75, \\\n",
    "                1.0, 1.0, 1e-2, 1e-1, 1e-1, \\\n",
    "                1e-2, 1e-1, 1e-1, 1e-1, 1e-1\n",
    "                ))\n",
    "for idx, param in enumerate(params_default_aux):\n",
    "    value = (param - lower_bounds[idx])/(upper_bounds[idx] - lower_bounds[idx])\n",
    "    params_default.append(value)\n",
    "\n",
    "params_default = tuple(params_default)\n",
    "\n",
    "print(\"params_default: \", params_default)\n",
    "\n",
    "def loss_function(exp, teo, flag='numpy'):\n",
    "    \n",
    "    func = ((teo-exp)**2)/(exp**2)\n",
    "    if flag == 'numpy':\n",
    "        return np.mean(func)\n",
    "    elif flag == 'torch':\n",
    "        return torch.mean(func)\n",
    "    else:\n",
    "        raise ValueError(f\"{flag} does not exist\")\n",
    "\n",
    "\n",
    "optimizer = opt.Optimizer(sim, \n",
    "                        lambda params: func_optimization(params, 'numpy'), \n",
    "                        lambda exp, teo: loss_function(exp, teo, 'numpy')\n",
    "                        )\n",
    "\n",
    "diff = sim_diff.SimDiff(sim, \n",
    "                        lambda params: func_optimization(params, 'torch'),\n",
    "                        params_default=params_default,\n",
    "                        gamma_exp_data=sim.gamma_exp_data_arr,\n",
    "                        loss_function=lambda exp, teo: loss_function(exp, teo, 'torch')\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def loss_and_grads(params, opt_object, diff_object):\n",
    "#     loss_val, frac_solutions_arr, rates_arr, _, gammas_predicted_arr = opt_object.objective_function_diff(params)\n",
    "#     grad_val = diff_object.objective_function_grad(params, frac_solutions_arr, rates_arr, gammas_predicted_arr)\n",
    "#     # print(\"loss_val: \", loss_val, \"grad_val: \", grad_val, \"params: \", params)\n",
    "#     return loss_val, grad_val.detach().numpy()[2]\n",
    "\n",
    "\n",
    "# # param_vec = np.linspace(19.5, 20.5, 12)\n",
    "\n",
    "# param_vec = np.linspace(0.673, 0.676, 12)\n",
    "# for param in param_vec:\n",
    "#     params = np.array(params_default)\n",
    "#     params[2] = param\n",
    "    \n",
    "#     print(loss_and_grads(params, optimizer, diff), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grads_wise(params, opt_object, diff_object):\n",
    "    loss_val, frac_solutions_arr, rates_arr, _, gammas_predicted_arr = opt_object.objective_function_diff(params)\n",
    "    grad_val = diff_object.objective_function_grad_element_wise(params, frac_solutions_arr, rates_arr, gammas_predicted_arr)\n",
    "    return grad_val.detach().numpy()\n",
    "\n",
    "\n",
    "def create_subspaces(params, percent_info, opt_object, diff_object):\n",
    "\n",
    "    grad_errors =  - grads_wise(params_default, opt_object, diff_object) / sim.gamma_exp_data_arr.reshape(-1, 1)\n",
    "    F_matrix = np.matmul(grad_errors.T, grad_errors)\n",
    "\n",
    "    eigenvalues, eigenvector = np.linalg.eigh(F_matrix)\n",
    "    \n",
    "    np.linalg.norm(eigenvector, axis=0)\n",
    "\n",
    "    idx = np.argsort(np.abs(eigenvalues))[::-1]\n",
    "    eigvals_sorted = eigenvalues[idx]\n",
    "    eigvecs_sorted = eigenvector[:,idx]\n",
    "\n",
    "    total_info = np.sum(np.abs(eigvals_sorted))\n",
    "\n",
    "    cumulative = np.cumsum(np.abs(eigvals_sorted))\n",
    "    threshold = percent_info * total_info\n",
    "    num_components = np.searchsorted(cumulative, threshold) + 1\n",
    "\n",
    "    eigvals_selected = eigvals_sorted[:num_components]\n",
    "    Vs = eigvecs_sorted[:,:num_components]\n",
    "    Vl = eigvecs_sorted[:,num_components:]\n",
    "    \n",
    "    output = {}\n",
    "    output['num_components'] = num_components\n",
    "    output['Vs'] = Vs\n",
    "    output['Vl'] = Vl\n",
    "    output['eigvals_sorted'] = eigvals_sorted\n",
    "    output['eigvecs_sorted'] = eigvecs_sorted\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grads_wise2(params, opt_object, diff_object):\n",
    "    _, frac_solutions_arr, rates_arr, _, gammas_predicted_arr = (opt_object.objective_function_diff(params))\n",
    "    grad_val = diff_object.objective_function_grad_element_wise(params, frac_solutions_arr, rates_arr, gammas_predicted_arr)\n",
    "    return grad_val.detach()\n",
    "\n",
    "\n",
    "def create_subspacesV2(params, percent_info, opt_object, diff_object, eps = 1e-8, reg = 1e-6):\n",
    "\n",
    "    grad_errors = -grads_wise2(params, opt_object, diff_object)\n",
    "    gamma_exp = torch.tensor(\n",
    "        sim.gamma_exp_data_arr, dtype=grad_errors.dtype\n",
    "    ).reshape(-1, 1)\n",
    "    grad_errors = grad_errors / (gamma_exp + eps)\n",
    "    norms = grad_errors.norm(dim=1, keepdim=True) + eps\n",
    "    G = grad_errors / norms                 \n",
    "    F  = G.T @ G                            \n",
    "\n",
    "    F_reg = F + reg * torch.eye(F.size(0), dtype=F.dtype)\n",
    "    eigvals, eigvecs = torch.linalg.eigh(F_reg) # ascending\n",
    "    \n",
    "    idx = torch.argsort(eigvals, descending=True)\n",
    "    eigvals_sorted = eigvals[idx]\n",
    "    eigvecs_sorted = eigvecs[:, idx]\n",
    "    \n",
    "    total_mass = eigvals_sorted.sum()\n",
    "    cumulative  = torch.cumsum(eigvals_sorted, dim=0)\n",
    "    k = int((cumulative < percent_info * total_mass).sum().item()) + 1\n",
    "    \n",
    "    Vs = eigvecs_sorted[:, :k]\n",
    "    Vl = eigvecs_sorted[:, k:]\n",
    "    return {\n",
    "        'num_components': k,\n",
    "        'Vs': Vs,\n",
    "        'Vl': Vl,\n",
    "        'eigvals_sorted': eigvals_sorted,\n",
    "        'eigvecs_sorted': eigvecs_sorted\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def loss_stiff_subspace(phi, opt_object, diff_object, config):\n",
    "    num_components = config['num_components']\n",
    "    Vs = config['Vs']\n",
    "    Vl = config['Vl']\n",
    "    phi0 = config['phi0']\n",
    "    \n",
    "    params_aux = np.dot(Vs, phi).reshape(-1) + np.dot(Vl, phi0[num_components:]).reshape(-1)\n",
    "    params = tuple(np.abs(params_aux).reshape(-1))    \n",
    "    \n",
    "    loss_val, frac_solutions_arr, rates_arr, _, gammas_predicted_arr = opt_object.objective_function_diff(params)\n",
    "    return loss_val\n",
    "\n",
    "\n",
    "def loss_and_grads_stiff_subspace(phi, opt_object, diff_object, config):\n",
    "    num_components = config['num_components']\n",
    "    Vs = config['Vs']\n",
    "    Vl = config['Vl']\n",
    "    phi0 = config['phi0']\n",
    "    \n",
    "    params_aux = np.dot(Vs, phi).reshape(-1) + np.dot(Vl, phi0[num_components:]).reshape(-1)\n",
    "    params = tuple(np.abs(params_aux).reshape(-1))    \n",
    "    \n",
    "    loss_val, frac_solutions_arr, rates_arr, _, gammas_predicted_arr = opt_object.objective_function_diff(params)\n",
    "    grad_val = diff_object.objective_function_grad(params, frac_solutions_arr, rates_arr, gammas_predicted_arr)\n",
    "    grad_val_stiff = Vs.reshape(-1) @ grad_val.detach().numpy()\n",
    "    print(\"loss: \", loss_val, \"grads: \", grad_val_stiff, \"phi: \", phi)\n",
    "    \n",
    "    return loss_val, grad_val_stiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.11222424225359708 grads:  tensor(-700.0361, dtype=torch.float64) phi:  [0.20961573]\n",
      "loss:  0.8576449876494352 grads:  tensor(0.4944, dtype=torch.float64) phi:  [1.]\n",
      "loss:  0.8346976581666731 grads:  tensor(1.9894, dtype=torch.float64) phi:  [0.47246186]\n",
      "loss:  0.7424475035386063 grads:  tensor(15.1081, dtype=torch.float64) phi:  [0.29667156]\n",
      "loss:  0.4936603403308341 grads:  tensor(93.2913, dtype=torch.float64) phi:  [0.2383516]\n",
      "loss:  0.18070526926025068 grads:  tensor(187.9791, dtype=torch.float64) phi:  [0.2194677]\n",
      "loss:  0.05858896335110213 grads:  tensor(2.6969, dtype=torch.float64) phi:  [0.21328888]\n",
      "loss:  0.058458491851253215 grads:  tensor(1.4763, dtype=torch.float64) phi:  [0.21327479]\n",
      "loss:  0.05830265302003106 grads:  tensor(-0.0091, dtype=torch.float64) phi:  [0.21325774]\n",
      "loss:  0.058303596446567796 grads:  tensor(3.1030e-05, dtype=torch.float64) phi:  [0.21325784]\n",
      "loss:  0.05830265317726424 grads:  tensor(-0.0091, dtype=torch.float64) phi:  [0.21325774]\n",
      "loss:  0.05830265301991272 grads:  tensor(-0.0091, dtype=torch.float64) phi:  [0.21325774]\n",
      "loss:  0.05830265309879248 grads:  tensor(-0.0091, dtype=torch.float64) phi:  [0.21325774]\n",
      "loss:  0.05830265302054505 grads:  tensor(-0.0091, dtype=torch.float64) phi:  [0.21325774]\n",
      "loss:  0.05830265301991272 grads:  tensor(-0.0091, dtype=torch.float64) phi:  [0.21325774]\n",
      "loss:  0.05830265302030101 grads:  tensor(-0.0091, dtype=torch.float64) phi:  [0.21325774]\n"
     ]
    }
   ],
   "source": [
    "percent_info = 0.90\n",
    "\n",
    "config_dict = create_subspacesV2(params_default, percent_info, optimizer, diff)\n",
    "phi0 = np.linalg.solve(config_dict['eigvecs_sorted'], np.array(params_default))\n",
    "\n",
    "config_dict['phi0'] = phi0\n",
    "\n",
    "lower_Vs = [0.0] * config_dict['num_components']\n",
    "upper_Vs = [1.0] * config_dict['num_components']\n",
    "\n",
    "res = sp.optimize.minimize(\n",
    "        lambda params: loss_and_grads_stiff_subspace(params, optimizer, diff, config_dict),\n",
    "        x0=phi0[:config_dict['num_components']],\n",
    "        jac=True,\n",
    "        bounds=[(a_i, b_i) for a_i, b_i in zip(lower_Vs, upper_Vs)],\n",
    "        tol = 5e-5,\n",
    "        method='L-BFGS-B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1440e-02],\n",
      "        [ 9.7930e-01],\n",
      "        [ 1.9428e-01],\n",
      "        [ 4.5638e-02],\n",
      "        [ 1.7040e-02],\n",
      "        [ 1.3385e-06],\n",
      "        [-1.2811e-06],\n",
      "        [ 1.9836e-02],\n",
      "        [ 3.3908e-04],\n",
      "        [-3.3554e-05],\n",
      "        [-6.9300e-07],\n",
      "        [-8.4869e-07],\n",
      "        [-2.7264e-09]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(config_dict['Vs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(config_dict['eigvals_sorted'], '.')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# phiVec = np.linspace(0.895, 0.904, 15)\n",
    "# lossVec = np.zeros_like(phiVec)\n",
    "# gradsVec = np.zeros_like(phiVec)\n",
    "\n",
    "# for idx, phi in enumerate(phiVec):\n",
    "#     result = loss_and_grads_stiff_subspace(phi, optimizer, diff, config_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# percent_info = 0.90\n",
    "\n",
    "# phiVec = np.linspace(0.87, 0.9, 10)\n",
    "# lossVec = np.zeros_like(phiVec)\n",
    "\n",
    "# config_dict = create_subspaces(params_default, percent_info, optimizer, diff)\n",
    "# phi0 = np.linalg.solve(config_dict['eigvecs_sorted'], np.array(params_default))\n",
    "\n",
    "# config_dict['phi0'] = phi0\n",
    "\n",
    "\n",
    "# result = sp.optimize.minimize(lambda phi: loss_stiff_subspace(phi, optimizer, diff, config_dict), phi0[0],\n",
    "#                             method='Nelder-Mead', options={'fatol': 1e-5})\n",
    "\n",
    "# print(result)\n",
    "\n",
    "# for idx, phi in enumerate(phiVec):\n",
    "#     lossVec[idx] = loss_stiff_subspace(phi, optimizer, diff, config_dict)    \n",
    "#     print(idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lossVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(phiVec, lossVec)\n",
    "# plt.yscale('log')\n",
    "# plt.ylim(0.0, 0.5)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvalues, eigenvector = np.linalg.eigh(F_matrix)\n",
    "\n",
    "# print(eigenvalues.real)\n",
    "\n",
    "# print(eigenvector[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
